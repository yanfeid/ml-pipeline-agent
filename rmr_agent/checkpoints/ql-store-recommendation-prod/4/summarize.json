{
  "summaries": {
<<<<<<< HEAD
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/00_driver.py": "**Load YAML configuration file (Lines 4-13):**\n- Defines a function to load a YAML file.\n- Loads the configuration from a specified file path.\n\n**Extract BigQuery project dataset prefix from configuration (Lines 14-16):**\n- Retrieves the BigQuery project dataset prefix from the loaded configuration.\n\n**Create live unique merchants training table (Lines 18-52):**\n- Drops the existing table if it exists.\n- Creates a new table with unique merchants by joining multiple tables and applying filters.\n\n**Create driver_00 table (Lines 54-81):**\n- Drops the existing table if it exists.\n- Creates a new table with customer and merchant interaction data, applying various filters and transformations.\n\n**Create driver_0 table (Lines 84-102):**\n- Drops the existing table if it exists.\n- Creates a new table by filtering and combining data from driver_00 based on specific conditions.\n\n**Create driver_1 table (Lines 105-120):**\n- Drops the existing table if it exists.\n- Creates a new table with transaction data by joining with the live unique merchants training table.\n\n**Create driver_positive_train_attributed table (Lines 124-168):**\n- Drops the existing table if it exists.\n- Creates a new table with positive training samples attributed to transactions, applying various sampling and filtering techniques.\n\n**Create driver_positive_train_organic_0 table (Lines 170-204):**\n- Drops the existing table if it exists.\n- Creates a new table with organic positive training samples, applying multiple filters to remove biases.\n\n**Create driver_positive_train_organic table (Lines 207-244):**\n- Drops the existing table if it exists.\n- Creates a new table with sampled organic positive training samples, applying additional sampling techniques.\n\n**Create driver_positive table (Lines 247-277):**\n- Drops the existing table if it exists.\n- Combines various positive training samples into a single table, including attributed, organic, and save samples.\n\n**Create driver_positive_training_split_0 table (Lines 281-307):**\n- Drops the existing table if it exists.\n- Creates a new table by splitting positive training samples into hard and uniform negatives.\n\n**Create driver_positive_training_split table (Lines 310-321):**\n- Drops the existing table if it exists.\n- Adds a count of positive samples per day to the training split table.\n\n**Create driver_training_hard_negative table (Lines 324-336):**\n- Drops the existing table if it exists.\n- Creates a new table with hard negative samples by joining with driver_0 and applying filters.\n\n**Create driver_training_hard_negative_downsample table (Lines 339-349):**\n- Drops the existing table if it exists.\n- Downsamples hard negative samples based on specific conditions.\n\n**Create driver_training_uniform_negative table (Lines 352-364):**\n- Drops the existing table if it exists.\n- Creates a new table with uniform negative samples by joining with live unique merchants training table.\n\n**Create driver_training_uniform_negative_remove_window_positive table (Lines 367-376):**\n- Drops the existing table if it exists.\n- Removes uniform negative samples that overlap with positive feedback windows.\n\n**Create driver_training_uniform_negative_downsample_0 table (Lines 379-401):**\n- Drops the existing table if it exists.\n- Downsamples uniform negative samples based on merchant sampling probabilities.\n\n**Create driver_training_uniform_negative_downsample table (Lines 404-407):**\n- Drops the existing table if it exists.\n- Further downsamples uniform negative samples to maintain a specific positive-to-negative ratio.\n\n**Create driver_dev table (Lines 410-445):**\n- Drops the existing table if it exists.\n- Combines positive and negative samples into a development dataset, including both hard and uniform negatives.\n\n**Create driver_oot_uniform_negative_0 table (Lines 449-469):**\n- Drops the existing table if it exists.\n- Creates a new table with out-of-time (OOT) uniform negative samples.\n\n**Create driver_oot_uniform_negative table (Lines 472-478):**\n- Drops the existing table if it exists.\n- Removes duplicate OOT uniform negative samples.\n\n**Create driver_oot table (Lines 481-495):**\n- Drops the existing table if it exists.\n- Combines positive and negative OOT samples into a single table.\n\n**Create driver_simu table (Lines 498-506):**\n- Drops the existing table if it exists.\n- Combines distinct customer and receiver interactions from development and OOT datasets.\n\n**Create driver_simu_consumer table (Lines 509-512):**\n- Drops the existing table if it exists.\n- Creates a new table with distinct customer and run date pairs from the simulation dataset.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/01_bq_feat.py": "**Load YAML configuration file** (Lines 4-13):\n- Defines a function to load a YAML file.\n- Loads a configuration file and assigns it to a variable.\n\n**Extract BigQuery project dataset prefix** (Lines 14-16):\n- Extracts the BigQuery project dataset prefix from the configuration.\n\n**Create driver_simu_txn_365d table** (Lines 17-40):\n- Drops the existing table if it exists.\n- Creates a new table with transaction data and additional date fields.\n\n**Create driver_simu_txn_365d_agg table** (Lines 43-55):\n- Drops the existing table if it exists.\n- Aggregates transaction data over different time intervals.\n\n**Create driver_consumer_base table** (Lines 58-66):\n- Drops the existing table if it exists.\n- Creates a base table with customer IDs and run dates.\n\n**Create driver_consumer_base_txn_5k_merch_category table** (Lines 69-93):\n- Drops the existing table if it exists.\n- Joins consumer base with transaction data and merchant categories.\n\n**Create driver_consumer_base_last_10_txn table** (Lines 96-175):\n- Drops the existing table if it exists.\n- Aggregates the last 10 transactions for each customer.\n\n**Create driver_consumer_base_all_history_array_0 table** (Lines 178-185):\n- Drops the existing table if it exists.\n- Selects the most recent 100 transactions for each customer.\n\n**Create driver_consumer_base_all_history_array table** (Lines 188-194):\n- Drops the existing table if it exists.\n- Aggregates the most recent 100 transactions into arrays.\n\n**Create driver_combine_category table** (Lines 198-203):\n- Drops the existing table if it exists.\n- Joins driver_simu with merchant categories.\n\n**Create driver_combine_category_agg_0 table** (Lines 206-219):\n- Drops the existing table if it exists.\n- Aggregates transaction data by category over different time intervals.\n\n**Create driver_combine_category_agg_1 table** (Lines 222-231):\n- Drops the existing table if it exists.\n- Aggregates transaction counts over different time intervals.\n\n**Create driver_combine_category_agg_2 table** (Lines 234-257):\n- Drops the existing table if it exists.\n- Combines category aggregates with overall transaction counts.\n\n**Create driver_combine_category_agg_3 table** (Lines 260-286):\n- Drops the existing table if it exists.\n- Combines category aggregates with receiver information.\n\n**Create driver_combine_category_agg_4 table** (Lines 289-302):\n- Drops the existing table if it exists.\n- Ranks categories by transaction frequency.\n\n**Create driver_combine_category_agg_5 table** (Lines 305-464):\n- Drops the existing table if it exists.\n- Joins category frequency ranks with consumer base.\n\n**Create driver_merchant_base table** (Lines 468-476):\n- Drops the existing table if it exists.\n- Creates a base table with receiver IDs and run dates.\n\n**Create driver_merchant_base_txn_30d table** (Lines 479-506):\n- Drops the existing table if it exists.\n- Joins merchant base with transaction data.\n\n**Create driver_merchant_base_txn_30d_filter_sndr table** (Lines 509-523):\n- Drops the existing table if it exists.\n- Filters transactions by sender account type.\n\n**Create driver_merchant_base_price_agg table** (Lines 526-551):\n- Drops the existing table if it exists.\n- Aggregates transaction prices for merchants.\n\n**Create driver_merchant_base_sales_agg table** (Lines 554-566):\n- Drops the existing table if it exists.\n- Aggregates sales data for merchants.\n\n**Create driver_elig_save_365d_category table** (Lines 569-616):\n- Drops the existing table if it exists.\n- Joins consumer base with save events and merchant categories.\n\n**Create driver_elig_save_agg_00 table** (Lines 619-630):\n- Drops the existing table if it exists.\n- Aggregates save events over different time intervals.\n\n**Create driver_elig_save_agg_0 table** (Lines 633-643):\n- Drops the existing table if it exists.\n- Aggregates save events for consumers over different time intervals.\n\n**Create driver_elig_save_agg_1 table** (Lines 646-717):\n- Drops the existing table if it exists.\n- Joins consumer base with recent save events.\n\n**Create driver_elig_save_agg_2 table** (Lines 720-731):\n- Drops the existing table if it exists.\n- Aggregates save events by category over different time intervals.\n\n**Create driver_elig_save_agg_3 table** (Lines 734-751):\n- Drops the existing table if it exists.\n- Joins category save aggregates with consumer base.\n\n**Create driver_merchant_base_click_save table** (Lines 754-793):\n- Drops the existing table if it exists.\n- Aggregates save events for merchants over different placements and segments.\n\n**Create driver_consumer_base_gender table** (Lines 796-817):\n- Drops the existing table if it exists.\n- Joins consumer base with gender prediction data.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/01_varmart_feat.py": "**[Import and authenticate user] (Lines 4-5):**\n- Imports a cloud module and authenticates the user.\n\n**[Set environment variable] (Line 9):**\n- Sets an environment variable to disable a specific development feature.\n\n**[Export data to Google Cloud Storage] (Lines 14-22):**\n- Exports data from a BigQuery table to Google Cloud Storage in Parquet format.\n\n**[Import modules and set up Fetcher] (Lines 23-40):**\n- Imports necessary modules and sets up a Fetcher object with various configurations such as stage, sequence number, job name, group name, model name, model owner, description, and manager.\n\n**[Configure Fetcher for GCP] (Lines 43-49):**\n- Configures the Fetcher object with Google Cloud Platform settings including project ID, bucket name, BigQuery project and dataset, and data locations.\n\n**[Specify variables and split ratio] (Lines 50-63):**\n- Specifies the variables to be fetched and sets the split ratio for training data.\n\n**[Run Fetcher] (Line 67):**\n- Executes the Fetcher to fetch the data based on the provided configurations.\n\n**[Create external table in BigQuery] (Lines 68-73):**\n- Creates or replaces an external table in BigQuery using data stored in Google Cloud Storage in Parquet format.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/02_combine.py": "**[Load YAML configuration file] (Lines 4-13):**\n- Defines a function to load a YAML file.\n- Attempts to read and parse the YAML file, returning its content or None if the file is not found.\n- Loads a specific configuration file into a variable.\n\n**[Extract BigQuery project dataset prefix from configuration] (Lines 14-16):**\n- Checks if the configuration is loaded.\n- Extracts the BigQuery project dataset prefix from the configuration.\n\n**[Create and populate driver_dev_features table] (Lines 17-216):**\n- Constructs a SQL query to drop the existing `driver_dev_features` table if it exists.\n- Creates a new `driver_dev_features` table with a comprehensive SELECT statement.\n- Joins multiple tables to enrich the data with various features, using COALESCE to handle null values.\n\n**[Create and populate driver_oot_features table] (Lines 219-418):**\n- Constructs a SQL query to drop the existing `driver_oot_features` table if it exists.\n- Creates a new `driver_oot_features` table with a comprehensive SELECT statement.\n- Joins multiple tables to enrich the data with various features, using COALESCE to handle null values.\n\n**[Expand sequence features in driver_oot_features_expand_seq table] (Lines 421-624):**\n- Constructs a SQL query to drop the existing `driver_oot_features_expand_seq` table if it exists.\n- Creates a new `driver_oot_features_expand_seq` table by expanding sequence features from `sndr_most_recent_100_merch_list` and `sndr_most_recent_100_merch_category` into individual columns.\n\n**[Export driver_dev_features table to Google Cloud Storage] (Lines 630-639):**\n- Exports the `ql_store_rmr_driver_dev_features` table to Google Cloud Storage in Parquet format.\n- Specifies the URI and format for the export, and ensures the data is overwritten if it already exists.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/03_prepare_training_data.py": "**[Import necessary libraries and modules] (Lines 1-9):**\n- Imports various libraries and modules required for data processing, feature transformation, and machine learning tasks.\n\n**[Set up model versioning and directories] (Lines 10-20):**\n- Defines the model version based on the current date.\n- Creates directories for storing model artifacts if they do not already exist.\n- Saves the current model version to a file.\n\n**[Initialize dictionaries for encoders and scalers] (Lines 21-22):**\n- Initializes empty dictionaries to store categorical feature encoders and numerical feature scalers.\n\n**[Load and concatenate data from parquet files] (Lines 23-30):**\n- Reads all parquet files from a specified directory and concatenates them into a single DataFrame.\n\n**[Map state names to abbreviations] (Lines 31-82):**\n- Defines a dictionary to map full state names to their abbreviations.\n\n**[Clean and encode state feature] (Lines 83-104):**\n- Cleans the state feature by mapping full state names to abbreviations and encoding them using LabelEncoder.\n- Stores the state encodings in a dictionary.\n\n**[Encode categorical features] (Lines 105-112):**\n- Encodes several categorical features using LabelEncoder and stores the encodings in a dictionary.\n\n**[Scale numerical features] (Lines 113-134):**\n- Scales a list of numerical features using StandardScaler and stores the scaling parameters (mean and standard deviation) in a dictionary.\n\n**[Process sequence features] (Lines 135-153):**\n- Processes sequence features by replacing missing values, splitting sequences, and padding them to a fixed length.\n- Tokenizes and pads another sequence feature, then renames the resulting column.\n\n**[Write transformed data to parquet files] (Lines 154-166):**\n- Defines a function to write DataFrame chunks to parquet files.\n- Splits the data into chunks and writes each chunk to a parquet file in a specified output directory.\n\n**[Export feature transformers] (Lines 167-175):**\n- Saves the trained Tokenizer, categorical feature encoders, and numerical feature scalers to files using pickle.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/04_training.py": "**[Import necessary libraries and set up GPU configuration] (Lines 2-14):**\n- Import essential libraries for data processing, machine learning, and model training.\n- Configure TensorFlow to use GPU with memory growth enabled.\n\n**[Load YAML configuration file] (Lines 15-21):**\n- Define a function to load a YAML file and handle file not found errors.\n\n**[Load model version and set up directories] (Lines 22-34):**\n- Load the current model version from a pickle file.\n- Set up directories for saving model artifacts and feature transformers.\n\n**[Load and concatenate parquet files] (Lines 36-43):**\n- List and read all parquet files from a specified directory.\n- Concatenate the data into a single DataFrame.\n\n**[Load feature encoders and tokenizers] (Lines 44-47):**\n- Load categorical feature encoders and receiver ID tokenizer from pickle files.\n\n**[Split data into training and validation sets] (Lines 48-49):**\n- Split the concatenated data into training and validation sets based on a 'split' column.\n\n**[Define feature names] (Lines 52-74):**\n- Define lists of numeric, receiver ID, and categorical feature names.\n\n**[Function to prepare data for model input] (Lines 75-106):**\n- Define a function to create feature columns and prepare data for model input.\n- Return feature columns, feature names, and behavior feature list.\n\n**[Prepare training and validation data] (Lines 107-109):**\n- Prepare training and validation data using the defined function.\n\n**[Data generator function] (Lines 110-120):**\n- Define a generator function to yield batches of data for training.\n\n**[Create training and validation datasets] (Lines 121-137):**\n- Create TensorFlow datasets for training and validation using the data generator function.\n- Shuffle the datasets.\n\n**[Set up distributed training strategy and compile model] (Lines 140-155):**\n- Use TensorFlow's MirroredStrategy for distributed training.\n- Compile the DIN model with specified configurations and Adam optimizer.\n\n**[Early stopping callback and model training] (Lines 156-170):**\n- Define an early stopping callback to monitor validation loss.\n- Train the model using the training and validation datasets.\n\n**[Save trained model in different formats] (Lines 171-175):**\n- Save the trained model in H5 and TensorFlow SavedModel formats.\n\n**[Convert TensorFlow model to ONNX format] (Lines 176-186):**\n- Convert the TensorFlow model to ONNX format and save the ONNX specification.\n\n**[Create and save production model with preprocessing layers] (Lines 196-227):**\n- Define functions to check ASCII encoding and filter categorical feature encoders.\n- Create a graph for the production model with preprocessing layers.\n- Save the production model.\n\n**[Prepare test data and make predictions] (Lines 230-239):**\n- Prepare test data for prediction.\n- Make predictions using the production model.\n\n**[Save test data to JSON file] (Lines 240-248):**\n- Save the test data to a JSON file for future use.\n\n**[Convert and test ONNX model] (Lines 250-267):**\n- Convert the saved TensorFlow model to ONNX format.\n- Test the ONNX model by comparing predictions with the TensorFlow model.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/05_scoring_oot.py": "**[Setup and configuration] (Lines 2-24):**\n- Imports necessary modules and libraries.\n- Sets the working directory and user environment.\n- Loads configuration settings and model version information.\n\n**[Define scoring function] (Lines 26-48):**\n- Defines a function `oot_data_eval` to evaluate out-of-time (OOT) data.\n- Loads OOT data and model files.\n- Scores the data using the loaded models.\n- Saves the scored data to a specified path.\n\n**[Model and data paths setup] (Lines 49-53):**\n- Sets local and GCP paths for model and data storage.\n- Defines paths for OOT data and evaluation results.\n\n**[Model specification and scoring setup] (Lines 54-69):**\n- Loads model specifications and prepares a list of model paths and score outputs.\n- Appends model paths to a list for GCP processing.\n\n**[Submit Spark job to GCP] (Lines 70-86):**\n- Configures and submits a Spark job to GCP for scoring the OOT data.\n- Specifies the function to run, packages to install, and other job parameters.\n\n**[Job status and logging] (Lines 87-94):**\n- Checks the status of the submitted job and waits for its completion.\n- Saves the job log to a specified file.\n\n**[Create external table in BigQuery] (Lines 99-104):**\n- Creates or replaces an external table in BigQuery using the scored data stored in GCS.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/06_evaluation.py": "**Load model version and set up directories (Lines 4-12):**\n- Loads the current model version from a file.\n- Sets up paths for model artifacts and evaluation readouts.\n- Creates the evaluation readout directory if it doesn't exist.\n\n**Load configuration from YAML file (Lines 13-25):**\n- Defines a function to load YAML files.\n- Loads the base configuration from a specified YAML file.\n- Extracts the BigQuery project dataset prefix from the configuration.\n\n**Create driver_oot_txn_365d table (Lines 26-46):**\n- Drops the existing `driver_oot_txn_365d` table if it exists.\n- Creates a new `driver_oot_txn_365d` table by joining `driver_oot` with transaction data to get the last purchase timestamp.\n\n**Create driver_oot_txn_save_365d table (Lines 47-67):**\n- Drops the existing `driver_oot_txn_save_365d` table if it exists.\n- Creates a new `driver_oot_txn_save_365d` table by joining `driver_oot_txn_365d` with save event data to get the last save date.\n\n**Create mlv2_gpt_similar_map_snapshot table (Lines 68-139):**\n- Drops the existing `mlv2_gpt_similar_map_snapshot` table if it exists.\n- Creates a new `mlv2_gpt_similar_map_snapshot` table by joining similar merchant map data with live unique merchants.\n\n**Create mlv2_gpt_similar_map_snapshot_1 table (Lines 140-195):**\n- Drops the existing `mlv2_gpt_similar_map_snapshot_1` table if it exists.\n- Creates a new `mlv2_gpt_similar_map_snapshot_1` table by concatenating and splitting similar merchant IDs into separate columns.\n\n**Create driver_oot_txn_save_365d_similar table (Lines 196-208):**\n- Drops the existing `driver_oot_txn_save_365d_similar` table if it exists.\n- Creates a new `driver_oot_txn_save_365d_similar` table by joining `driver_oot_txn_save_365d` with `mlv2_gpt_similar_map_snapshot_1` to get similar merchants.\n\n**Create driver_oot_txn_save_365d_similar_dedup table (Lines 209-248):**\n- Drops the existing `driver_oot_txn_save_365d_similar_dedup` table if it exists.\n- Creates a new `driver_oot_txn_save_365d_similar_dedup` table by deduplicating similar merchants and ranking them.\n\n**Create driver_oot_two_tower_similar_score table (Lines 249-337):**\n- Drops the existing `driver_oot_two_tower_similar_score` table if it exists.\n- Creates a new `driver_oot_two_tower_similar_score` table by calculating dot product scores between customer and merchant embeddings.\n\n**Create driver_oot_hueristic_model_comparison table (Lines 338-373):**\n- Drops the existing `driver_oot_hueristic_model_comparison` table if it exists.\n- Creates a new `driver_oot_hueristic_model_comparison` table by comparing heuristic model scores and ranks.\n\n**Calculate recall metrics and save performance data (Lines 375-446):**\n- Calculates recall metrics for different models and saves the results to a CSV file.\n- Plots the performance metrics and saves the plot as an image.\n\n**Calculate recall metrics for specific merchant category and save performance data (Lines 448-530):**\n- Calculates recall metrics for different models for a specific merchant category and saves the results to a CSV file.\n- Plots the performance metrics and saves the plot as an image.\n\n**Calculate recall metrics excluding specific merchants and save performance data (Lines 531-607):**\n- Calculates recall metrics for different models excluding specific merchants and saves the results to a CSV file.\n- Plots the performance metrics and saves the plot as an image.\n\n**Calculate recall metrics for recent data and save performance data (Lines 608-731):**\n- Calculates recall metrics for different models for recent data and saves the results to a CSV file.\n- Plots the performance metrics and saves the plot as an image."
=======
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/00_driver.py": "**Load YAML configuration file** (Lines 4-13):\n- Defines a function to load a YAML file.\n- Attempts to load the configuration from a specified file path.\n- Returns the loaded configuration or None if the file is not found.\n\n**Extract BigQuery project dataset prefix** (Lines 14-16):\n- Extracts the BigQuery project dataset prefix from the loaded configuration.\n\n**Create live unique merchants training table** (Lines 18-52):\n- Drops the existing table if it exists.\n- Creates a new table with unique merchants by joining multiple tables and applying filters.\n\n**Create driver_00 table** (Lines 54-82):\n- Drops the existing table if it exists.\n- Creates a new table with various customer and merchant attributes, applying specific filters and conditions.\n\n**Create driver_0 table** (Lines 84-103):\n- Drops the existing table if it exists.\n- Creates a new table by filtering customers based on the number of distinct placements and specific conditions.\n\n**Create driver_1 table** (Lines 105-121):\n- Drops the existing table if it exists.\n- Creates a new table with transaction details for specific customers and merchants.\n\n**Create driver_positive_train_attributed table** (Lines 124-168):\n- Drops the existing table if it exists.\n- Creates a new table with positive samples for training, applying various sampling and filtering techniques.\n\n**Create driver_positive_train_organic_0 table** (Lines 170-204):\n- Drops the existing table if it exists.\n- Creates a new table with organic positive samples, applying multiple filters to remove biases.\n\n**Create driver_positive_train_organic table** (Lines 207-244):\n- Drops the existing table if it exists.\n- Creates a new table with sampled organic positive transactions, applying specific sampling ratios.\n\n**Create driver_positive table** (Lines 247-277):\n- Drops the existing table if it exists.\n- Combines multiple positive sample tables into one, including attributed transactions, saves, and organic transactions.\n\n**Create driver_positive_training_split_0 table** (Lines 281-308):\n- Drops the existing table if it exists.\n- Creates a new table with positive samples, marking them as hard or uniform negatives based on specific conditions.\n\n**Create driver_positive_training_split table** (Lines 310-322):\n- Drops the existing table if it exists.\n- Adds a count of positive samples per day to the training split table.\n\n**Create driver_training_hard_negative table** (Lines 324-336):\n- Drops the existing table if it exists.\n- Creates a new table with hard negative samples by joining with the driver_0 table.\n\n**Create driver_training_hard_negative_downsample table** (Lines 339-349):\n- Drops the existing table if it exists.\n- Downsamples hard negative samples based on specific conditions.\n\n**Create driver_training_uniform_negative table** (Lines 352-364):\n- Drops the existing table if it exists.\n- Creates a new table with uniform negative samples by joining with the live unique merchants table.\n\n**Create driver_training_uniform_negative_remove_window_positive table** (Lines 367-376):\n- Drops the existing table if it exists.\n- Removes uniform negative samples that overlap with positive feedback within a specific time window.\n\n**Create driver_training_uniform_negative_downsample_0 table** (Lines 379-401):\n- Drops the existing table if it exists.\n- Downsamples uniform negative samples based on merchant sampling probabilities.\n\n**Create driver_training_uniform_negative_downsample table** (Lines 404-408):\n- Drops the existing table if it exists.\n- Further downsamples uniform negative samples based on a specified ratio.\n\n**Create driver_dev table** (Lines 410-445):\n- Drops the existing table if it exists.\n- Combines positive and negative samples into a development table, marking targets and splits.\n\n**Create driver_oot_uniform_negative_0 table** (Lines 449-469):\n- Drops the existing table if it exists.\n- Creates a new table with out-of-time (OOT) uniform negative samples.\n\n**Create driver_oot_uniform_negative table** (Lines 472-478):\n- Drops the existing table if it exists.\n- Removes duplicate OOT uniform negative samples.\n\n**Create driver_oot table** (Lines 481-495):\n- Drops the existing table if it exists.\n- Combines positive and negative OOT samples into one table.\n\n**Create driver_simu table** (Lines 498-507):\n- Drops the existing table if it exists.\n- Combines distinct customer and receiver pairs from development and OOT tables.\n\n**Create driver_simu_consumer table** (Lines 509-512):\n- Drops the existing table if it exists.\n- Creates a table with distinct customers and run dates from the simulation table.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/01_bq_feat.py": "**Load YAML configuration file (Lines 4-13):**\n- Defines a function to load a YAML file.\n- Loads a configuration file and assigns it to a variable.\n\n**Extract BigQuery project dataset prefix (Lines 14-16):**\n- Extracts the BigQuery project dataset prefix from the loaded configuration.\n\n**Create driver_simu_txn_365d table (Lines 17-40):**\n- Drops the existing table if it exists.\n- Creates a new table with transaction data joined with payment data, including various date intervals.\n\n**Create driver_simu_txn_365d_agg table (Lines 43-55):**\n- Drops the existing table if it exists.\n- Creates a new aggregated table with transaction counts and amounts over different time intervals.\n\n**Create driver_consumer_base table (Lines 58-66):**\n- Drops the existing table if it exists.\n- Creates a new table with consumer base data including various date intervals.\n\n**Create driver_consumer_base_txn_5k_merch_category table (Lines 69-93):**\n- Drops the existing table if it exists.\n- Creates a new table with consumer base transaction data joined with merchant category data.\n\n**Create driver_consumer_base_last_10_txn table (Lines 96-175):**\n- Drops the existing table if it exists.\n- Creates a new table with the last 10 transactions for each consumer, including average transaction amounts.\n\n**Create driver_consumer_base_all_history_array_0 table (Lines 178-185):**\n- Drops the existing table if it exists.\n- Creates a new table with the most recent 100 transactions for each consumer.\n\n**Create driver_consumer_base_all_history_array table (Lines 188-194):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated lists of the most recent 100 merchants and categories for each consumer.\n\n**Create driver_combine_category table (Lines 198-203):**\n- Drops the existing table if it exists.\n- Creates a new table combining driver simulation data with merchant category data.\n\n**Create driver_combine_category_agg_0 table (Lines 206-219):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated transaction data by category over different time intervals.\n\n**Create driver_combine_category_agg_1 table (Lines 222-231):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated transaction counts over different time intervals.\n\n**Create driver_combine_category_agg_2 table (Lines 234-257):**\n- Drops the existing table if it exists.\n- Creates a new table with average transaction amounts by category over different time intervals.\n\n**Create driver_combine_category_agg_3 table (Lines 260-286):**\n- Drops the existing table if it exists.\n- Creates a new table combining consumer and category transaction data with aggregated category data.\n\n**Create driver_combine_category_agg_4 table (Lines 289-302):**\n- Drops the existing table if it exists.\n- Creates a new table with transaction frequency ranks by category over different time intervals.\n\n**Create driver_combine_category_agg_5 table (Lines 305-464):**\n- Drops the existing table if it exists.\n- Creates a new table with the top 3 frequent merchant categories over different time intervals.\n\n**Create driver_merchant_base table (Lines 468-476):**\n- Drops the existing table if it exists.\n- Creates a new table with merchant base data including a 30-day interval.\n\n**Create driver_merchant_base_txn_30d table (Lines 479-506):**\n- Drops the existing table if it exists.\n- Creates a new table with merchant transaction data over the last 30 days.\n\n**Create driver_merchant_base_txn_30d_filter_sndr table (Lines 509-523):**\n- Drops the existing table if it exists.\n- Creates a new table filtering merchant transactions by sender account type.\n\n**Create driver_merchant_base_price_agg table (Lines 526-551):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated price statistics for merchants over the last 30 days.\n\n**Create driver_merchant_base_sales_agg table (Lines 554-566):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated sales statistics for merchants over the last 30 days.\n\n**Create driver_elig_save_365d_category table (Lines 569-616):**\n- Drops the existing table if it exists.\n- Creates a new table with consumer save event data joined with merchant category data.\n\n**Create driver_elig_save_agg_00 table (Lines 619-630):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated save counts over different time intervals.\n\n**Create driver_elig_save_agg_0 table (Lines 633-643):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated save counts for consumers over different time intervals.\n\n**Create driver_elig_save_agg_1 table (Lines 646-717):**\n- Drops the existing table if it exists.\n- Creates a new table with the last 5 save events for each consumer.\n\n**Create driver_elig_save_agg_2 table (Lines 720-731):**\n- Drops the existing table if it exists.\n- Creates a new table with aggregated save counts by category over different time intervals.\n\n**Create driver_elig_save_agg_3 table (Lines 734-751):**\n- Drops the existing table if it exists.\n- Creates a new table combining consumer and category save data with aggregated save data.\n\n**Create driver_merchant_base_click_save table (Lines 754-793):**\n- Drops the existing table if it exists.\n- Creates a new table with merchant save event statistics over the last 30 days.\n\n**Create driver_consumer_base_gender table (Lines 796-817):**\n- Drops the existing table if it exists.\n- Creates a new table with consumer gender information based on first name predictions.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/01_varmart_feat.py": "**[Authenticate user and set environment variables] (Lines 4-9):**\n- Imports necessary modules and authenticates the user.\n- Sets an environment variable to disable a specific development feature.\n\n**[Export data to Google Cloud Storage] (Lines 13-22):**\n- Exports data from a BigQuery table to Google Cloud Storage in Parquet format.\n\n**[Initialize Fetcher object with configurations] (Lines 23-66):**\n- Imports additional modules and sets up date, user, and job-related variables.\n- Initializes a Fetcher object with specific configurations for the job, including GCP settings, data locations, and variables to fetch.\n- Specifies the split ratio for the data.\n\n**[Run the Fetcher] (Line 67):**\n- Executes the Fetcher to fetch the data based on the provided configurations.\n\n**[Create or replace external table in BigQuery] (Lines 68-73):**\n- Creates or replaces an external table in BigQuery, pointing to the Parquet files stored in Google Cloud Storage.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/02_combine.py": "**[Load YAML configuration file] (Lines 4-13):**\n- Defines a function to load a YAML file.\n- Attempts to load a configuration file and assigns its content to a variable.\n\n**[Extract BigQuery project dataset prefix from configuration] (Lines 14-16):**\n- Checks if the configuration is loaded successfully.\n- Extracts the BigQuery project dataset prefix from the configuration.\n\n**[Create driver_dev_features table in BigQuery] (Lines 17-216):**\n- Constructs a SQL query to drop and create a new table `driver_dev_features`.\n- Selects various features from multiple joined tables, applying COALESCE to handle null values.\n\n**[Create driver_oot_features table in BigQuery] (Lines 219-418):**\n- Constructs a SQL query to drop and create a new table `driver_oot_features`.\n- Similar to the previous block, selects features from multiple joined tables with COALESCE for null values.\n\n**[Expand sequence features in driver_oot_features_expand_seq table] (Lines 421-624):**\n- Constructs a SQL query to drop and create a new table `driver_oot_features_expand_seq`.\n- Splits a comma-separated list into multiple columns, handling null values with IFNULL.\n\n**[Export data to Google Cloud Storage in Parquet format] (Lines 630-639):**\n- Constructs a SQL query to export data from a BigQuery table to Google Cloud Storage in Parquet format.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/03_prepare_training_data.py": "**[Setup and initialization] (Lines 1-20):**\n- Imports necessary libraries and modules.\n- Sets up the model version and directories for saving artifacts.\n- Saves the current model version using pickle.\n\n**[Load and concatenate data] (Lines 21-30):**\n- Lists all parquet files in the specified directory.\n- Reads each parquet file into a DataFrame and concatenates them into a single DataFrame.\n\n**[State abbreviation mapping] (Lines 31-94):**\n- Creates a dictionary to map state names to their abbreviations.\n- Defines a function to clean state names and applies it to the DataFrame.\n\n**[Encode categorical features] (Lines 95-112):**\n- Encodes the 'sndr_prmry_addr_state' column using LabelEncoder and saves the encoder.\n- Encodes other specified categorical features and saves their encoders.\n\n**[Scale numerical features] (Lines 113-134):**\n- Lists numerical features to be scaled.\n- Scales each numerical feature using StandardScaler and saves the scaler parameters.\n\n**[Process sequence features] (Lines 135-153):**\n- Processes 'sndr_most_recent_100_merch_category' and 'sndr_most_recent_100_merch_list' columns to create padded sequences.\n- Tokenizes 'sndr_most_recent_100_merch_list' and creates padded sequences.\n- Drops the original sequence columns from the DataFrame.\n\n**[Save transformed data and encoders] (Lines 154-175):**\n- Defines a function to write DataFrame chunks to parquet files.\n- Splits the DataFrame into chunks and writes each chunk to parquet files.\n- Saves the tokenizer and feature encoders using pickle.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/04_training.py": "**[Import necessary libraries and modules] (Lines 2-11):**\n- Import essential libraries and modules such as TensorFlow, pandas, numpy, and deepctr.\n\n**[Configure GPU settings] (Lines 12-14):**\n- List available GPUs and set memory growth to true for each GPU.\n\n**[Load YAML configuration file] (Lines 15-23):**\n- Define a function to load a YAML file and load the configuration from a specified path.\n\n**[Load model version and create directories] (Lines 24-34):**\n- Load the current model version from a pickle file and create necessary directories for storing model artifacts.\n\n**[Load and concatenate parquet files] (Lines 36-43):**\n- List all parquet files in a specified directory, read them into pandas DataFrames, and concatenate them into a single DataFrame.\n\n**[Load feature encoders and tokenizers] (Lines 44-47):**\n- Load categorical feature encoders and a tokenizer for receiver IDs from pickle files.\n\n**[Split data into training and validation sets] (Lines 48-49):**\n- Split the concatenated data into training and validation sets based on a 'split' column.\n\n**[Define numeric, receiver ID, and categorical feature names] (Lines 52-74):**\n- Define lists of numeric feature names, receiver ID names, and categorical feature names.\n\n**[Define function to prepare input features and labels] (Lines 75-106):**\n- Define a function to prepare input features and labels for the model, including creating feature columns and extracting feature names.\n\n**[Prepare training and validation data] (Lines 107-109):**\n- Prepare training and validation data using the defined function.\n\n**[Define data generator function] (Lines 110-120):**\n- Define a generator function to yield batches of data for training and validation.\n\n**[Create training and validation datasets] (Lines 121-137):**\n- Create TensorFlow datasets for training and validation using the data generator function.\n\n**[Define and compile the model] (Lines 140-155):**\n- Define and compile the DIN model within a distributed strategy scope, using parameters from the configuration file.\n\n**[Set up early stopping callback and train the model] (Lines 156-170):**\n- Set up an early stopping callback and train the model using the training and validation datasets.\n\n**[Save the trained model] (Lines 171-175):**\n- Save the trained model in both H5 and TensorFlow SavedModel formats.\n\n**[Convert TensorFlow model to ONNX format] (Lines 176-186):**\n- Convert the TensorFlow model to ONNX format and save the ONNX specification.\n\n**[Create directories for out-of-time scoring] (Lines 188-189):**\n- Create directories for out-of-time scoring if they do not exist.\n\n**[Filter non-ASCII keys in categorical encoders] (Lines 196-204):**\n- Filter out non-ASCII keys from categorical feature encoders.\n\n**[Load numerical feature scalars] (Lines 205-206):**\n- Load numerical feature scalars from a pickle file.\n\n**[Build ONNX graph and save the model] (Lines 207-227):**\n- Build an ONNX graph using the model and feature transformations, then save the final ONNX model.\n\n**[Prepare test data and make predictions] (Lines 230-239):**\n- Prepare test data and make predictions using the final model.\n\n**[Save test data to JSON file] (Lines 240-248):**\n- Save the prepared test data to a JSON file.\n\n**[Convert TensorFlow model to ONNX format using tf2onnx] (Lines 251-253):**\n- Convert the TensorFlow model to ONNX format using the tf2onnx library.\n\n**[Run inference with ONNX model] (Lines 254-268):**\n- Load the ONNX model and run inference, comparing results with the TensorFlow model to ensure consistency.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/05_scoring_oot.py": "**[Set up environment and configuration] (Lines 2-24):**\n- Import necessary libraries and modules.\n- Set working directory and user-specific paths.\n- Load configuration settings.\n- Load the current model version from a pickle file.\n\n**[Define function for out-of-time (OOT) data evaluation] (Lines 26-48):**\n- Define a function `oot_data_eval` to score OOT data using specified models.\n- Load OOT data from a specified path.\n- Copy model files from Google Cloud Storage (GCS) to a local temporary directory.\n- Initialize a model scorer and generate evaluation scores.\n- Optionally select specific columns to keep in the output.\n- Save the scored data to a specified path in parquet format.\n\n**[Prepare model paths and scoring lists] (Lines 49-69):**\n- Define local and GCS paths for model files and OOT data.\n- Load model specifications and prepare lists of model paths and scoring outputs.\n\n**[Submit Spark job to Google Cloud Platform (GCP)] (Lines 71-86):**\n- Initialize a GCP client for submitting Spark jobs.\n- Create and submit a Spark job to run the `oot_data_eval` function on GCP.\n- Specify necessary packages, billing tags, and function arguments.\n\n**[Monitor job status and save logs] (Lines 87-94):**\n- Wait for the Spark job to complete and monitor its status.\n- Save the job logs to a local file for future reference.\n\n**[Create external table in BigQuery] (Lines 100-104):**\n- Create or replace an external table in BigQuery to reference the scored OOT data stored in GCS.",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/06_evaluation.py": "**Load model version and create directories if not exist (Lines 4-12):**\n- Loads the current model version from a file.\n- Constructs paths for storing evaluation readouts.\n- Creates the directory for evaluation readouts if it does not exist.\n\n**Load configuration from YAML file (Lines 13-25):**\n- Defines a function to load YAML files.\n- Loads configuration settings from a specified YAML file.\n- Extracts the BigQuery project dataset prefix from the configuration.\n\n**Create BigQuery table for transactions (Lines 26-46):**\n- Constructs a SQL query to create a BigQuery table for transactions within the last 365 days.\n- Joins transaction data with customer data to get the last purchase timestamp.\n\n**Create BigQuery table for saved transactions (Lines 47-67):**\n- Constructs a SQL query to create a BigQuery table for saved transactions within the last 365 days.\n- Joins transaction data with offer data to get the last save date.\n\n**Create BigQuery table for similar merchant mappings (Lines 68-137):**\n- Constructs a SQL query to create a BigQuery table for similar merchant mappings.\n- Joins merchant data to get the top 20 similar merchants for each receiver ID.\n\n**Create BigQuery table for concatenated similar merchants (Lines 140-194):**\n- Constructs a SQL query to create a BigQuery table with concatenated similar merchants.\n- Splits the concatenated list into individual similar merchant columns.\n\n**Create BigQuery table for transactions with similar merchants (Lines 196-208):**\n- Constructs a SQL query to create a BigQuery table for transactions with similar merchants.\n- Joins transaction data with similar merchant data.\n\n**Create BigQuery table for deduplicated similar merchants (Lines 209-247):**\n- Constructs a SQL query to create a BigQuery table for deduplicated similar merchants.\n- Aggregates and deduplicates similar merchants for each customer and run date.\n\n**Create BigQuery table for two-tower model scores (Lines 249-336):**\n- Constructs a SQL query to create a BigQuery table for two-tower model scores.\n- Joins customer and merchant embeddings to calculate dot product scores.\n\n**Create BigQuery table for heuristic model comparison (Lines 339-373):**\n- Constructs a SQL query to create a BigQuery table for heuristic model comparison.\n- Joins various model scores and ranks them for each customer and run date.\n\n**Calculate recall metrics for all models (Lines 375-430):**\n- Constructs a SQL query to calculate recall metrics for different models.\n- Aggregates recall metrics for various transaction types and ranks.\n\n**Save recall metrics to CSV and plot (Lines 432-447):**\n- Saves the recall metrics to a CSV file.\n- Plots the recall metrics using seaborn and saves the plot as an image.\n\n**Calculate recall metrics for first-time users (Lines 448-530):**\n- Constructs a SQL query to calculate recall metrics for first-time users.\n- Aggregates recall metrics for various transaction types and ranks.\n- Saves the recall metrics to a CSV file and plots them.\n\n**Calculate recall metrics excluding specific merchants (Lines 531-607):**\n- Constructs a SQL query to calculate recall metrics excluding specific merchants.\n- Aggregates recall metrics for various transaction types and ranks.\n- Saves the recall metrics to a CSV file and plots them.\n\n**Calculate recall metrics for recent transactions (Lines 608-731):**\n- Constructs a SQL query to calculate recall metrics for recent transactions.\n- Aggregates recall metrics for various transaction types and ranks.\n- Saves the recall metrics to a CSV file."
>>>>>>> origin/main
  },
  "cleaned_code": {
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/00_driver.py": "   1 | # %reload_ext cloudmagics.bigquery\n   2 | # %config PPMagics.domain=\"ccg24-hrzana-gds-pacman\"\n   3 | # %config PPMagics.autolimit = 0\n   4 | import yaml\n   5 | def load_yaml_file(file_path):\n   6 |     try:\n   7 |         with open(file_path, 'r') as file:\n   8 |             yaml_content = yaml.safe_load(file)\n   9 |         return yaml_content\n  10 |     except FileNotFoundError:\n  11 |         return None\n  12 | file_path = '../config/base_config.yaml'\n  13 | config = load_yaml_file(file_path)\n  14 | if config is not None:\n  15 | bq_prefix = config['general_config']['bq_project_dataset_prefix']\n  16 | bq_prefix\n  17 | ## eligible merchants\n  18 | q = f\"\"\"\n  19 | DROP TABLE IF EXISTS {bq_prefix}live_unique_merchants_train;\n  20 | CREATE TABLE {bq_prefix}live_unique_merchants_train AS\n  21 | WITH\n  22 |   stores_paypalMerchant_raw AS (\n  23 |   SELECT\n  24 |     storeid,\n  25 |     encryptedid\n  26 |   FROM\n  27 |     pypl-edl.honey_raw_tables.stores_paypalMerchant_raw\n  28 |   QUALIFY\n  29 |     ROW_NUMBER() OVER (PARTITION BY storeid ORDER BY last_ingestion_utc_time DESC)=1 )\n  30 | SELECT\n  31 |   a.store_id AS honey_store_id,\n  32 |   a.name AS honey_store_name,\n  33 |   CAST(SUBSTR(a.max_cash_back, 1, LENGTH(a.max_cash_back) - 1) AS FLOAT64) AS cashback_percent,\n  34 |   b.encryptedid AS encrypt_id,\n  35 |   c.customer_id AS rcvr_id,\n  36 |   COALESCE(d.gpt_1st_category_l2_index,0) AS gpt_1st_category_l2_index\n  37 | FROM\n  38 |   honey-production.aoi.live_unique_merchants a\n  39 | JOIN\n  40 |   stores_paypalMerchant_raw b\n  41 | ON\n  42 |   a.store_id = b.storeid\n  43 | JOIN\n  44 |   pypl-edw.pp_access_views.dw_customer_map c\n  45 | ON\n  46 |   b.encryptedid = c.dienc13i6_id\n  47 | LEFT JOIN\n  48 |   pypl-bods.gds_pacman_prod.ql_store_rmr_merchant_info d\n  49 | ON\n  50 |   b.encryptedid = d.encrypt_id\n  51 | where rcvr_id not in ({config['driver_config']['training_exclude_merch']})\n  52 | \"\"\"\n  53 | # %ppbq $q\n  54 | q=f\"\"\"\n  55 | drop table if exists {bq_prefix}driver_00 ;\n  56 | create table {bq_prefix}driver_00 as\n  57 | SELECT\n  58 | cust_id,\n  59 | b.rcvr_id,\n  60 | a.evnt_dt-1 as run_date,\n  61 | a.placement,\n  62 | a.client_os,\n  63 | a.devc_type,\n  64 | a.rfmbc_seg,\n  65 | a.consu_dmgrphc_seg,\n  66 | a.consu_age_band,\n  67 | a.consu_inc_band,\n  68 | case when coalesce(saves_clk_unique_cnt,0)+coalesce(saves_outclick_unique_cnt,0)+coalesce(saves_save_unique_cnt,0)>0 then 1 else 0 end as save,\n  69 | case when coalesce(saves_leap_txns,0)+coalesce(saves_left_aft_txn,0)>0 then 1 else 0 end as leap_aft_txn,\n  70 | b.gpt_1st_category_l2_index,\n  71 | b.honey_store_name\n  72 | from pypl-edw.pp_scratch.tmp_offers_output_dedup_archive a\n  73 | JOIN {bq_prefix}live_unique_merchants_train b\n  74 | on a.pp_merchant_id=b.encrypt_id\n  75 | where evnt_dt >= {config['driver_config']['train_start_date']}\n  76 | and placement in ('deals_explore_tertiary','ql_home','rewards_zone_new','reboarding')\n  77 | and cust_id is not null\n  78 | and cust_id<>'na'\n  79 | and cust_id<>'no_cust_id'\n  80 | and pp_merchant_id is not null\n  81 | and saves_imp_unique_cnt>0;\n  82 | \"\"\"\n  83 | # %ppbq $q\n  84 | q=f\"\"\"drop table if exists {bq_prefix}driver_0 ;\n  85 | create table {bq_prefix}driver_0 as\n  86 | with temp as (\n  87 |     select cust_id,count(distinct placement) as cnt_placement\n  88 |     from {bq_prefix}driver_00\n  89 |     group by 1\n  90 | )\n  91 | select * from {bq_prefix}driver_00\n  92 | where cust_id in (\n  93 |     select distinct cust_id from temp\n  94 |     where cnt_placement>1\n  95 | )\n  96 | union all\n  97 | select * from {bq_prefix}driver_00\n  98 | where cust_id in (\n  99 |     select distinct cust_id from temp\n 100 |     where cnt_placement=1\n 101 | )\n 102 | and (save>0 or leap_aft_txn>0);\n 103 | \"\"\"\n 104 | # %ppbq $q\n 105 | q=f\"\"\"drop table if exists {bq_prefix}driver_1;\n 106 | create table {bq_prefix}driver_1 as\n 107 | SELECT \n 108 | a.payment_transid,\n 109 | a.tran_customer_id as cust_id,\n 110 | a.customer_counterparty as rcvr_id,\n 111 | a.transaction_created_date-1 as run_date,\n 112 | b.gpt_1st_category_l2_index,\n 113 | b.honey_store_name\n 114 | FROM pypl-edw.pp_access_views.dw_payment_sent a\n 115 | JOIN {bq_prefix}live_unique_merchants_train b\n 116 | on a.customer_counterparty=b.rcvr_id\n 117 | where tran_customer_id in (select distinct cust_id from {bq_prefix}driver_0)\n 118 | and customer_counterparty in (select distinct rcvr_id from {bq_prefix}live_unique_merchants_train)\n 119 | and transaction_created_date >= {config['driver_config']['train_start_date']}\n 120 | and transaction_status='S';\n 121 | \"\"\"\n 122 | # %ppbq $q\n 123 | # # Positive Samples\n 124 | q=f\"\"\"drop table if exists {bq_prefix}driver_positive_train_attributed;\n 125 | create table {bq_prefix}driver_positive_train_attributed as\n 126 | WITH t1 as (\n 127 |         SELECT * FROM {bq_prefix}driver_0\n 128 |         WHERE leap_aft_txn>0\n 129 |         AND run_date<{config['driver_config']['oot_start_date']}),\n 130 |     t2 as (\n 131 |         SELECT count(*) as total_cnt\n 132 |         FROM {bq_prefix}driver_0\n 133 |         WHERE leap_aft_txn>0\n 134 |         AND run_date<{config['driver_config']['oot_start_date']}\n 135 |     ),\n 136 |     t3 as (\n 137 |         SELECT rcvr_id,count(*) as cnt\n 138 |         FROM {bq_prefix}driver_0\n 139 |         WHERE leap_aft_txn>0\n 140 |         AND run_date<{config['driver_config']['oot_start_date']}\n 141 |         GROUP BY 1\n 142 |     ),\n 143 |     t4 as (\n 144 |         SELECT \n 145 |         t3.rcvr_id,\n 146 |         t3.cnt/t2.total_cnt as merchant_ratio,\n 147 |         (SQRT(t3.cnt/t2.total_cnt/{config['driver_config']['training_hot_positive_attributed_txn_sampling_alpha']})+1)*{config['driver_config']['training_hot_positive_attributed_txn_sampling_alpha']}*t2.total_cnt/t3.cnt as merchant_sampling_ratio\n 148 |         FROM t3\n 149 |         JOIN t2\n 150 |         ON 1=1\n 151 |     ),\n 152 |     t5 as (\n 153 |         SELECT t1.*,t4,merchant_ratio,t4.merchant_sampling_ratio\n 154 |         FROM t1\n 155 |         JOIN t4\n 156 |         ON t1.rcvr_id=t4.rcvr_id\n 157 |     ),\n 158 |     t6 as (\n 159 |         SELECT *\n 160 |         FROM t5\n 161 |         WHERE RAND()<=merchant_sampling_ratio\n 162 |     )\n 163 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,merchant_ratio,merchant_sampling_ratio,\n 164 | 'attributed_txn' as pos_tag_type, \n 165 | case when run_date<{config['driver_config']['val_start_date']} then 'train' else 'val' end as split\n 166 | FROM t6\n 167 | CROSS JOIN UNNEST(GENERATE_ARRAY(1,{config['driver_config']['training_attributed_txn_upsampling_rate']})) AS repeat\n 168 | \"\"\"\n 169 | # %ppbq $q\n 170 | q=f\"\"\"drop table if exists {bq_prefix}driver_positive_train_organic_0;\n 171 | create table {bq_prefix}driver_positive_train_organic_0 as\n 172 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index\n 173 | FROM {bq_prefix}driver_1\n 174 | WHERE CONCAT(cust_id,rcvr_id) not in (\n 175 |         select distinct concat(cust_id,rcvr_id) from {bq_prefix}driver_0 where leap_aft_txn>0\n 176 |     )\n 177 | AND CONCAT(cust_id,rcvr_id) not in (\n 178 |         select distinct concat(cust_id,rcvr_id) from {bq_prefix}driver_0 where save>0\n 179 |     )\n 180 | AND run_date<{config['driver_config']['oot_start_date']}\n 181 | AND cust_id in (\n 182 |     SELECT distinct cust_id from (\n 183 |         SELECT cust_id,count(distinct payment_transid)\n 184 |         FROM {bq_prefix}driver_1\n 185 |         GROUP BY 1\n 186 |         HAVING count(distinct payment_transid)<{config['driver_config']['removing_highly_active_user_threshold']} -- remove highly active user's bias\n 187 |         )\n 188 | )\n 189 | AND concat(cust_id,rcvr_id) in (\n 190 |     SELECT concat(cust_id,rcvr_id) from (\n 191 |         SELECT cust_id,rcvr_id,count(distinct payment_transid)\n 192 |         FROM {bq_prefix}driver_1\n 193 |         GROUP BY 1,2\n 194 |         HAVING count(distinct payment_transid)<{config['driver_config']['removing_highly_active_user_merchant_threshold']} -- remove highly active user-merchant pairs bias\n 195 |         )\n 196 | )\n 197 | AND concat(cust_id,rcvr_id,run_date) in (\n 198 |     SELECT concat(cust_id,rcvr_id,run_date) from (\n 199 |         SELECT cust_id,rcvr_id,run_date,count(distinct payment_transid)\n 200 |         FROM {bq_prefix}driver_1\n 201 |         GROUP BY 1,2,3\n 202 |         HAVING count(distinct payment_transid)<{config['driver_config']['removing_highly_active_user_merchant_date_threshold']} -- remove highly active user-merchant-date bias\n 203 |         )\n 204 | );\n 205 | \"\"\"\n 206 | # %ppbq $q\n 207 | q=f\"\"\"drop table if exists {bq_prefix}driver_positive_train_organic;\n 208 | create table {bq_prefix}driver_positive_train_organic as\n 209 | WITH t1 as (\n 210 |         SELECT * \n 211 |         FROM {bq_prefix}driver_positive_train_organic_0),\n 212 |     t2 as (\n 213 |         SELECT count(*) as total_cnt\n 214 |         FROM {bq_prefix}driver_positive_train_organic_0\n 215 |     ),\n 216 |     t3 as (\n 217 |         SELECT rcvr_id,count(*) as cnt\n 218 |         FROM {bq_prefix}driver_positive_train_organic_0\n 219 |         GROUP BY 1\n 220 |     ),\n 221 |     t4 as (\n 222 |         SELECT \n 223 |         t3.rcvr_id,\n 224 |         t3.cnt/t2.total_cnt as merchant_ratio,\n 225 |         (SQRT(t3.cnt/t2.total_cnt/{config['driver_config']['training_hot_positive_organic_txn_sampling_alpha']})+1)*{config['driver_config']['training_hot_positive_organic_txn_sampling_alpha']}*t2.total_cnt/t3.cnt as merchant_sampling_ratio\n 226 |         FROM t3\n 227 |         JOIN t2\n 228 |         ON 1=1\n 229 |     ),\n 230 |     t5 as (\n 231 |         SELECT t1.*,t4,merchant_ratio,t4.merchant_sampling_ratio\n 232 |         FROM t1\n 233 |         JOIN t4\n 234 |         ON t1.rcvr_id=t4.rcvr_id\n 235 |     ),\n 236 |     t6 as (\n 237 |         SELECT *\n 238 |         FROM t5\n 239 |         WHERE RAND()<=merchant_sampling_ratio\n 240 |     )\n 241 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,merchant_ratio,merchant_sampling_ratio,\n 242 | 'pure_organirc_txn' as pos_tag_type, \n 243 | case when run_date<{config['driver_config']['val_start_date']} then 'train' else 'val' end as split\n 244 | FROM t6;\n 245 | \"\"\"\n 246 | # %ppbq $q\n 247 | q=f\"\"\"drop table if exists {bq_prefix}driver_positive;\n 248 | create table {bq_prefix}driver_positive as\n 249 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,pos_tag_type,split\n 250 | FROM {bq_prefix}driver_positive_train_attributed\n 251 | UNION ALL\n 252 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,'attributed_txn' as pos_tag_type,'oot' as split\n 253 | FROM {bq_prefix}driver_0\n 254 | WHERE leap_aft_txn>0\n 255 | AND run_date>={config['driver_config']['oot_start_date']}\n 256 | UNION ALL\n 257 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,'save' as pos_tag_type,'train' as split\n 258 | FROM {bq_prefix}driver_0 \n 259 | WHERE save>0\n 260 | AND run_date<{config['driver_config']['oot_start_date']}\n 261 | AND rand()<{config['driver_config']['save_label_mixing_rate']}\n 262 | UNION ALL\n 263 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,'save' as pos_tag_type,'oot' as split\n 264 | FROM {bq_prefix}driver_0 \n 265 | WHERE save>0\n 266 | AND run_date>={config['driver_config']['oot_start_date']}\n 267 | UNION ALL\n 268 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,pos_tag_type,split\n 269 | FROM {bq_prefix}driver_positive_train_organic\n 270 | UNION ALL\n 271 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,'pure_organirc_txn' as pos_tag_type,'oot' as split\n 272 | FROM {bq_prefix}driver_1\n 273 | WHERE CONCAT(cust_id,rcvr_id) not in (select distinct concat(cust_id,rcvr_id) \n 274 |                                       from {bq_prefix}driver_0 where leap_aft_txn>0)\n 275 | AND CONCAT(cust_id,rcvr_id) not in (select distinct concat(cust_id,rcvr_id) \n 276 |                                     from {bq_prefix}driver_0 where save>0)\n 277 | AND run_date>={config['driver_config']['oot_start_date']};\n 278 | \"\"\"\n 279 | # %ppbq $q\n 280 | # # Negative Sampling\n 281 | q=f\"\"\"drop table if exists {bq_prefix}driver_positive_training_split_0;\n 282 | create table {bq_prefix}driver_positive_training_split_0 as\n 283 | with t1 as(\n 284 |     select a.cust_id, avg(rand()) as random\n 285 |     from (\n 286 |         select * \n 287 |         from {bq_prefix}driver_positive \n 288 |         where split in ('train','val')) a\n 289 |     join {bq_prefix}driver_0 b\n 290 |     on a.cust_id=b.cust_id\n 291 |     and a.run_date>=b.run_date\n 292 |     and a.run_date<=DATE_ADD(b.run_date,INTERVAL 7 DAY)\n 293 |     and b.save=0\n 294 |     and b.leap_aft_txn=0\n 295 |     and a.rcvr_id<>b.rcvr_id\n 296 |     where a.split in ('train','val')\n 297 |     group by 1\n 298 | )\n 299 | select a.*,\n 300 | case when t1.cust_id is not null then 'y' else 'n' end as has_hard_negative,\n 301 | case when t1.cust_id is not null and random<{config['driver_config']['ratio_for_hard_negtive']} then 'hard_negative' else 'uniform_negative' end as negative_type,\n 302 | from (\n 303 |     select * from {bq_prefix}driver_positive \n 304 |     where split in ('train','val')\n 305 | ) a\n 306 | left join t1\n 307 | on a.cust_id=t1.cust_id;\n 308 | \"\"\"\n 309 | # %ppbq $q\n 310 | q=f\"\"\"drop table if exists {bq_prefix}driver_positive_training_split;\n 311 | create table {bq_prefix}driver_positive_training_split as\n 312 | with t1 as (\n 313 |     select cust_id,run_date,count(*) as day_pos_cnt\n 314 |     from {bq_prefix}driver_positive_training_split_0\n 315 |     group by 1,2\n 316 | )\n 317 | select a.*,t1.day_pos_cnt\n 318 | from {bq_prefix}driver_positive_training_split_0 a\n 319 | join t1\n 320 | on a.cust_id=t1.cust_id\n 321 | and a.run_date=t1.run_date;\n 322 | \"\"\"\n 323 | # %ppbq $q\n 324 | q=f\"\"\"drop table if exists {bq_prefix}driver_training_hard_negative;\n 325 | create table {bq_prefix}driver_training_hard_negative as\n 326 | select a.*,b.rcvr_id as hard_negative_id,b.run_date as hard_negative_impression_date\n 327 | from (select * from {bq_prefix}driver_positive_training_split \n 328 |       where negative_type='hard_negative'\n 329 |      ) a\n 330 | join {bq_prefix}driver_0 b\n 331 | on a.cust_id=b.cust_id\n 332 | and a.run_date>=b.run_date\n 333 | and a.run_date<=DATE_ADD(b.run_date,INTERVAL 7 DAY)\n 334 | and a.rcvr_id<>b.rcvr_id\n 335 | and b.save=0\n 336 | and b.leap_aft_txn=0;\n 337 | \"\"\"\n 338 | # %ppbq $q\n 339 | q=f\"\"\"drop table if exists {bq_prefix}driver_training_hard_negative_downsample;\n 340 | create table {bq_prefix}driver_training_hard_negative_downsample as\n 341 | select a.*\n 342 | from {bq_prefix}driver_training_hard_negative a\n 343 | left join {bq_prefix}driver_positive_training_split b\n 344 | on a.cust_id=b.cust_id\n 345 | and a.hard_negative_id=b.rcvr_id\n 346 | and b.run_date>=DATE_SUB(a.hard_negative_impression_date,INTERVAL {config['driver_config']['hard_negative_impression_time_window']} DAY)\n 347 | and b.run_date<=DATE_ADD(a.hard_negative_impression_date,INTERVAL {config['driver_config']['hard_negative_impression_time_window']} DAY)\n 348 | where b.rcvr_id is null\n 349 | qualify row_number() over (partition by a.cust_id,a.run_date order by rand())<=a.day_pos_cnt;\n 350 | \"\"\"\n 351 | # %ppbq $q\n 352 | q=f\"\"\"drop table if exists {bq_prefix}driver_training_uniform_negative;\n 353 | create table {bq_prefix}driver_training_uniform_negative as\n 354 | select a.*,b.rcvr_id as uniform_negative_id\n 355 | from (select * \n 356 |       from {bq_prefix}driver_positive_training_split \n 357 |       where concat(cust_id,run_date) not in (\n 358 |           select distinct concat(cust_id,run_date) \n 359 |           from {bq_prefix}driver_training_hard_negative_downsample\n 360 |         )\n 361 |     ) a\n 362 | join {bq_prefix}live_unique_merchants_train b\n 363 | on 1=1\n 364 | where a.rcvr_id<>b.rcvr_id;\n 365 | \"\"\"\n 366 | # %ppbq $q\n 367 | q=f\"\"\"drop table if exists {bq_prefix}driver_training_uniform_negative_remove_window_positive;\n 368 | create table {bq_prefix}driver_training_uniform_negative_remove_window_positive as\n 369 | select a.*\n 370 | from {bq_prefix}driver_training_uniform_negative a\n 371 | left join {bq_prefix}driver_positive_training_split b\n 372 | on a.cust_id=b.cust_id\n 373 | and a.uniform_negative_id=b.rcvr_id\n 374 | and b.run_date>=DATE_SUB(a.run_date,INTERVAL {config['driver_config']['negative_sampling_avoid_delay_postive_feedback_window']} DAY)\n 375 | and b.run_date<=DATE_ADD(a.run_date,INTERVAL {config['driver_config']['negative_sampling_avoid_delay_postive_feedback_window']} DAY)\n 376 | where b.rcvr_id is null;\n 377 | \"\"\"\n 378 | # %ppbq $q\n 379 | q=f\"\"\"drop table if exists {bq_prefix}driver_training_uniform_negative_downsample_0;\n 380 | create table {bq_prefix}driver_training_uniform_negative_downsample_0 as\n 381 | with \n 382 | t1 as (\n 383 |     select rcvr_id,count(*) as cnt_merch\n 384 |     from {bq_prefix}driver_1\n 385 |     group by 1\n 386 | ),\n 387 | t2 as (\n 388 |     select count(*) as cnt_all\n 389 |     from {bq_prefix}driver_1\n 390 | ),\n 391 | t3 as (\n 392 |     select t1.rcvr_id,pow(t1.cnt_merch/t2.cnt_all,{config['driver_config']['training_hot_negative_sampling_alpha']}) as merch_sampling_prob\n 393 |     from t1\n 394 |     join t2\n 395 |     on 1=1\n 396 | )\n 397 | SELECT\n 398 |     a.*\n 399 |     from {bq_prefix}driver_training_uniform_negative_remove_window_positive a\n 400 |     join t3 on a.uniform_negative_id = t3.rcvr_id\n 401 |     where rand()<=t3.merch_sampling_prob;\n 402 | \"\"\"\n 403 | # %ppbq $q\n 404 | q=f\"\"\"drop table if exists {bq_prefix}driver_training_uniform_negative_downsample;\n 405 | create table {bq_prefix}driver_training_uniform_negative_downsample as\n 406 | select * from {bq_prefix}driver_training_uniform_negative_downsample_0\n 407 | qualify row_number() over (partition by cust_id,run_date order by rand())<={config['driver_config']['uniform_negative_postive_ratio']}*day_pos_cnt;\n 408 | \"\"\"\n 409 | # %ppbq $q\n 410 | q=f\"\"\"drop table if exists {bq_prefix}driver_dev;\n 411 | create table {bq_prefix}driver_dev as\n 412 | SELECT \n 413 |     cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,pos_tag_type,1 as target,split\n 414 | from {bq_prefix}driver_positive_training_split\n 415 | where negative_type='hard_negative'\n 416 | UNION ALL\n 417 | SELECT \n 418 |     a.cust_id,\n 419 |     a.hard_negative_id as rcvr_id,\n 420 |     a.run_date,\n 421 |     b.gpt_1st_category_l2_index,\n 422 |     a.pos_tag_type,\n 423 |     0 as target,\n 424 |     split\n 425 | FROM {bq_prefix}driver_training_hard_negative_downsample a\n 426 | JOIN {bq_prefix}live_unique_merchants_train b\n 427 | ON a.hard_negative_id=b.rcvr_id\n 428 | UNION ALL\n 429 | SELECT \n 430 |     cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,pos_tag_type,1 as target,split\n 431 | from {bq_prefix}driver_positive_training_split\n 432 | where negative_type='uniform_negative'\n 433 | UNION ALL\n 434 | SELECT \n 435 |     a.cust_id,\n 436 |     a.uniform_negative_id as rcvr_id,\n 437 |     a.run_date,\n 438 |     b.gpt_1st_category_l2_index,\n 439 |     a.pos_tag_type,\n 440 |     0 as target,\n 441 |     split\n 442 | FROM {bq_prefix}driver_training_uniform_negative_downsample a\n 443 | JOIN {bq_prefix}live_unique_merchants_train b\n 444 | ON a.uniform_negative_id=b.rcvr_id\n 445 | ;\n 446 | \"\"\"\n 447 | # %ppbq $q\n 448 | # # OOT\n 449 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_uniform_negative_0;\n 450 | create table {bq_prefix}driver_oot_uniform_negative_0 as\n 451 | with t1 as (\n 452 |     select cust_id,run_date,count(*) as day_pos_cnt\n 453 |     from {bq_prefix}driver_positive\n 454 |     where split='oot'\n 455 |     GROUP BY 1,2\n 456 | ),\n 457 | t2 as (\n 458 |     select * from {bq_prefix}driver_positive\n 459 |     where split='oot'\n 460 |     )\n 461 | SELECT t2.*,t1.day_pos_cnt,b.rcvr_id as uniform_negative_id\n 462 | from t2\n 463 | join {bq_prefix}live_unique_merchants_train b\n 464 | on 1=1\n 465 | and t2.rcvr_id<>b.rcvr_id\n 466 | join t1 \n 467 | on t2.cust_id=t1.cust_id\n 468 | and t2.run_date=t1.run_date\n 469 | qualify row_number() over (partition by t2.cust_id,t2.run_date,b.rcvr_id order by rand())=1;\n 470 | \"\"\"\n 471 | # %ppbq $q\n 472 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_uniform_negative;\n 473 | create table {bq_prefix}driver_oot_uniform_negative as\n 474 | select * from {bq_prefix}driver_oot_uniform_negative_0\n 475 | where concat(cust_id,run_date,uniform_negative_id) not in (\n 476 |     select distinct concat(cust_id,run_date,rcvr_id)\n 477 |     from {bq_prefix}driver_oot_uniform_negative_0\n 478 | );\n 479 | \"\"\"\n 480 | # %ppbq $q\n 481 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot;\n 482 | create table {bq_prefix}driver_oot as\n 483 | SELECT cust_id,rcvr_id,run_date,gpt_1st_category_l2_index,pos_tag_type,1 as target\n 484 | FROM {bq_prefix}driver_positive\n 485 | WHERE split='oot'\n 486 | UNION ALL\n 487 | SELECT a.cust_id,\n 488 | a.uniform_negative_id as rcvr_id,\n 489 | a.run_date,\n 490 | b.gpt_1st_category_l2_index,\n 491 | a.pos_tag_type,\n 492 | 0 as target\n 493 | FROM {bq_prefix}driver_oot_uniform_negative  a\n 494 | JOIN {bq_prefix}live_unique_merchants_train b\n 495 | ON a.uniform_negative_id=b.rcvr_id;\n 496 | \"\"\"\n 497 | # %ppbq $q\n 498 | q=f\"\"\"drop table if exists {bq_prefix}driver_simu;\n 499 | create table {bq_prefix}driver_simu as\n 500 | select distinct \n 501 | cust_id,rcvr_id,run_date\n 502 | from {bq_prefix}driver_dev\n 503 | union distinct\n 504 | select distinct \n 505 | cust_id,rcvr_id,run_date\n 506 | from {bq_prefix}driver_oot;\n 507 | \"\"\"\n 508 | # %ppbq $q\n 509 | q=f\"\"\"drop table if exists {bq_prefix}driver_simu_consumer;\n 510 | create table  {bq_prefix}driver_simu_consumer as\n 511 | select distinct cust_id,run_date from {bq_prefix}driver_simu;\n 512 | \"\"\"\n 513 | # %ppbq $q",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/01_bq_feat.py": "   1 | # %reload_ext cloudmagics.bigquery\n   2 | # %config PPMagics.domain=\"ccg24-hrzana-gds-pacman\"\n   3 | # %config PPMagics.autolimit = 0\n   4 | import yaml\n   5 | def load_yaml_file(file_path):\n   6 |     try:\n   7 |         with open(file_path, 'r') as file:\n   8 |             yaml_content = yaml.safe_load(file)\n   9 |         return yaml_content\n  10 |     except FileNotFoundError:\n  11 |         return None\n  12 | file_path = '../config/base_config.yaml'\n  13 | config = load_yaml_file(file_path)\n  14 | if config is not None:\n  15 | bq_prefix = config['general_config']['bq_project_dataset_prefix']\n  16 | bq_prefix\n  17 | q=f\"\"\"drop table if exists {bq_prefix}driver_simu_txn_365d;\n  18 | create table {bq_prefix}driver_simu_txn_365d as\n  19 | select a.*,\n  20 |     date_sub(cast(a.run_date as DATE),INTERVAL 7 DAY) as run_date_7d,\n  21 |     date_sub(cast(a.run_date as DATE),INTERVAL 30 DAY) as run_date_30d,\n  22 |     date_sub(cast(a.run_date as DATE),INTERVAL 180 DAY) as run_date_180d,\n  23 |     date_sub(cast(a.run_date as DATE),INTERVAL 365 DAY) as run_date_365d,\n  24 |     b.payment_transid,b.transaction_created_date,b.transaction_usd_equiv_amt\n  25 | from {bq_prefix}driver_simu a\n  26 | join (\n  27 |     select payment_transid,\n  28 |     tran_customer_id,\n  29 |     customer_counterparty,\n  30 |     transaction_created_date,\n  31 |     transaction_created_ts,\n  32 |     -0.01*transaction_usd_equiv_amt as transaction_usd_equiv_amt\n  33 |     from pypl-edw.pp_access_views.dw_payment_sent\n  34 |     where transaction_status='S'\n  35 |     and transaction_created_date >= date_sub({config['driver_config']['train_start_date']},INTERVAL 365 DAY)\n  36 | )b\n  37 | on a.cust_id = b.tran_customer_id\n  38 | and a.rcvr_id = b.customer_counterparty\n  39 | and a.run_date>b.transaction_created_date\n  40 | qualify row_number() over (partition by payment_transid order by transaction_created_ts desc)=1;\n  41 | \"\"\"\n  42 | # %ppbq $q\n  43 | q=f\"\"\"drop table if exists {bq_prefix}driver_simu_txn_365d_agg;\n  44 | create table {bq_prefix}driver_simu_txn_365d_agg as\n  45 | select cust_id,rcvr_id,run_date\n  46 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_7d then 1 else 0 end) as sndr_rcvr_txn_num_7d\n  47 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_30d then 1 else 0 end) as sndr_rcvr_txn_num_30d\n  48 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_180d then 1 else 0 end) as sndr_rcvr_txn_num_180d\n  49 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_365d then 1 else 0 end) as sndr_rcvr_txn_num_365d\n  50 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_7d then transaction_usd_equiv_amt else 0 end) as sndr_rcvr_txn_amt_7d\n  51 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_30d then transaction_usd_equiv_amt else 0 end) as sndr_rcvr_txn_amt_30d\n  52 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_180d then transaction_usd_equiv_amt else 0 end) as sndr_rcvr_txn_amt_180d\n  53 | ,sum(case when transaction_created_date<cast(run_date as DATE) and transaction_created_date>run_date_365d then transaction_usd_equiv_amt else 0 end) as sndr_rcvr_txn_amt_365d\n  54 | from {bq_prefix}driver_simu_txn_365d\n  55 | group by 1,2,3;\n  56 | \"\"\"\n  57 | # %ppbq $q\n  58 | q=f\"\"\"drop table if exists {bq_prefix}driver_consumer_base;\n  59 | create table {bq_prefix}driver_consumer_base as\n  60 | select \n  61 |     cust_id,cast(run_date as DATE) as run_date,\n  62 |     date_sub(cast(run_date as DATE),INTERVAL 30 DAY) as run_date_30d,\n  63 |     date_sub(cast(run_date as DATE),INTERVAL 180 DAY) as run_date_180d,\n  64 |     date_sub(cast(run_date as DATE),INTERVAL 365 DAY) as run_date_365d,\n  65 | from {bq_prefix}driver_simu\n  66 | group by 1,2,3,4,5;\n  67 | \"\"\"\n  68 | # %ppbq $q\n  69 | q=f\"\"\"drop table if exists {bq_prefix}driver_consumer_base_txn_5k_merch_category;\n  70 | create table {bq_prefix}driver_consumer_base_txn_5k_merch_category as\n  71 | select \n  72 | a.*,b.customer_counterparty,b.payment_transid,b.transaction_created_date,b.transaction_created_ts,b.transaction_usd_equiv_amt,c.gpt_1st_category_l2_index,\n  73 | row_number() over (partition by a.cust_id,a.run_date order by b.transaction_created_ts desc) as recency_rank\n  74 | from {bq_prefix}driver_consumer_base a\n  75 | join (\n  76 |     select payment_transid,\n  77 |     tran_customer_id,\n  78 |     customer_counterparty,\n  79 |     transaction_created_date,\n  80 |     transaction_created_ts,\n  81 |     -0.01*transaction_usd_equiv_amt as transaction_usd_equiv_amt,\n  82 |     from pypl-edw.pp_access_views.dw_payment_sent\n  83 |     where transaction_status='S'\n  84 |     and transaction_created_date >= date_sub({config['driver_config']['train_start_date']},INTERVAL 365 DAY)\n  85 |     and tran_customer_id in (select distinct cust_id from {bq_prefix}driver_consumer_base)\n  86 |     and customer_counterparty in (select distinct rcvr_id from {bq_prefix}live_unique_merchants_train)\n  87 |     qualify row_number() over (partition by payment_transid order by transaction_created_ts desc)=1\n  88 | )b\n  89 | on a.cust_id = b.tran_customer_id\n  90 | and a.run_date>b.transaction_created_date\n  91 | and a.run_date_365d<b.transaction_created_date\n  92 | join {bq_prefix}live_unique_merchants_train c\n  93 | on b.customer_counterparty=c.rcvr_id;\n  94 | \"\"\"\n  95 | # %ppbq $q\n  96 | q=f\"\"\"drop table if exists {bq_prefix}driver_consumer_base_last_10_txn;\n  97 | create table  {bq_prefix}driver_consumer_base_last_10_txn as\n  98 | select \n  99 |     a.cust_id,a.run_date\n 100 |     ,COALESCE(last_1.transaction_usd_equiv_amt,0) as sndr_last_1_txn_amt\n 101 |     ,(COALESCE(last_1.transaction_usd_equiv_amt,0)\n 102 |       +COALESCE(last_2.transaction_usd_equiv_amt,0)\n 103 |       +COALESCE(last_3.transaction_usd_equiv_amt,0)\n 104 |       +COALESCE(last_4.transaction_usd_equiv_amt,0)\n 105 |       +COALESCE(last_5.transaction_usd_equiv_amt,0)\n 106 |      )/(\n 107 |         IF(last_1.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 108 |         +IF(last_2.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 109 |         +IF(last_3.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 110 |         +IF(last_4.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 111 |         +IF(last_5.transaction_usd_equiv_amt IS NOT NULL, 1, 0)+1.0\n 112 |        ) as sndr_last_5_txn_avg_amt\n 113 |     ,(COALESCE(last_1.transaction_usd_equiv_amt,0)\n 114 |       +COALESCE(last_2.transaction_usd_equiv_amt,0)\n 115 |       +COALESCE(last_3.transaction_usd_equiv_amt,0)\n 116 |       +COALESCE(last_4.transaction_usd_equiv_amt,0)\n 117 |       +COALESCE(last_5.transaction_usd_equiv_amt,0)\n 118 |       +COALESCE(last_6.transaction_usd_equiv_amt,0)\n 119 |       +COALESCE(last_7.transaction_usd_equiv_amt,0)\n 120 |       +COALESCE(last_8.transaction_usd_equiv_amt,0)\n 121 |       +COALESCE(last_9.transaction_usd_equiv_amt,0)\n 122 |       +COALESCE(last_10.transaction_usd_equiv_amt,0)\n 123 |      )/(\n 124 |         IF(last_1.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 125 |         +IF(last_2.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 126 |         +IF(last_3.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 127 |         +IF(last_4.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 128 |         +IF(last_5.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 129 |         +IF(last_6.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 130 |         +IF(last_7.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 131 |         +IF(last_8.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 132 |         +IF(last_9.transaction_usd_equiv_amt IS NOT NULL, 1, 0)\n 133 |         +IF(last_10.transaction_usd_equiv_amt IS NOT NULL, 1, 0)+1.0\n 134 |        ) as sndr_last_10_txn_avg_amt\n 135 | from {bq_prefix}driver_consumer_base a\n 136 | left join (\n 137 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 138 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=1\n 139 | ) last_1 on a.cust_id=last_1.cust_id and a.run_date=last_1.run_date\n 140 | left join (\n 141 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 142 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=2\n 143 | ) last_2 on a.cust_id=last_2.cust_id and a.run_date=last_2.run_date\n 144 | left join (\n 145 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 146 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=3\n 147 | ) last_3 on a.cust_id=last_3.cust_id and a.run_date=last_3.run_date\n 148 | left join (\n 149 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 150 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=4\n 151 | ) last_4 on a.cust_id=last_4.cust_id and a.run_date=last_4.run_date\n 152 | left join (\n 153 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 154 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=5\n 155 | ) last_5 on a.cust_id=last_5.cust_id and a.run_date=last_5.run_date\n 156 | left join (\n 157 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 158 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=6\n 159 | ) last_6 on a.cust_id=last_6.cust_id and a.run_date=last_6.run_date\n 160 | left join (\n 161 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 162 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=7\n 163 | ) last_7 on a.cust_id=last_7.cust_id and a.run_date=last_7.run_date\n 164 | left join (\n 165 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 166 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=8\n 167 | ) last_8 on a.cust_id=last_8.cust_id and a.run_date=last_8.run_date\n 168 | left join (\n 169 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 170 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=9\n 171 | ) last_9 on a.cust_id=last_9.cust_id and a.run_date=last_9.run_date\n 172 | left join (\n 173 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_usd_equiv_amt,gpt_1st_category_l2_index\n 174 |     from {bq_prefix}driver_consumer_base_txn_5k_merch_category where recency_rank=10\n 175 | ) last_10 on a.cust_id=last_10.cust_id and a.run_date=last_10.run_date;\n 176 | \"\"\"\n 177 | # %ppbq $q\n 178 | q=f\"\"\"drop table if exists {bq_prefix}driver_consumer_base_all_history_array_0;\n 179 | create table  {bq_prefix}driver_consumer_base_all_history_array_0 as\n 180 | select cust_id,run_date,customer_counterparty,transaction_created_date,transaction_created_ts,gpt_1st_category_l2_index\n 181 | from \n 182 | (select cust_id,run_date, customer_counterparty,transaction_created_date,transaction_created_ts,gpt_1st_category_l2_index\n 183 |  from {bq_prefix}driver_consumer_base_txn_5k_merch_category\n 184 | )\n 185 | qualify row_number() over (partition by cust_id,run_date order by transaction_created_ts desc)<=100;\n 186 | \"\"\"\n 187 | # %ppbq $q\n 188 | q=f\"\"\"drop table if exists {bq_prefix}driver_consumer_base_all_history_array;\n 189 | create table  {bq_prefix}driver_consumer_base_all_history_array as\n 190 | select cust_id,run_date\n 191 | ,ARRAY_TO_STRING(ARRAY_AGG(COALESCE(customer_counterparty, '0') ORDER BY transaction_created_ts), ',') AS sndr_most_recent_100_merch_list\n 192 | ,ARRAY_TO_STRING(ARRAY_AGG(COALESCE(cast(gpt_1st_category_l2_index as string), '0') ORDER BY transaction_created_ts), ',') AS sndr_most_recent_100_merch_category\n 193 | from {bq_prefix}driver_consumer_base_all_history_array_0\n 194 | group by 1,2;\n 195 | \"\"\"\n 196 | # %ppbq $q\n 197 | # # Category aggregation\n 198 | q=f\"\"\"drop table if exists {bq_prefix}driver_combine_category;\n 199 | create table  {bq_prefix}driver_combine_category as\n 200 | select a.*,b.gpt_1st_category_l2_index as rcvr_gpt_1st_category_l2_index\n 201 | from {bq_prefix}driver_simu a\n 202 | left join {bq_prefix}live_unique_merchants_train b \n 203 | on a.rcvr_id=b.rcvr_id;\n 204 | \"\"\"\n 205 | # %ppbq $q\n 206 | q=f\"\"\"drop table if exists {bq_prefix}driver_combine_category_agg_0;\n 207 | create table  {bq_prefix}driver_combine_category_agg_0 as\n 208 | select cust_id,run_date,gpt_1st_category_l2_index,\n 209 |   COUNT(DISTINCT IF((transaction_created_date>run_date_30d),customer_counterparty,NULL)) AS sndr_category_breadth_30d,\n 210 |   COUNT(DISTINCT IF((transaction_created_date>run_date_180d),customer_counterparty,NULL)) AS sndr_category_breadth_180d,\n 211 |   COUNT(DISTINCT IF((transaction_created_date>run_date_365d),customer_counterparty,NULL)) AS sndr_category_breadth_365d,\n 212 |   SUM(IF((transaction_created_date>run_date_30d),1,0)) AS sndr_category_txn_num_30d,\n 213 |   SUM(IF((transaction_created_date>run_date_180d),1,0)) AS sndr_category_txn_num_180d,\n 214 |   SUM(IF((transaction_created_date>run_date_365d),1,0)) AS sndr_category_txn_num_365d,\n 215 |   SUM(IF((transaction_created_date>run_date_30d),transaction_usd_equiv_amt,0)) AS sndr_category_txn_amt_30d,\n 216 |   SUM(IF((transaction_created_date>run_date_180d),transaction_usd_equiv_amt,0)) AS sndr_category_txn_amt_180d,\n 217 |   SUM(IF((transaction_created_date>run_date_365d),transaction_usd_equiv_amt,0)) AS sndr_category_txn_amt_365d\n 218 | FROM {bq_prefix}driver_consumer_base_txn_5k_merch_category \n 219 | group by 1,2,3;\n 220 | \"\"\"\n 221 | # %ppbq $q\n 222 | q=f\"\"\"drop table if exists {bq_prefix}driver_combine_category_agg_1;\n 223 | create table  {bq_prefix}driver_combine_category_agg_1 as\n 224 | SELECT\n 225 |   cust_id,\n 226 |   run_date,\n 227 |   SUM(IF((transaction_created_date>run_date_30d),1,0)) AS sndr_txn_num_30d,\n 228 |   SUM(IF((transaction_created_date>run_date_180d),1,0)) AS sndr_txn_num_180d,\n 229 |   SUM(IF((transaction_created_date>run_date_365d),1,0)) AS sndr_txn_num_365d\n 230 | FROM {bq_prefix}driver_consumer_base_txn_5k_merch_category\n 231 | GROUP BY 1,2;\n 232 | \"\"\"\n 233 | # %ppbq $q\n 234 | q=f\"\"\"drop table if exists {bq_prefix}driver_combine_category_agg_2;\n 235 | create table  {bq_prefix}driver_combine_category_agg_2 as\n 236 | SELECT\n 237 |   a.cust_id,\n 238 |   a.run_date,\n 239 |   a.gpt_1st_category_l2_index,\n 240 |   a.sndr_category_breadth_30d,\n 241 |   a.sndr_category_breadth_180d,\n 242 |   a.sndr_category_breadth_365d,\n 243 |   a.sndr_category_txn_num_30d,\n 244 |   a.sndr_category_txn_num_180d,\n 245 |   a.sndr_category_txn_num_365d,\n 246 |   a.sndr_category_txn_amt_30d,\n 247 |   a.sndr_category_txn_amt_180d,\n 248 |   a.sndr_category_txn_amt_365d,\n 249 |   a.sndr_category_txn_amt_30d/b.sndr_txn_num_365d AS sndr_category_avg_txn_amt_30d,\n 250 |   a.sndr_category_txn_amt_180d/b.sndr_txn_num_365d AS sndr_category_avg_txn_amt_180d,\n 251 |   a.sndr_category_txn_amt_365d/b.sndr_txn_num_365d AS sndr_category_avg_txn_amt_365d\n 252 | FROM\n 253 |   {bq_prefix}driver_combine_category_agg_0 AS a\n 254 | JOIN\n 255 |   {bq_prefix}driver_combine_category_agg_1 AS b\n 256 | ON a.cust_id=b.cust_id\n 257 | AND a.run_date=b.run_date;\n 258 | \"\"\"\n 259 | # %ppbq $q\n 260 | q=f\"\"\"drop table if exists {bq_prefix}driver_combine_category_agg_3;\n 261 | create table  {bq_prefix}driver_combine_category_agg_3 as\n 262 | SELECT\n 263 |   a.cust_id,\n 264 |   a.run_date,\n 265 |   a.rcvr_id,\n 266 |   a.rcvr_gpt_1st_category_l2_index,\n 267 |   COALESCE(b.sndr_category_breadth_30d,0) AS sndr_rcvr_category_breadth_30d,\n 268 |   COALESCE(b.sndr_category_breadth_180d,0) AS sndr_rcvr_category_breadth_180d,\n 269 |   COALESCE(b.sndr_category_breadth_365d,0) AS sndr_rcvr_category_breadth_365d,\n 270 |   COALESCE(b.sndr_category_txn_num_30d,0) AS sndr_rcvr_category_txn_num_30d,\n 271 |   COALESCE(b.sndr_category_txn_num_180d,0) AS sndr_rcvr_category_txn_num_180d,\n 272 |   COALESCE(b.sndr_category_txn_num_365d,0) AS sndr_rcvr_category_txn_num_365d,\n 273 |   COALESCE(b.sndr_category_txn_amt_30d,0) AS sndr_rcvr_category_txn_amt_30d,\n 274 |   COALESCE(b.sndr_category_txn_amt_180d,0) AS sndr_rcvr_category_txn_amt_180d,\n 275 |   COALESCE(b.sndr_category_txn_amt_365d,0) AS sndr_rcvr_category_txn_amt_365d,\n 276 |   COALESCE(b.sndr_category_avg_txn_amt_30d,0) AS sndr_rcvr_category_avg_txn_amt_30d,\n 277 |   COALESCE(b.sndr_category_avg_txn_amt_180d,0) AS sndr_rcvr_category_avg_txn_amt_180d,\n 278 |   COALESCE(b.sndr_category_avg_txn_amt_365d,0) AS sndr_rcvr_category_avg_txn_amt_365d\n 279 | FROM\n 280 |   {bq_prefix}driver_combine_category AS a\n 281 | LEFT JOIN\n 282 |   {bq_prefix}driver_combine_category_agg_2 AS b\n 283 | ON\n 284 |   a.cust_id=b.cust_id\n 285 |   AND a.run_date=b.run_date\n 286 |   AND a.rcvr_gpt_1st_category_l2_index=b.gpt_1st_category_l2_index;\n 287 | \"\"\"\n 288 | # %ppbq $q\n 289 | q=f\"\"\"drop table if exists {bq_prefix}driver_combine_category_agg_4;\n 290 | create table  {bq_prefix}driver_combine_category_agg_4 as\n 291 | SELECT\n 292 |   cust_id,\n 293 |   run_date,\n 294 |   gpt_1st_category_l2_index,\n 295 |   sndr_category_txn_num_30d,\n 296 |   sndr_category_txn_num_180d,\n 297 |   sndr_category_txn_num_365d,\n 298 |   ROW_NUMBER() OVER (PARTITION BY cust_id, run_date ORDER BY sndr_category_txn_num_30d DESC) AS sndr_category_txn_num_30d_freq_rank,\n 299 |   ROW_NUMBER() OVER (PARTITION BY cust_id, run_date ORDER BY sndr_category_txn_num_180d DESC) AS sndr_category_txn_num_180d_freq_rank,\n 300 |   ROW_NUMBER() OVER (PARTITION BY cust_id, run_date ORDER BY sndr_category_txn_num_365d DESC) AS sndr_category_txn_num_365d_freq_rank\n 301 | FROM\n 302 |   {bq_prefix}driver_combine_category_agg_0;\n 303 | \"\"\"\n 304 | # %ppbq $q\n 305 | q=f\"\"\"drop table if exists {bq_prefix}driver_combine_category_agg_5;\n 306 | create table  {bq_prefix}driver_combine_category_agg_5 as\n 307 | SELECT\n 308 |   a.cust_id,\n 309 |   a.run_date,\n 310 |   COALESCE(cat_freq_30d_1.gpt_1st_category_l2_index,0) AS sndr_1st_freq_merchant_category_30d,\n 311 |   COALESCE(cat_freq_30d_1.sndr_category_txn_num_30d,0) AS sndr_1st_freq_merchant_category_cnt_30d,\n 312 |   COALESCE(cat_freq_30d_2.gpt_1st_category_l2_index,0) AS sndr_2nd_freq_merchant_category_30d,\n 313 |   COALESCE(cat_freq_30d_2.sndr_category_txn_num_30d,0) AS sndr_2nd_freq_merchant_category_cnt_30d,\n 314 |   COALESCE(cat_freq_30d_3.gpt_1st_category_l2_index,0) AS sndr_3rd_freq_merchant_category_30d,\n 315 |   COALESCE(cat_freq_30d_3.sndr_category_txn_num_30d,0) AS sndr_3rd_freq_merchant_category_cnt_30d,\n 316 |   COALESCE(cat_freq_180d_1.gpt_1st_category_l2_index,0) AS sndr_1st_freq_merchant_category_180d,\n 317 |   COALESCE(cat_freq_180d_1.sndr_category_txn_num_180d,0) AS sndr_1st_freq_merchant_category_cnt_180d,\n 318 |   COALESCE(cat_freq_180d_2.gpt_1st_category_l2_index,0) AS sndr_2nd_freq_merchant_category_180d,\n 319 |   COALESCE(cat_freq_180d_2.sndr_category_txn_num_180d,0) AS sndr_2nd_freq_merchant_category_cnt_180d,\n 320 |   COALESCE(cat_freq_180d_3.gpt_1st_category_l2_index,0) AS sndr_3rd_freq_merchant_category_180d,\n 321 |   COALESCE(cat_freq_180d_3.sndr_category_txn_num_180d,0) AS sndr_3rd_freq_merchant_category_cnt_180d,\n 322 |   COALESCE(cat_freq_365d_1.gpt_1st_category_l2_index,0) AS sndr_1st_freq_merchant_category_365d,\n 323 |   COALESCE(cat_freq_365d_1.sndr_category_txn_num_365d,0) AS sndr_1st_freq_merchant_category_cnt_365d,\n 324 |   COALESCE(cat_freq_365d_2.gpt_1st_category_l2_index,0) AS sndr_2nd_freq_merchant_category_365d,\n 325 |   COALESCE(cat_freq_365d_2.sndr_category_txn_num_365d,0) AS sndr_2nd_freq_merchant_category_cnt_365d,\n 326 |   COALESCE(cat_freq_365d_3.gpt_1st_category_l2_index,0) AS sndr_3rd_freq_merchant_category_365d,\n 327 |   COALESCE(cat_freq_365d_3.sndr_category_txn_num_365d,0) AS sndr_3rd_freq_merchant_category_cnt_365d\n 328 | FROM\n 329 |   {bq_prefix}driver_consumer_base a\n 330 | LEFT JOIN (\n 331 |   SELECT\n 332 |     cust_id,\n 333 |     run_date,\n 334 |     gpt_1st_category_l2_index,\n 335 |     sndr_category_txn_num_30d,\n 336 |     sndr_category_txn_num_180d,\n 337 |     sndr_category_txn_num_365d\n 338 |   FROM\n 339 |     {bq_prefix}driver_combine_category_agg_4\n 340 |   WHERE\n 341 |     sndr_category_txn_num_30d_freq_rank=1 ) cat_freq_30d_1\n 342 | ON\n 343 |   a.cust_id=cat_freq_30d_1.cust_id\n 344 |   AND a.run_date=cat_freq_30d_1.run_date\n 345 | LEFT JOIN (\n 346 |   SELECT\n 347 |     cust_id,\n 348 |     run_date,\n 349 |     gpt_1st_category_l2_index,\n 350 |     sndr_category_txn_num_30d,\n 351 |     sndr_category_txn_num_180d,\n 352 |     sndr_category_txn_num_365d\n 353 |   FROM\n 354 |     {bq_prefix}driver_combine_category_agg_4\n 355 |   WHERE\n 356 |     sndr_category_txn_num_30d_freq_rank=2 ) cat_freq_30d_2\n 357 | ON\n 358 |   a.cust_id=cat_freq_30d_2.cust_id\n 359 |   AND a.run_date=cat_freq_30d_2.run_date\n 360 | LEFT JOIN (\n 361 |   SELECT\n 362 |     cust_id,\n 363 |     run_date,\n 364 |     gpt_1st_category_l2_index,\n 365 |     sndr_category_txn_num_30d,\n 366 |     sndr_category_txn_num_180d,\n 367 |     sndr_category_txn_num_365d\n 368 |   FROM\n 369 |     {bq_prefix}driver_combine_category_agg_4\n 370 |   WHERE\n 371 |     sndr_category_txn_num_30d_freq_rank=3 ) cat_freq_30d_3\n 372 | ON\n 373 |   a.cust_id=cat_freq_30d_3.cust_id\n 374 |   AND a.run_date=cat_freq_30d_3.run_date\n 375 | LEFT JOIN (\n 376 |   SELECT\n 377 |     cust_id,\n 378 |     run_date,\n 379 |     gpt_1st_category_l2_index,\n 380 |     sndr_category_txn_num_30d,\n 381 |     sndr_category_txn_num_180d,\n 382 |     sndr_category_txn_num_365d\n 383 |   FROM\n 384 |     {bq_prefix}driver_combine_category_agg_4\n 385 |   WHERE\n 386 |     sndr_category_txn_num_180d_freq_rank=1 ) cat_freq_180d_1\n 387 | ON\n 388 |   a.cust_id=cat_freq_180d_1.cust_id\n 389 |   AND a.run_date=cat_freq_180d_1.run_date\n 390 | LEFT JOIN (\n 391 |   SELECT\n 392 |     cust_id,\n 393 |     run_date,\n 394 |     gpt_1st_category_l2_index,\n 395 |     sndr_category_txn_num_30d,\n 396 |     sndr_category_txn_num_180d,\n 397 |     sndr_category_txn_num_365d\n 398 |   FROM\n 399 |     {bq_prefix}driver_combine_category_agg_4\n 400 |   WHERE\n 401 |     sndr_category_txn_num_180d_freq_rank=2 ) cat_freq_180d_2\n 402 | ON\n 403 |   a.cust_id=cat_freq_180d_2.cust_id\n 404 |   AND a.run_date=cat_freq_180d_2.run_date\n 405 | LEFT JOIN (\n 406 |   SELECT\n 407 |     cust_id,\n 408 |     run_date,\n 409 |     gpt_1st_category_l2_index,\n 410 |     sndr_category_txn_num_30d,\n 411 |     sndr_category_txn_num_180d,\n 412 |     sndr_category_txn_num_365d\n 413 |   FROM\n 414 |     {bq_prefix}driver_combine_category_agg_4\n 415 |   WHERE\n 416 |     sndr_category_txn_num_180d_freq_rank=3 ) cat_freq_180d_3\n 417 | ON\n 418 |   a.cust_id=cat_freq_180d_3.cust_id\n 419 |   AND a.run_date=cat_freq_180d_3.run_date\n 420 | LEFT JOIN (\n 421 |   SELECT\n 422 |     cust_id,\n 423 |     run_date,\n 424 |     gpt_1st_category_l2_index,\n 425 |     sndr_category_txn_num_30d,\n 426 |     sndr_category_txn_num_180d,\n 427 |     sndr_category_txn_num_365d\n 428 |   FROM\n 429 |     {bq_prefix}driver_combine_category_agg_4\n 430 |   WHERE\n 431 |     sndr_category_txn_num_180d_freq_rank=1 ) cat_freq_365d_1\n 432 | ON\n 433 |   a.cust_id=cat_freq_365d_1.cust_id\n 434 |   AND a.run_date=cat_freq_365d_1.run_date\n 435 | LEFT JOIN (\n 436 |   SELECT\n 437 |     cust_id,\n 438 |     run_date,\n 439 |     gpt_1st_category_l2_index,\n 440 |     sndr_category_txn_num_30d,\n 441 |     sndr_category_txn_num_180d,\n 442 |     sndr_category_txn_num_365d\n 443 |   FROM\n 444 |     {bq_prefix}driver_combine_category_agg_4\n 445 |   WHERE\n 446 |     sndr_category_txn_num_180d_freq_rank=2 ) cat_freq_365d_2\n 447 | ON\n 448 |   a.cust_id=cat_freq_365d_2.cust_id\n 449 |   AND a.run_date=cat_freq_365d_2.run_date\n 450 | LEFT JOIN (\n 451 |   SELECT\n 452 |     cust_id,\n 453 |     run_date,\n 454 |     gpt_1st_category_l2_index,\n 455 |     sndr_category_txn_num_30d,\n 456 |     sndr_category_txn_num_180d,\n 457 |     sndr_category_txn_num_365d\n 458 |   FROM\n 459 |     {bq_prefix}driver_combine_category_agg_4\n 460 |   WHERE\n 461 |     sndr_category_txn_num_180d_freq_rank=3 ) cat_freq_365d_3\n 462 | ON\n 463 |   a.cust_id=cat_freq_365d_3.cust_id\n 464 |   AND a.run_date=cat_freq_365d_3.run_date;\n 465 | \"\"\"\n 466 | # %ppbq $q\n 467 | # # Merchant Info\n 468 | q=f\"\"\"drop table if exists {bq_prefix}driver_merchant_base;\n 469 | create table  {bq_prefix}driver_merchant_base as\n 470 | SELECT\n 471 |   rcvr_id,\n 472 |   run_date,\n 473 |   DATE_SUB(run_date,INTERVAL 30 DAY) AS run_date_30d\n 474 | FROM\n 475 |   {bq_prefix}driver_simu\n 476 | GROUP BY 1,2,3;\n 477 | \"\"\"\n 478 | # %ppbq $q\n 479 | q=f\"\"\"drop table if exists {bq_prefix}driver_merchant_base_txn_30d;\n 480 | create table  {bq_prefix}driver_merchant_base_txn_30d as\n 481 | SELECT\n 482 |   a.rcvr_id,\n 483 |   a.run_date,\n 484 |   b.tran_customer_id,\n 485 |   b.transaction_usd_equiv_amt\n 486 | FROM\n 487 |   {bq_prefix}driver_merchant_base AS a\n 488 | LEFT JOIN (\n 489 |   SELECT\n 490 |     tran_customer_id,\n 491 |     customer_counterparty,\n 492 |     transaction_created_date,\n 493 |     -0.01*transaction_usd_equiv_amt AS transaction_usd_equiv_amt,\n 494 |   FROM\n 495 |     pypl-edw.pp_access_views.dw_payment_sent\n 496 |   WHERE\n 497 |     transaction_status='S'\n 498 |     AND transaction_created_date>=DATE_SUB({config['driver_config']['train_start_date']},INTERVAL 30 DAY)\n 499 |     AND customer_counterparty IN (\n 500 |     SELECT DISTINCT rcvr_id FROM {bq_prefix}live_unique_merchants_train) \n 501 |     QUALIFY ROW_NUMBER() OVER (PARTITION BY payment_transid ORDER BY transaction_created_ts DESC)=1 )b\n 502 | ON\n 503 |   a.rcvr_id=b.customer_counterparty\n 504 | WHERE\n 505 |   a.run_date>b.transaction_created_date\n 506 |   AND a.run_date_30d<b.transaction_created_date;\n 507 | \"\"\"\n 508 | # %ppbq $q\n 509 | q=f\"\"\"drop table if exists {bq_prefix}driver_merchant_base_txn_30d_filter_sndr;\n 510 | create table  {bq_prefix}driver_merchant_base_txn_30d_filter_sndr as\n 511 | SELECT\n 512 |   a.rcvr_id,\n 513 |   a.run_date,\n 514 |   a.tran_customer_id,\n 515 |   a.transaction_usd_equiv_amt\n 516 | FROM\n 517 |   {bq_prefix}driver_merchant_base_txn_30d a\n 518 | JOIN\n 519 |   pypl-edw.pp_access_views.dim_cust b\n 520 | ON\n 521 |   a.tran_customer_id=b.cust_id\n 522 | WHERE\n 523 |   b.cust_acct_type_code IN (0,1);\n 524 | \"\"\"\n 525 | # %ppbq $q\n 526 | q=f\"\"\"drop table if exists {bq_prefix}driver_merchant_base_price_agg;\n 527 | create table  {bq_prefix}driver_merchant_base_price_agg as\n 528 | SELECT\n 529 |   rcvr_id,\n 530 |   run_date,\n 531 |   AVG(transaction_usd_equiv_amt) AS rcvr_avg_price_30d,\n 532 |   APPROX_QUANTILES(transaction_usd_equiv_amt, 100)[\n 533 | OFFSET\n 534 |   (10)] rcvr_price_10_penentile_30d,\n 535 |   APPROX_QUANTILES(transaction_usd_equiv_amt, 100)[\n 536 | OFFSET\n 537 |   (30)] rcvr_price_30_penentile_30d,\n 538 |   APPROX_QUANTILES(transaction_usd_equiv_amt, 100)[\n 539 | OFFSET\n 540 |   (50)] rcvr_price_50_penentile_30d,\n 541 |   APPROX_QUANTILES(transaction_usd_equiv_amt, 100)[\n 542 | OFFSET\n 543 |   (70)] rcvr_price_70_penentile_30d,\n 544 |   APPROX_QUANTILES(transaction_usd_equiv_amt, 100)[\n 545 | OFFSET\n 546 |   (90)] rcvr_price_90_penentile_30d\n 547 | FROM\n 548 |   {bq_prefix}driver_merchant_base_txn_30d_filter_sndr\n 549 | GROUP BY\n 550 |   1,\n 551 |   2;\n 552 | \"\"\"\n 553 | # %ppbq $q\n 554 | q=f\"\"\"drop table if exists {bq_prefix}driver_merchant_base_sales_agg;\n 555 | create table  {bq_prefix}driver_merchant_base_sales_agg as\n 556 | SELECT\n 557 |   rcvr_id,\n 558 |   run_date,\n 559 |   SUM(1) AS rcvr_rcvd_txn_num_30d,\n 560 |   COUNT(DISTINCT tran_customer_id) rcvr_rcvd_distinct_consumer_num_30d,\n 561 |   SUM(transaction_usd_equiv_amt) AS rcvr_rcvd_txn_amt_30d\n 562 | FROM\n 563 |   {bq_prefix}driver_merchant_base_txn_30d_filter_sndr\n 564 | GROUP BY\n 565 |   1,\n 566 |   2;\n 567 | \"\"\"\n 568 | # %ppbq $q\n 569 | q=f\"\"\"drop table if exists {bq_prefix}driver_elig_save_365d_category;\n 570 | create table {bq_prefix}driver_elig_save_365d_category as\n 571 | SELECT\n 572 |   a.cust_id,\n 573 |   a.run_date,\n 574 |   a.run_date_30d,\n 575 |   a.run_date_180d,\n 576 |   a.run_date_365d,\n 577 |   c.rcvr_id,\n 578 |   d.gpt_1st_category_l2_index,\n 579 |   b.evnt_dt,\n 580 |   b.save_cnt,\n 581 |   ROW_NUMBER() OVER (PARTITION BY a.cust_id, a.run_date ORDER BY b.evnt_dt DESC) AS recency_rank\n 582 | FROM\n 583 |   {bq_prefix}driver_consumer_base a\n 584 | JOIN (\n 585 |   SELECT\n 586 |     cust_id,\n 587 |     evnt_dt,\n 588 |     pp_merchant_id,\n 589 |     coalesce(saves_clk_unique_cnt,0)+coalesce(saves_outclick_unique_cnt,0)+coalesce(saves_save_unique_cnt,0) as save_cnt\n 590 |   FROM\n 591 |     pypl-edw.pp_scratch.tmp_offers_output_dedup_archive\n 592 |   WHERE\n 593 |     evnt_dt>=DATE_SUB('2023-12-31',INTERVAL 180 DAY)\n 594 |     AND (coalesce(saves_clk_unique_cnt,0)+coalesce(saves_outclick_unique_cnt,0)+coalesce(saves_save_unique_cnt,0)>0)\n 595 |     AND cust_id IN (\n 596 |     SELECT\n 597 |       cust_id\n 598 |     FROM\n 599 |       {bq_prefix}driver_consumer_base)\n 600 |     AND pp_merchant_id IN (\n 601 |     SELECT\n 602 |       encrypt_id\n 603 |     FROM\n 604 |       {bq_prefix}live_unique_merchants_train) )b\n 605 | ON\n 606 |   a.cust_id = b.cust_id\n 607 |   AND a.run_date>b.evnt_dt\n 608 |   AND a.run_date_180d<b.evnt_dt\n 609 | JOIN\n 610 |   {bq_prefix}live_unique_merchants_train c\n 611 | ON\n 612 |   b.pp_merchant_id=c.encrypt_id\n 613 | JOIN \n 614 |   pypl-bods.gds_pacman_prod.ql_store_rmr_gpt_category_l2_mapping d\n 615 | ON\n 616 |   c.gpt_1st_category_l2_index=d.gpt_1st_category_l2_index;\n 617 | \"\"\"\n 618 | # %ppbq $q\n 619 | q=f\"\"\"drop table if exists {bq_prefix}driver_elig_save_agg_00;\n 620 | create table  {bq_prefix}driver_elig_save_agg_00 as\n 621 | SELECT\n 622 |   cust_id,\n 623 |   rcvr_id,\n 624 |   run_date,\n 625 |   SUM(IF((evnt_dt>date_sub(run_date,INTERVAL 7 DAY)),save_cnt,0)) AS sndr_rcvr_num_save_7day,\n 626 |   SUM(IF((evnt_dt>run_date_30d),save_cnt,0)) AS sndr_rcvr_num_save_30day,\n 627 |   SUM(IF((evnt_dt>run_date_180d),save_cnt,0)) AS sndr_rcvr_num_save_180day\n 628 | FROM\n 629 |   {bq_prefix}driver_elig_save_365d_category\n 630 | GROUP BY 1,2,3;\n 631 | \"\"\"\n 632 | # %ppbq $q\n 633 | q=f\"\"\"drop table if exists {bq_prefix}driver_elig_save_agg_0;\n 634 | create table  {bq_prefix}driver_elig_save_agg_0 as\n 635 | SELECT\n 636 |   cust_id,\n 637 |   run_date,\n 638 |   SUM(IF((evnt_dt>date_sub(run_date,INTERVAL 7 DAY)),save_cnt,0)) AS sndr_num_save_7day,\n 639 |   SUM(IF((evnt_dt>run_date_30d),save_cnt,0)) AS sndr_num_save_30day,\n 640 |   SUM(IF((evnt_dt>run_date_180d),save_cnt,0)) AS sndr_num_save_180day\n 641 | FROM\n 642 |   {bq_prefix}driver_elig_save_365d_category\n 643 | GROUP BY 1,2;\n 644 | \"\"\"\n 645 | # %ppbq $q\n 646 | q=f\"\"\"drop table if exists {bq_prefix}driver_elig_save_agg_1;\n 647 | create table  {bq_prefix}driver_elig_save_agg_1 as\n 648 | SELECT\n 649 |   a.cust_id,\n 650 |   a.run_date,\n 651 |   COALESCE(last_1.rcvr_id,'0') AS sndr_last_save_1st_merchant_id,\n 652 |   COALESCE(last_2.rcvr_id,'0') AS sndr_last_save_2nd_merchant_id,\n 653 |   COALESCE(last_3.rcvr_id,'0') AS sndr_last_save_3rd_merchant_id,\n 654 |   COALESCE(last_4.rcvr_id,'0') AS sndr_last_save_4th_merchant_id,\n 655 |   COALESCE(last_5.rcvr_id,'0') AS sndr_last_save_5th_merchant_id\n 656 | FROM\n 657 |   {bq_prefix}driver_consumer_base a\n 658 | LEFT JOIN (\n 659 |   SELECT\n 660 |     cust_id,\n 661 |     run_date,\n 662 |     rcvr_id\n 663 |   FROM\n 664 |     {bq_prefix}driver_elig_save_365d_category\n 665 |   WHERE\n 666 |     recency_rank=1 ) last_1\n 667 | ON\n 668 |   a.cust_id=last_1.cust_id\n 669 |   AND a.run_date=last_1.run_date\n 670 | LEFT JOIN (\n 671 |   SELECT\n 672 |     cust_id,\n 673 |     run_date,\n 674 |     rcvr_id\n 675 |   FROM\n 676 |     {bq_prefix}driver_elig_save_365d_category\n 677 |   WHERE\n 678 |     recency_rank=2 ) last_2\n 679 | ON\n 680 |   a.cust_id=last_2.cust_id\n 681 |   AND a.run_date=last_2.run_date\n 682 | LEFT JOIN (\n 683 |   SELECT\n 684 |     cust_id,\n 685 |     run_date,\n 686 |     rcvr_id\n 687 |   FROM\n 688 |     {bq_prefix}driver_elig_save_365d_category\n 689 |   WHERE\n 690 |     recency_rank=3 ) last_3\n 691 | ON\n 692 |   a.cust_id=last_3.cust_id\n 693 |   AND a.run_date=last_3.run_date\n 694 | LEFT JOIN (\n 695 |   SELECT\n 696 |     cust_id,\n 697 |     run_date,\n 698 |     rcvr_id\n 699 |   FROM\n 700 |     {bq_prefix}driver_elig_save_365d_category\n 701 |   WHERE\n 702 |     recency_rank=4 ) last_4\n 703 | ON\n 704 |   a.cust_id=last_4.cust_id\n 705 |   AND a.run_date=last_4.run_date\n 706 | LEFT JOIN (\n 707 |   SELECT\n 708 |     cust_id,\n 709 |     run_date,\n 710 |     rcvr_id\n 711 |   FROM\n 712 |     {bq_prefix}driver_elig_save_365d_category\n 713 |   WHERE\n 714 |     recency_rank=5 ) last_5\n 715 | ON\n 716 |   a.cust_id=last_5.cust_id\n 717 |   AND a.run_date=last_5.run_date;\n 718 | \"\"\"\n 719 | # %ppbq $q\n 720 | q=f\"\"\"drop table if exists {bq_prefix}driver_elig_save_agg_2;\n 721 | create table  {bq_prefix}driver_elig_save_agg_2 as\n 722 | SELECT\n 723 |   cust_id,\n 724 |   run_date,\n 725 |   gpt_1st_category_l2_index,\n 726 |   SUM(IF((evnt_dt>date_sub(run_date,INTERVAL 7 DAY)),save_cnt,0)) AS sndr_category_num_save_7day,\n 727 |   SUM(IF((evnt_dt>run_date_30d),save_cnt,0)) AS sndr_category_num_save_30day,\n 728 |   SUM(IF((evnt_dt>run_date_180d),save_cnt,0)) AS sndr_category_num_save_180day\n 729 | FROM\n 730 |   {bq_prefix}driver_elig_save_365d_category\n 731 | GROUP BY 1,2,3;\n 732 | \"\"\"\n 733 | # %ppbq $q\n 734 | q=f\"\"\"drop table if exists {bq_prefix}driver_elig_save_agg_3;\n 735 | create table  {bq_prefix}driver_elig_save_agg_3 as\n 736 | SELECT\n 737 |   a.cust_id,\n 738 |   a.run_date,\n 739 |   a.rcvr_id,\n 740 |   a.rcvr_gpt_1st_category_l2_index,\n 741 |   COALESCE(b.sndr_category_num_save_7day,0) AS sndr_rcvr_num_sameindustry_save_7day,\n 742 |   COALESCE(b.sndr_category_num_save_30day,0) AS sndr_rcvr_num_sameindustry_save_30day,\n 743 |   COALESCE(b.sndr_category_num_save_180day,0) AS sndr_rcvr_num_sameindustry_save_180day\n 744 | FROM\n 745 |   {bq_prefix}driver_combine_category a\n 746 | LEFT JOIN\n 747 |   {bq_prefix}driver_elig_save_agg_2 b\n 748 | ON\n 749 |   a.cust_id=b.cust_id\n 750 |   AND a.run_date=b.run_date\n 751 |   AND a.rcvr_gpt_1st_category_l2_index=b.gpt_1st_category_l2_index;\n 752 | \"\"\"\n 753 | # %ppbq $q\n 754 | q=f\"\"\"drop table if exists {bq_prefix}driver_merchant_base_click_save;\n 755 | create table  {bq_prefix}driver_merchant_base_click_save as\n 756 | with save_event as (\n 757 |     SELECT a.cust_id,a.evnt_dt,b.rcvr_id,a.placement,a.rfmbc_seg,\n 758 |     coalesce(saves_clk_unique_cnt,0)+coalesce(saves_outclick_unique_cnt,0)+coalesce(saves_save_unique_cnt,0) as save_cnt\n 759 |     FROM pypl-edw.pp_scratch.tmp_offers_output_dedup_archive a\n 760 |     JOIN {bq_prefix}live_unique_merchants_train b\n 761 |     ON a.pp_merchant_id=b.encrypt_id\n 762 |     WHERE a.cust_id IS NOT NULL\n 763 |     and a.cust_id<>'na'\n 764 |     and a.cust_id<>''\n 765 |     and a.pp_merchant_id is not null\n 766 |     AND a.evnt_dt>=DATE_SUB({config['driver_config']['train_start_date']}, INTERVAL 30 DAY)\n 767 |     AND coalesce(saves_clk_unique_cnt,0)+coalesce(saves_outclick_unique_cnt,0)+coalesce(saves_save_unique_cnt,0)>0\n 768 | ),\n 769 | merchant_stat as (\n 770 |     select a.rcvr_id,a.run_date,cust_id,placement,rfmbc_seg,evnt_dt\n 771 |     from {bq_prefix}driver_merchant_base a\n 772 |     join save_event\n 773 |     on a.rcvr_id = save_event.rcvr_id\n 774 |     and save_event.evnt_dt>=DATE_SUB(a.run_date,INTERVAL 30 DAY)\n 775 |     and save_event.evnt_dt<a.run_date\n 776 | )\n 777 | SELECT rcvr_id,run_date,\n 778 |   COUNT(DISTINCT cust_id) AS rcvr_save_cnt_30d,\n 779 |   COUNT(DISTINCT CASE WHEN placement='deals_explore_tertiary' then cust_id else null end) as rcvr_save_cnt_deals_explore_tertiary_30d,\n 780 |   COUNT(DISTINCT CASE WHEN placement='ql_home' then cust_id else null end) as rcvr_save_cnt_ql_home_30d,\n 781 |   COUNT(DISTINCT CASE WHEN placement='rewards_zone_new' then cust_id else null end) as rcvr_save_cnt_rewards_zone_new_30d,\n 782 |   COUNT(DISTINCT CASE WHEN placement='reboarding' then cust_id else null end) as rcvr_save_cnt_reboarding_30d,\n 783 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='High Engaged' then cust_id else null end) as rcvr_save_cnt_high_engaged_30d,\n 784 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='Mid Engaged' then cust_id else null end) as rcvr_save_cnt_mid_engaged_30d,\n 785 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='Low Engaged' then cust_id else null end) as rcvr_save_cnt_low_engaged_30d,\n 786 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='Likely To Churn' then cust_id else null end) as rcvr_save_cnt_likely_to_churn_30d,\n 787 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='New Not Active' then cust_id else null end) as rcvr_save_cnt_new_not_active_30d,\n 788 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='Never Active' then cust_id else null end) as rcvr_save_cnt_never_active_30d,\n 789 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='Churned' then cust_id else null end) as rcvr_save_cnt_churned_30d,\n 790 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='Re-engaged' then cust_id else null end) as rcvr_save_cnt_re_engaged_30d,\n 791 |   COUNT(DISTINCT CASE WHEN rfmbc_seg='New Active' then cust_id else null end) as rcvr_save_cnt_new_active_30d\n 792 | FROM merchant_stat\n 793 | GROUP BY 1,2;\n 794 | \"\"\"\n 795 | # %ppbq $q\n 796 | q=f\"\"\"drop table if exists {bq_prefix}driver_consumer_base_gender;\n 797 | create table  {bq_prefix}driver_consumer_base_gender as\n 798 | SELECT\n 799 |   a.cust_id,\n 800 |   max(c.gender) as gender\n 801 | FROM\n 802 |   {bq_prefix}driver_consumer_base a\n 803 | JOIN\n 804 |   pypl-edw.pp_access_pii_views.dim_cust b\n 805 | ON\n 806 |   a.cust_id=b.cust_id\n 807 | JOIN (\n 808 |   SELECT\n 809 |     cust_first_name,\n 810 |     MAX(gender) AS gender\n 811 |   FROM\n 812 |     pypl-bods.gds_pacman_prod.gender_brass_prediction_output\n 813 |   GROUP BY\n 814 |     1) c\n 815 | ON\n 816 |   LOWER(b.cust_first_name)=LOWER(c.cust_first_name)\n 817 | GROUP BY 1;\n 818 | \"\"\"\n 819 | # %ppbq $q",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/01_varmart_feat.py": "   1 | # %reload_ext cloudmagics.bigquery\n   2 | # %config PPMagics.domain=\"ccg24-hrzana-gds-pacman\"\n   3 | # %config PPMagics.autolimit = 0\n   4 | import aml.cloud_v1 as cloud\n   5 | cloud.notebook.authenticate_user()\n   6 | import json\n   7 | import os \n   8 | import sys\n   9 | os.environ[\"PYMLS_DEV_ENABLE\"] = 'false'\n  10 | # %ppauth\n  11 | # !gsutil rm -r gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_simu_consumer\n  12 | # !gsutil rm -r gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_simu_consumer_varmart\n  13 | # %%ppbq\n  14 | EXPORT DATA\n  15 | OPTIONS (\n  16 | uri = 'gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_simu_consumer/part*.parquet',\n  17 | format = 'parquet',\n  18 | overwrite = true)\n  19 | AS (\n  20 | SELECT *\n  21 | FROM pypl-bods.gds_pacman_prod.ql_store_rmr_driver_simu_consumer\n  22 | );\n  23 | import json\n  24 | import os \n  25 | import sys\n  26 | import datetime\n  27 | from pymls.component import Fetcher\n  28 | today = datetime.date.today()\n  29 | user = os.environ[\"USER\"]\n  30 | is_prod = 'True'\n  31 | stage = 'training'\n  32 | seq_num = today.strftime(\"%Y%m%d\")\n  33 | job_name = 'ql_store_rmr'\n  34 | fetcher = Fetcher(stage, seq_num, is_prod=is_prod)\n  35 | fetcher.job_name = 'ql_store_rmr'\n  36 | fetcher.group_name = 'mls_gads'\n  37 | fetcher.model_name = 'ql_store_rmr_datafetcher'\n  38 | fetcher.model_owner = 'chenzhao'\n  39 | fetcher.description = 'ranking_combined_datafetcher'\n  40 | fetcher.manager = 'Farhad'\n  41 | # -------- Component specific configs start here -------- \n  42 | # GCP Settings\n  43 | fetcher.on_gcp = True\n  44 | fetcher.gcp_project_id = 'ccg24-hrzana-gds-pacman'\n  45 | fetcher.gcs_bucket_name = 'pypl-bkt-rsh-row-std-gds-pacman'\n  46 | fetcher.bq_materialization_project = 'pypl-bods' \n  47 | fetcher.bq_materialization_dataset = 'rsh_row_gds_pacman' \n  48 | fetcher.driver_loc = \"gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_simu_consumer\" \n  49 | fetcher.data_loc = \"gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_simu_consumer_varmart\" \n  50 | fetcher.variables = [\n  51 | 'prmry_addr_state',\n  52 | 'days_on_file',\n  53 | 'ebay_member_y_n',\n  54 | 'consu_engagmnt_seg_key',\n  55 | 'prmry_cc_type_code',\n  56 | 'days_appweb_visit',\n  57 | 'consu_age_band_key',\n  58 | 'consu_income_band_key',\n  59 | 'consu_dmgrphc_seg_key'\n  60 | ]\n  61 | # Specify your split ratio here. Should add up to 1.0\n  62 | fetcher.split_ratio = {\"train\": 1.0}\n  63 | fetcher.num_of_splits = 1\n  64 | # default workspace is /home/[user]/mls_workspace\n  65 | # fetcher.workspace =\n  66 | # -------- Component specific configs end here -------- \n  67 | res = fetcher.run()\n  68 | # %%ppbq\n  69 | CREATE OR REPLACE EXTERNAL TABLE pypl-bods.gds_pacman_prod.ql_store_rmr_driver_simu_consumer_varmart_external\n  70 | OPTIONS (\n  71 |   format = \"PARQUET\",\n  72 |   uris = [\"gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_simu_consumer_varmart/all/parquet/part*\"]\n  73 | )",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/02_combine.py": "   1 | # %reload_ext cloudmagics.bigquery\n   2 | # %config PPMagics.domain=\"ccg24-hrzana-gds-pacman\"\n   3 | # %config PPMagics.autolimit = 0\n   4 | import yaml\n   5 | def load_yaml_file(file_path):\n   6 |     try:\n   7 |         with open(file_path, 'r') as file:\n   8 |             yaml_content = yaml.safe_load(file)\n   9 |         return yaml_content\n  10 |     except FileNotFoundError:\n  11 |         return None\n  12 | file_path = '../config/base_config.yaml'\n  13 | config = load_yaml_file(file_path)\n  14 | if config is not None:\n  15 | bq_prefix = config['general_config']['bq_project_dataset_prefix']\n  16 | bq_prefix\n  17 | q=f\"\"\"drop table if exists {bq_prefix}driver_dev_features;\n  18 | create table  {bq_prefix}driver_dev_features as\n  19 | SELECT\n  20 |   t.*,\n  21 |   COALESCE(sndr_rcvr_txn_num_30d,0) AS sndr_rcvr_txn_num_30d,\n  22 |   COALESCE(sndr_rcvr_txn_num_180d,0) AS sndr_rcvr_txn_num_180d,\n  23 |   COALESCE(sndr_rcvr_txn_num_365d,0) AS sndr_rcvr_txn_num_365d,\n  24 |   COALESCE(sndr_rcvr_txn_amt_30d,0) AS sndr_rcvr_txn_amt_30d,\n  25 |   COALESCE(sndr_rcvr_txn_amt_180d,0) AS sndr_rcvr_txn_amt_180d,\n  26 |   COALESCE(sndr_rcvr_txn_amt_365d,0) AS sndr_rcvr_txn_amt_365d,\n  27 |   COALESCE(sndr_last_5_txn_avg_amt,0) AS sndr_last_5_txn_avg_amt,\n  28 |   COALESCE(sndr_last_10_txn_avg_amt,0) AS sndr_last_10_txn_avg_amt,\n  29 |   COALESCE(sndr_most_recent_100_merch_list,'0') as sndr_most_recent_100_merch_list,\n  30 |   COALESCE(sndr_most_recent_100_merch_category,'0') as sndr_most_recent_100_merch_category,\n  31 |   COALESCE(sndr_rcvr_category_breadth_30d,0) AS sndr_rcvr_category_breadth_30d,\n  32 |   COALESCE(sndr_rcvr_category_breadth_180d,0) AS sndr_rcvr_category_breadth_180d,\n  33 |   COALESCE(sndr_rcvr_category_breadth_365d,0) AS sndr_rcvr_category_breadth_365d,\n  34 |   COALESCE(sndr_rcvr_category_txn_num_30d,0) AS sndr_rcvr_category_txn_num_30d,\n  35 |   COALESCE(sndr_rcvr_category_txn_num_180d,0) AS sndr_rcvr_category_txn_num_180d,\n  36 |   COALESCE(sndr_rcvr_category_txn_num_365d,0) AS sndr_rcvr_category_txn_num_365d,\n  37 |   COALESCE(sndr_rcvr_category_txn_amt_30d,0) AS sndr_rcvr_category_txn_amt_30d,\n  38 |   COALESCE(sndr_rcvr_category_txn_amt_180d,0) AS sndr_rcvr_category_txn_amt_180d,\n  39 |   COALESCE(sndr_rcvr_category_txn_amt_365d,0) AS sndr_rcvr_category_txn_amt_365d,\n  40 |   COALESCE(sndr_rcvr_category_avg_txn_amt_30d,0) AS sndr_rcvr_category_avg_txn_amt_30d,\n  41 |   COALESCE(sndr_rcvr_category_avg_txn_amt_180d,0) AS sndr_rcvr_category_avg_txn_amt_180d,\n  42 |   COALESCE(sndr_rcvr_category_avg_txn_amt_365d,0) AS sndr_rcvr_category_avg_txn_amt_365d,\n  43 |   COALESCE(sndr_1st_freq_merchant_category_30d, 0) AS sndr_1st_freq_merchant_category_30d,\n  44 |   COALESCE(sndr_2nd_freq_merchant_category_30d, 0) AS sndr_2nd_freq_merchant_category_30d,\n  45 |   COALESCE(sndr_3rd_freq_merchant_category_30d, 0) AS sndr_3rd_freq_merchant_category_30d,\n  46 |   COALESCE(sndr_1st_freq_merchant_category_180d, 0) AS sndr_1st_freq_merchant_category_180d,\n  47 |   COALESCE(sndr_2nd_freq_merchant_category_180d, 0) AS sndr_2nd_freq_merchant_category_180d,\n  48 |   COALESCE(sndr_3rd_freq_merchant_category_180d, 0) AS sndr_3rd_freq_merchant_category_180d,\n  49 |   COALESCE(sndr_1st_freq_merchant_category_365d, 0) AS sndr_1st_freq_merchant_category_365d,\n  50 |   COALESCE(sndr_2nd_freq_merchant_category_365d, 0) AS sndr_2nd_freq_merchant_category_365d,\n  51 |   COALESCE(sndr_3rd_freq_merchant_category_365d, 0) AS sndr_3rd_freq_merchant_category_365d,\n  52 |   COALESCE(sndr_1st_freq_merchant_category_cnt_30d, 0) AS sndr_1st_freq_merchant_category_cnt_30d,\n  53 |   COALESCE(sndr_2nd_freq_merchant_category_cnt_30d, 0) AS sndr_2nd_freq_merchant_category_cnt_30d,\n  54 |   COALESCE(sndr_3rd_freq_merchant_category_cnt_30d, 0) AS sndr_3rd_freq_merchant_category_cnt_30d,\n  55 |   COALESCE(sndr_1st_freq_merchant_category_cnt_180d, 0) AS sndr_1st_freq_merchant_category_cnt_180d,\n  56 |   COALESCE(sndr_2nd_freq_merchant_category_cnt_180d, 0) AS sndr_2nd_freq_merchant_category_cnt_180d,\n  57 |   COALESCE(sndr_3rd_freq_merchant_category_cnt_180d, 0) AS sndr_3rd_freq_merchant_category_cnt_180d,\n  58 |   COALESCE(sndr_1st_freq_merchant_category_cnt_365d, 0) AS sndr_1st_freq_merchant_category_cnt_365d,\n  59 |   COALESCE(sndr_2nd_freq_merchant_category_cnt_365d, 0) AS sndr_2nd_freq_merchant_category_cnt_365d,\n  60 |   COALESCE(sndr_3rd_freq_merchant_category_cnt_365d, 0) AS sndr_3rd_freq_merchant_category_cnt_365d,\n  61 |   COALESCE(rcvr_avg_price_30d,0) AS rcvr_avg_price_30d,\n  62 |   COALESCE(rcvr_price_10_penentile_30d,0) AS rcvr_price_10_penentile_30d,\n  63 |   COALESCE(rcvr_price_30_penentile_30d,0) AS rcvr_price_30_penentile_30d,\n  64 |   COALESCE(rcvr_price_50_penentile_30d,0) AS rcvr_price_50_penentile_30d,\n  65 |   COALESCE(rcvr_price_70_penentile_30d,0) AS rcvr_price_70_penentile_30d,\n  66 |   COALESCE(rcvr_price_90_penentile_30d,0) AS rcvr_price_90_penentile_30d,\n  67 |   COALESCE(rcvr_rcvd_txn_num_30d,0) AS rcvr_rcvd_txn_num_30d,\n  68 |   COALESCE(rcvr_rcvd_distinct_consumer_num_30d,0) AS rcvr_rcvd_distinct_consumer_num_30d,\n  69 |   COALESCE(rcvr_rcvd_txn_amt_30d,0) AS rcvr_rcvd_txn_amt_30d,\n  70 |   ABS(COALESCE(sndr_last_1_txn_amt,0)-COALESCE(rcvr_avg_price_30d,0)) AS sndr_last_1_txn_avg_amt_rcvr_avg_price_diff,\n  71 |   ABS(COALESCE(sndr_last_1_txn_amt,0)-COALESCE(rcvr_price_50_penentile_30d,0)) AS sndr_last_1_txn_avg_amt_rcvr_median_price_diff,\n  72 |   ABS(COALESCE(sndr_last_5_txn_avg_amt,0)-COALESCE(rcvr_avg_price_30d,0)) AS sndr_last_5_txn_avg_amt_rcvr_avg_price_diff,\n  73 |   ABS(COALESCE(sndr_last_5_txn_avg_amt,0)-COALESCE(rcvr_price_50_penentile_30d,0)) AS sndr_last_5_txn_avg_amt_rcvr_median_price_diff,\n  74 |   ABS(COALESCE(sndr_last_10_txn_avg_amt,0)-COALESCE(rcvr_avg_price_30d,0)) AS sndr_last_10_txn_avg_amt_rcvr_avg_price_diff,\n  75 |   ABS(COALESCE(sndr_last_10_txn_avg_amt,0)-COALESCE(rcvr_price_50_penentile_30d,0)) AS sndr_last_10_txn_avg_amt_rcvr_median_price_diff,\n  76 |   COALESCE(sndr_rcvr_num_save_7day,0) AS sndr_rcvr_num_save_7day,\n  77 |   COALESCE(sndr_rcvr_num_save_30day,0) AS sndr_rcvr_num_save_30day,\n  78 |   COALESCE(sndr_rcvr_num_save_180day,0) AS sndr_rcvr_num_save_180day,\n  79 |   COALESCE(sndr_num_save_7day,0) AS sndr_num_save_7day,\n  80 |   COALESCE(sndr_num_save_30day,0) AS sndr_num_save_30day,\n  81 |   COALESCE(sndr_num_save_180day,0) AS sndr_num_save_180day,\n  82 |   COALESCE(sndr_rcvr_num_sameindustry_save_7day, 0) AS sndr_rcvr_num_sameindustry_save_7day,\n  83 |   COALESCE(sndr_rcvr_num_sameindustry_save_30day, 0) AS sndr_rcvr_num_sameindustry_save_30day,\n  84 |   COALESCE(sndr_rcvr_num_sameindustry_save_180day, 0) AS sndr_rcvr_num_sameindustry_save_180day,\n  85 |   COALESCE(rcvr_save_cnt_30d, 0) AS rcvr_save_cnt_30d,\n  86 |   COALESCE(rcvr_save_cnt_deals_explore_tertiary_30d,0) AS rcvr_save_cnt_deals_explore_tertiary_30d,\n  87 |   COALESCE(rcvr_save_cnt_ql_home_30d,0) AS rcvr_save_cnt_ql_home_30d,\n  88 |   COALESCE(rcvr_save_cnt_rewards_zone_new_30d,0) AS rcvr_save_cnt_rewards_zone_new_30d,\n  89 |   COALESCE(rcvr_save_cnt_reboarding_30d,0) AS rcvr_save_cnt_reboarding_30d,\n  90 |   COALESCE(rcvr_save_cnt_high_engaged_30d,0) AS rcvr_save_cnt_high_engaged_30d,\n  91 |   COALESCE(rcvr_save_cnt_mid_engaged_30d,0) AS rcvr_save_cnt_mid_engaged_30d,\n  92 |   COALESCE(rcvr_save_cnt_low_engaged_30d,0) AS rcvr_save_cnt_low_engaged_30d,\n  93 |   COALESCE(rcvr_save_cnt_likely_to_churn_30d,0) AS rcvr_save_cnt_likely_to_churn_30d,\n  94 |   COALESCE(rcvr_save_cnt_new_not_active_30d,0) AS rcvr_save_cnt_new_not_active_30d,\n  95 |   COALESCE(rcvr_save_cnt_never_active_30d,0) AS rcvr_save_cnt_never_active_30d,\n  96 |   COALESCE(rcvr_save_cnt_churned_30d,0) AS rcvr_save_cnt_churned_30d,\n  97 |   COALESCE(rcvr_save_cnt_re_engaged_30d,0) AS rcvr_save_cnt_re_engaged_30d,\n  98 |   COALESCE(rcvr_save_cnt_new_active_30d,0) AS rcvr_save_cnt_new_active_30d,\n  99 |   COALESCE(gender,'unknown') as gender,\n 100 |   COALESCE(score_transformed,0) as rcvr_tpv_score,\n 101 |   COALESCE(consu_engagmnt_seg_key,0) as sndr_consu_engagmnt_seg_key,\n 102 |   COALESCE(days_on_file,0) as sndr_days_on_file,\n 103 |   COALESCE(ebay_member_y_n,'unknown') as sndr_ebay_member_y_n,\n 104 |   COALESCE(prmry_cc_type_code,'#') as sndr_prmry_cc_type_code,\n 105 |   COALESCE(prmry_addr_state,'#') as sndr_prmry_addr_state,\n 106 |   COALESCE(days_appweb_visit,0) as sndr_days_appweb_visit,\n 107 |   COALESCE(consu_age_band_key,-99) as sndr_consu_age_band_key,\n 108 |   COALESCE(consu_dmgrphc_seg_key,-99) as sndr_consu_dmgrphc_seg_key,\n 109 |   COALESCE(embedding_1,0) AS embedding_1,\n 110 |   COALESCE(embedding_2,0) AS embedding_2,\n 111 |   COALESCE(embedding_3,0) AS embedding_3,\n 112 |   COALESCE(embedding_4,0) AS embedding_4,\n 113 |   COALESCE(embedding_5,0) AS embedding_5,\n 114 |   COALESCE(embedding_6,0) AS embedding_6,\n 115 |   COALESCE(embedding_7,0) AS embedding_7,\n 116 |   COALESCE(embedding_8,0) AS embedding_8,\n 117 |   COALESCE(embedding_9,0) AS embedding_9,\n 118 |   COALESCE(embedding_10,0) AS embedding_10,\n 119 |   COALESCE(embedding_11,0) AS embedding_11,\n 120 |   COALESCE(embedding_12,0) AS embedding_12,\n 121 |   COALESCE(embedding_13,0) AS embedding_13,\n 122 |   COALESCE(embedding_14,0) AS embedding_14,\n 123 |   COALESCE(embedding_15,0) AS embedding_15,\n 124 |   COALESCE(embedding_16,0) AS embedding_16,\n 125 |   COALESCE(embedding_17,0) AS embedding_17,\n 126 |   COALESCE(embedding_18,0) AS embedding_18,\n 127 |   COALESCE(embedding_19,0) AS embedding_19,\n 128 |   COALESCE(embedding_20,0) AS embedding_20,\n 129 |   COALESCE(embedding_21,0) AS embedding_21,\n 130 |   COALESCE(embedding_22,0) AS embedding_22,\n 131 |   COALESCE(embedding_23,0) AS embedding_23,\n 132 |   COALESCE(embedding_24,0) AS embedding_24,\n 133 |   COALESCE(embedding_25,0) AS embedding_25,\n 134 |   COALESCE(embedding_26,0) AS embedding_26,\n 135 |   COALESCE(embedding_27,0) AS embedding_27,\n 136 |   COALESCE(embedding_28,0) AS embedding_28,\n 137 |   COALESCE(embedding_29,0) AS embedding_29,\n 138 |   COALESCE(embedding_30,0) AS embedding_30,\n 139 |   COALESCE(embedding_31,0) AS embedding_31,\n 140 |   COALESCE(embedding_32,0) AS embedding_32\n 141 | FROM\n 142 |   {bq_prefix}driver_dev t\n 143 | LEFT JOIN\n 144 |   {bq_prefix}driver_simu_txn_365d_agg t1\n 145 | ON\n 146 |   t.cust_id=t1.cust_id\n 147 |   AND t.rcvr_id=t1.rcvr_id\n 148 |   AND cast(t.run_date as string)=cast(t1.run_date as string)\n 149 | LEFT JOIN\n 150 |   {bq_prefix}driver_consumer_base_last_10_txn t2\n 151 | ON\n 152 |   t.cust_id=t2.cust_id\n 153 |   AND cast(t.run_date as string)=cast(t2.run_date as string)\n 154 | LEFT JOIN\n 155 |   {bq_prefix}driver_consumer_base_all_history_array t3\n 156 | ON\n 157 |   t.cust_id=t3.cust_id\n 158 |   AND cast(t.run_date as string)=cast(t3.run_date as string)\n 159 | LEFT JOIN\n 160 |   {bq_prefix}driver_combine_category_agg_3 t4\n 161 | ON\n 162 |   t.cust_id=t4.cust_id\n 163 |   AND t.rcvr_id=t4.rcvr_id\n 164 |   AND cast(t.run_date as string)=cast(t4.run_date as string)\n 165 | LEFT JOIN\n 166 |   {bq_prefix}driver_combine_category_agg_5 t5\n 167 | ON\n 168 |   t.cust_id=t5.cust_id\n 169 |   AND cast(t.run_date as string)=cast(t5.run_date as string)\n 170 | LEFT JOIN\n 171 |   {bq_prefix}driver_merchant_base_price_agg t6\n 172 | ON\n 173 |   t.rcvr_id=t6.rcvr_id\n 174 |   AND cast(t.run_date as string)=cast(t6.run_date as string)\n 175 | LEFT JOIN\n 176 |   {bq_prefix}driver_merchant_base_sales_agg t7\n 177 | ON\n 178 |   t.rcvr_id=t7.rcvr_id\n 179 |   AND cast(t.run_date as string)=cast(t7.run_date as string)\n 180 | LEFT JOIN\n 181 |   {bq_prefix}driver_elig_save_agg_00 t8\n 182 | ON\n 183 |   t.cust_id=t8.cust_id\n 184 |   AND t.rcvr_id=t8.rcvr_id\n 185 |   AND cast(t.run_date as string)=cast(t8.run_date as string)\n 186 | LEFT JOIN\n 187 |   {bq_prefix}driver_elig_save_agg_0 t9\n 188 | ON\n 189 |   t.cust_id=t9.cust_id\n 190 |   AND cast(t.run_date as string)=cast(t9.run_date as string)\n 191 | LEFT JOIN\n 192 |   {bq_prefix}driver_elig_save_agg_3 t10\n 193 | ON\n 194 |   t.cust_id=t10.cust_id\n 195 |   AND t.rcvr_id=t10.rcvr_id\n 196 |   AND cast(t.run_date as string)=cast(t10.run_date as string)\n 197 | LEFT JOIN\n 198 |   {bq_prefix}driver_merchant_base_click_save t11\n 199 | ON\n 200 |   t.rcvr_id=t11.rcvr_id\n 201 |   AND cast(t.run_date as string)=cast(t11.run_date as string)\n 202 | LEFT JOIN\n 203 |   {bq_prefix}driver_consumer_base_gender t12\n 204 | ON\n 205 |   t.cust_id=t12.cust_id\n 206 | LEFT JOIN pypl-bods.gds_pacman_prod.ql_store_honey_merch_quality_scores_external t13\n 207 | ON \n 208 |   t.rcvr_id=t13.rcvr_id\n 209 | LEFT JOIN {bq_prefix}driver_simu_consumer_varmart_external t14\n 210 | ON\n 211 |   t.cust_id=t14.cust_id\n 212 |   and cast(t.run_date as string)=cast(t14.run_date as string)\n 213 | LEFT JOIN pypl-bods.gds_pacman_prod.store_recommendation_kg_embedding_32_v2 t15\n 214 | ON\n 215 |   t.rcvr_id=t15.rcvr_id\n 216 | ;\n 217 | \"\"\"\n 218 | # %ppbq $q\n 219 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_features;\n 220 | create table {bq_prefix}driver_oot_features as\n 221 | SELECT\n 222 |   t.*,\n 223 |   COALESCE(sndr_rcvr_txn_num_30d,0) AS sndr_rcvr_txn_num_30d,\n 224 |   COALESCE(sndr_rcvr_txn_num_180d,0) AS sndr_rcvr_txn_num_180d,\n 225 |   COALESCE(sndr_rcvr_txn_num_365d,0) AS sndr_rcvr_txn_num_365d,\n 226 |   COALESCE(sndr_rcvr_txn_amt_30d,0) AS sndr_rcvr_txn_amt_30d,\n 227 |   COALESCE(sndr_rcvr_txn_amt_180d,0) AS sndr_rcvr_txn_amt_180d,\n 228 |   COALESCE(sndr_rcvr_txn_amt_365d,0) AS sndr_rcvr_txn_amt_365d,\n 229 |   COALESCE(sndr_last_5_txn_avg_amt,0) AS sndr_last_5_txn_avg_amt,\n 230 |   COALESCE(sndr_last_10_txn_avg_amt,0) AS sndr_last_10_txn_avg_amt,\n 231 |   COALESCE(sndr_most_recent_100_merch_list,'0') as sndr_most_recent_100_merch_list,\n 232 |   COALESCE(sndr_most_recent_100_merch_category,'0') as sndr_most_recent_100_merch_category,\n 233 |   COALESCE(sndr_rcvr_category_breadth_30d,0) AS sndr_rcvr_category_breadth_30d,\n 234 |   COALESCE(sndr_rcvr_category_breadth_180d,0) AS sndr_rcvr_category_breadth_180d,\n 235 |   COALESCE(sndr_rcvr_category_breadth_365d,0) AS sndr_rcvr_category_breadth_365d,\n 236 |   COALESCE(sndr_rcvr_category_txn_num_30d,0) AS sndr_rcvr_category_txn_num_30d,\n 237 |   COALESCE(sndr_rcvr_category_txn_num_180d,0) AS sndr_rcvr_category_txn_num_180d,\n 238 |   COALESCE(sndr_rcvr_category_txn_num_365d,0) AS sndr_rcvr_category_txn_num_365d,\n 239 |   COALESCE(sndr_rcvr_category_txn_amt_30d,0) AS sndr_rcvr_category_txn_amt_30d,\n 240 |   COALESCE(sndr_rcvr_category_txn_amt_180d,0) AS sndr_rcvr_category_txn_amt_180d,\n 241 |   COALESCE(sndr_rcvr_category_txn_amt_365d,0) AS sndr_rcvr_category_txn_amt_365d,\n 242 |   COALESCE(sndr_rcvr_category_avg_txn_amt_30d,0) AS sndr_rcvr_category_avg_txn_amt_30d,\n 243 |   COALESCE(sndr_rcvr_category_avg_txn_amt_180d,0) AS sndr_rcvr_category_avg_txn_amt_180d,\n 244 |   COALESCE(sndr_rcvr_category_avg_txn_amt_365d,0) AS sndr_rcvr_category_avg_txn_amt_365d,\n 245 |   COALESCE(sndr_1st_freq_merchant_category_30d, 0) AS sndr_1st_freq_merchant_category_30d,\n 246 |   COALESCE(sndr_2nd_freq_merchant_category_30d, 0) AS sndr_2nd_freq_merchant_category_30d,\n 247 |   COALESCE(sndr_3rd_freq_merchant_category_30d, 0) AS sndr_3rd_freq_merchant_category_30d,\n 248 |   COALESCE(sndr_1st_freq_merchant_category_180d, 0) AS sndr_1st_freq_merchant_category_180d,\n 249 |   COALESCE(sndr_2nd_freq_merchant_category_180d, 0) AS sndr_2nd_freq_merchant_category_180d,\n 250 |   COALESCE(sndr_3rd_freq_merchant_category_180d, 0) AS sndr_3rd_freq_merchant_category_180d,\n 251 |   COALESCE(sndr_1st_freq_merchant_category_365d, 0) AS sndr_1st_freq_merchant_category_365d,\n 252 |   COALESCE(sndr_2nd_freq_merchant_category_365d, 0) AS sndr_2nd_freq_merchant_category_365d,\n 253 |   COALESCE(sndr_3rd_freq_merchant_category_365d, 0) AS sndr_3rd_freq_merchant_category_365d,\n 254 |   COALESCE(sndr_1st_freq_merchant_category_cnt_30d, 0) AS sndr_1st_freq_merchant_category_cnt_30d,\n 255 |   COALESCE(sndr_2nd_freq_merchant_category_cnt_30d, 0) AS sndr_2nd_freq_merchant_category_cnt_30d,\n 256 |   COALESCE(sndr_3rd_freq_merchant_category_cnt_30d, 0) AS sndr_3rd_freq_merchant_category_cnt_30d,\n 257 |   COALESCE(sndr_1st_freq_merchant_category_cnt_180d, 0) AS sndr_1st_freq_merchant_category_cnt_180d,\n 258 |   COALESCE(sndr_2nd_freq_merchant_category_cnt_180d, 0) AS sndr_2nd_freq_merchant_category_cnt_180d,\n 259 |   COALESCE(sndr_3rd_freq_merchant_category_cnt_180d, 0) AS sndr_3rd_freq_merchant_category_cnt_180d,\n 260 |   COALESCE(sndr_1st_freq_merchant_category_cnt_365d, 0) AS sndr_1st_freq_merchant_category_cnt_365d,\n 261 |   COALESCE(sndr_2nd_freq_merchant_category_cnt_365d, 0) AS sndr_2nd_freq_merchant_category_cnt_365d,\n 262 |   COALESCE(sndr_3rd_freq_merchant_category_cnt_365d, 0) AS sndr_3rd_freq_merchant_category_cnt_365d,\n 263 |   COALESCE(rcvr_avg_price_30d,0) AS rcvr_avg_price_30d,\n 264 |   COALESCE(rcvr_price_10_penentile_30d,0) AS rcvr_price_10_penentile_30d,\n 265 |   COALESCE(rcvr_price_30_penentile_30d,0) AS rcvr_price_30_penentile_30d,\n 266 |   COALESCE(rcvr_price_50_penentile_30d,0) AS rcvr_price_50_penentile_30d,\n 267 |   COALESCE(rcvr_price_70_penentile_30d,0) AS rcvr_price_70_penentile_30d,\n 268 |   COALESCE(rcvr_price_90_penentile_30d,0) AS rcvr_price_90_penentile_30d,\n 269 |   COALESCE(rcvr_rcvd_txn_num_30d,0) AS rcvr_rcvd_txn_num_30d,\n 270 |   COALESCE(rcvr_rcvd_distinct_consumer_num_30d,0) AS rcvr_rcvd_distinct_consumer_num_30d,\n 271 |   COALESCE(rcvr_rcvd_txn_amt_30d,0) AS rcvr_rcvd_txn_amt_30d,\n 272 |   ABS(COALESCE(sndr_last_1_txn_amt,0)-COALESCE(rcvr_avg_price_30d,0)) AS sndr_last_1_txn_avg_amt_rcvr_avg_price_diff,\n 273 |   ABS(COALESCE(sndr_last_1_txn_amt,0)-COALESCE(rcvr_price_50_penentile_30d,0)) AS sndr_last_1_txn_avg_amt_rcvr_median_price_diff,\n 274 |   ABS(COALESCE(sndr_last_5_txn_avg_amt,0)-COALESCE(rcvr_avg_price_30d,0)) AS sndr_last_5_txn_avg_amt_rcvr_avg_price_diff,\n 275 |   ABS(COALESCE(sndr_last_5_txn_avg_amt,0)-COALESCE(rcvr_price_50_penentile_30d,0)) AS sndr_last_5_txn_avg_amt_rcvr_median_price_diff,\n 276 |   ABS(COALESCE(sndr_last_10_txn_avg_amt,0)-COALESCE(rcvr_avg_price_30d,0)) AS sndr_last_10_txn_avg_amt_rcvr_avg_price_diff,\n 277 |   ABS(COALESCE(sndr_last_10_txn_avg_amt,0)-COALESCE(rcvr_price_50_penentile_30d,0)) AS sndr_last_10_txn_avg_amt_rcvr_median_price_diff,\n 278 |   COALESCE(sndr_rcvr_num_save_7day,0) AS sndr_rcvr_num_save_7day,\n 279 |   COALESCE(sndr_rcvr_num_save_30day,0) AS sndr_rcvr_num_save_30day,\n 280 |   COALESCE(sndr_rcvr_num_save_180day,0) AS sndr_rcvr_num_save_180day,\n 281 |   COALESCE(sndr_num_save_7day,0) AS sndr_num_save_7day,\n 282 |   COALESCE(sndr_num_save_30day,0) AS sndr_num_save_30day,\n 283 |   COALESCE(sndr_num_save_180day,0) AS sndr_num_save_180day,\n 284 |   COALESCE(sndr_rcvr_num_sameindustry_save_7day, 0) AS sndr_rcvr_num_sameindustry_save_7day,\n 285 |   COALESCE(sndr_rcvr_num_sameindustry_save_30day, 0) AS sndr_rcvr_num_sameindustry_save_30day,\n 286 |   COALESCE(sndr_rcvr_num_sameindustry_save_180day, 0) AS sndr_rcvr_num_sameindustry_save_180day,\n 287 |   COALESCE(rcvr_save_cnt_30d, 0) AS rcvr_save_cnt_30d,\n 288 |   COALESCE(rcvr_save_cnt_deals_explore_tertiary_30d,0) AS rcvr_save_cnt_deals_explore_tertiary_30d,\n 289 |   COALESCE(rcvr_save_cnt_ql_home_30d,0) AS rcvr_save_cnt_ql_home_30d,\n 290 |   COALESCE(rcvr_save_cnt_rewards_zone_new_30d,0) AS rcvr_save_cnt_rewards_zone_new_30d,\n 291 |   COALESCE(rcvr_save_cnt_reboarding_30d,0) AS rcvr_save_cnt_reboarding_30d,\n 292 |   COALESCE(rcvr_save_cnt_high_engaged_30d,0) AS rcvr_save_cnt_high_engaged_30d,\n 293 |   COALESCE(rcvr_save_cnt_mid_engaged_30d,0) AS rcvr_save_cnt_mid_engaged_30d,\n 294 |   COALESCE(rcvr_save_cnt_low_engaged_30d,0) AS rcvr_save_cnt_low_engaged_30d,\n 295 |   COALESCE(rcvr_save_cnt_likely_to_churn_30d,0) AS rcvr_save_cnt_likely_to_churn_30d,\n 296 |   COALESCE(rcvr_save_cnt_new_not_active_30d,0) AS rcvr_save_cnt_new_not_active_30d,\n 297 |   COALESCE(rcvr_save_cnt_never_active_30d,0) AS rcvr_save_cnt_never_active_30d,\n 298 |   COALESCE(rcvr_save_cnt_churned_30d,0) AS rcvr_save_cnt_churned_30d,\n 299 |   COALESCE(rcvr_save_cnt_re_engaged_30d,0) AS rcvr_save_cnt_re_engaged_30d,\n 300 |   COALESCE(rcvr_save_cnt_new_active_30d,0) AS rcvr_save_cnt_new_active_30d,\n 301 |   COALESCE(gender,'unknown') as gender,\n 302 |   COALESCE(score_transformed,0) as rcvr_tpv_score,\n 303 |   COALESCE(consu_engagmnt_seg_key,0) as sndr_consu_engagmnt_seg_key,\n 304 |   COALESCE(days_on_file,0) as sndr_days_on_file,\n 305 |   COALESCE(ebay_member_y_n,'unknown') as sndr_ebay_member_y_n,\n 306 |   COALESCE(prmry_cc_type_code,'#') as sndr_prmry_cc_type_code,\n 307 |   COALESCE(prmry_addr_state,'#') as sndr_prmry_addr_state,\n 308 |   COALESCE(days_appweb_visit,0) as sndr_days_appweb_visit,\n 309 |   COALESCE(consu_age_band_key,-99) as sndr_consu_age_band_key,\n 310 |   COALESCE(consu_dmgrphc_seg_key,-99) as sndr_consu_dmgrphc_seg_key,\n 311 |   COALESCE(embedding_1,0) AS embedding_1,\n 312 |   COALESCE(embedding_2,0) AS embedding_2,\n 313 |   COALESCE(embedding_3,0) AS embedding_3,\n 314 |   COALESCE(embedding_4,0) AS embedding_4,\n 315 |   COALESCE(embedding_5,0) AS embedding_5,\n 316 |   COALESCE(embedding_6,0) AS embedding_6,\n 317 |   COALESCE(embedding_7,0) AS embedding_7,\n 318 |   COALESCE(embedding_8,0) AS embedding_8,\n 319 |   COALESCE(embedding_9,0) AS embedding_9,\n 320 |   COALESCE(embedding_10,0) AS embedding_10,\n 321 |   COALESCE(embedding_11,0) AS embedding_11,\n 322 |   COALESCE(embedding_12,0) AS embedding_12,\n 323 |   COALESCE(embedding_13,0) AS embedding_13,\n 324 |   COALESCE(embedding_14,0) AS embedding_14,\n 325 |   COALESCE(embedding_15,0) AS embedding_15,\n 326 |   COALESCE(embedding_16,0) AS embedding_16,\n 327 |   COALESCE(embedding_17,0) AS embedding_17,\n 328 |   COALESCE(embedding_18,0) AS embedding_18,\n 329 |   COALESCE(embedding_19,0) AS embedding_19,\n 330 |   COALESCE(embedding_20,0) AS embedding_20,\n 331 |   COALESCE(embedding_21,0) AS embedding_21,\n 332 |   COALESCE(embedding_22,0) AS embedding_22,\n 333 |   COALESCE(embedding_23,0) AS embedding_23,\n 334 |   COALESCE(embedding_24,0) AS embedding_24,\n 335 |   COALESCE(embedding_25,0) AS embedding_25,\n 336 |   COALESCE(embedding_26,0) AS embedding_26,\n 337 |   COALESCE(embedding_27,0) AS embedding_27,\n 338 |   COALESCE(embedding_28,0) AS embedding_28,\n 339 |   COALESCE(embedding_29,0) AS embedding_29,\n 340 |   COALESCE(embedding_30,0) AS embedding_30,\n 341 |   COALESCE(embedding_31,0) AS embedding_31,\n 342 |   COALESCE(embedding_32,0) AS embedding_32\n 343 | FROM\n 344 |   {bq_prefix}driver_oot t\n 345 | LEFT JOIN\n 346 |   {bq_prefix}driver_simu_txn_365d_agg t1\n 347 | ON\n 348 |   t.cust_id=t1.cust_id\n 349 |   AND t.rcvr_id=t1.rcvr_id\n 350 |   AND cast(t.run_date as string)=cast(t1.run_date as string)\n 351 | LEFT JOIN\n 352 |   {bq_prefix}driver_consumer_base_last_10_txn t2\n 353 | ON\n 354 |   t.cust_id=t2.cust_id\n 355 |   AND cast(t.run_date as string)=cast(t2.run_date as string)\n 356 | LEFT JOIN\n 357 |   {bq_prefix}driver_consumer_base_all_history_array t3\n 358 | ON\n 359 |   t.cust_id=t3.cust_id\n 360 |   AND cast(t.run_date as string)=cast(t3.run_date as string)\n 361 | LEFT JOIN\n 362 |   {bq_prefix}driver_combine_category_agg_3 t4\n 363 | ON\n 364 |   t.cust_id=t4.cust_id\n 365 |   AND t.rcvr_id=t4.rcvr_id\n 366 |   AND cast(t.run_date as string)=cast(t4.run_date as string)\n 367 | LEFT JOIN\n 368 |   {bq_prefix}driver_combine_category_agg_5 t5\n 369 | ON\n 370 |   t.cust_id=t5.cust_id\n 371 |   AND cast(t.run_date as string)=cast(t5.run_date as string)\n 372 | LEFT JOIN\n 373 |   {bq_prefix}driver_merchant_base_price_agg t6\n 374 | ON\n 375 |   t.rcvr_id=t6.rcvr_id\n 376 |   AND cast(t.run_date as string)=cast(t6.run_date as string)\n 377 | LEFT JOIN\n 378 |   {bq_prefix}driver_merchant_base_sales_agg t7\n 379 | ON\n 380 |   t.rcvr_id=t7.rcvr_id\n 381 |   AND cast(t.run_date as string)=cast(t7.run_date as string)\n 382 | LEFT JOIN\n 383 |   {bq_prefix}driver_elig_save_agg_00 t8\n 384 | ON\n 385 |   t.cust_id=t8.cust_id\n 386 |   AND t.rcvr_id=t8.rcvr_id\n 387 |   AND cast(t.run_date as string)=cast(t8.run_date as string)\n 388 | LEFT JOIN\n 389 |   {bq_prefix}driver_elig_save_agg_0 t9\n 390 | ON\n 391 |   t.cust_id=t9.cust_id\n 392 |   AND cast(t.run_date as string)=cast(t9.run_date as string)\n 393 | LEFT JOIN\n 394 |   {bq_prefix}driver_elig_save_agg_3 t10\n 395 | ON\n 396 |   t.cust_id=t10.cust_id\n 397 |   AND t.rcvr_id=t10.rcvr_id\n 398 |   AND cast(t.run_date as string)=cast(t10.run_date as string)\n 399 | LEFT JOIN\n 400 |   {bq_prefix}driver_merchant_base_click_save t11\n 401 | ON\n 402 |   t.rcvr_id=t11.rcvr_id\n 403 |   AND cast(t.run_date as string)=cast(t11.run_date as string)\n 404 | LEFT JOIN\n 405 |   {bq_prefix}driver_consumer_base_gender t12\n 406 | ON\n 407 |   t.cust_id=t12.cust_id\n 408 | LEFT JOIN pypl-bods.gds_pacman_prod.ql_store_honey_merch_quality_scores_external t13\n 409 | ON \n 410 |   t.rcvr_id=t13.rcvr_id\n 411 | LEFT JOIN {bq_prefix}driver_simu_consumer_varmart_external t14\n 412 | ON\n 413 |   t.cust_id=t14.cust_id\n 414 |   and cast(t.run_date as string)=cast(t14.run_date as string)\n 415 | LEFT JOIN pypl-bods.gds_pacman_prod.store_recommendation_kg_embedding_32_v2 t15\n 416 | ON\n 417 |   t.rcvr_id=t15.rcvr_id\n 418 | ;\n 419 | \"\"\"\n 420 | # %ppbq $q\n 421 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_features_expand_seq;\n 422 | create table {bq_prefix}driver_oot_features_expand_seq as\n 423 | select *,\n 424 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(0)], '0') AS hist_rcvr_id_1,\n 425 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(1)], '0') AS hist_rcvr_id_2,\n 426 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(2)], '0') AS hist_rcvr_id_3,\n 427 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(3)], '0') AS hist_rcvr_id_4,\n 428 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(4)], '0') AS hist_rcvr_id_5,\n 429 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(5)], '0') AS hist_rcvr_id_6,\n 430 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(6)], '0') AS hist_rcvr_id_7,\n 431 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(7)], '0') AS hist_rcvr_id_8,\n 432 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(8)], '0') AS hist_rcvr_id_9,\n 433 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(9)], '0') AS hist_rcvr_id_10,\n 434 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(10)], '0') AS hist_rcvr_id_11,\n 435 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(11)], '0') AS hist_rcvr_id_12,\n 436 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(12)], '0') AS hist_rcvr_id_13,\n 437 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(13)], '0') AS hist_rcvr_id_14,\n 438 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(14)], '0') AS hist_rcvr_id_15,\n 439 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(15)], '0') AS hist_rcvr_id_16,\n 440 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(16)], '0') AS hist_rcvr_id_17,\n 441 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(17)], '0') AS hist_rcvr_id_18,\n 442 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(18)], '0') AS hist_rcvr_id_19,\n 443 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(19)], '0') AS hist_rcvr_id_20,\n 444 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(20)], '0') AS hist_rcvr_id_21,\n 445 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(21)], '0') AS hist_rcvr_id_22,\n 446 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(22)], '0') AS hist_rcvr_id_23,\n 447 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(23)], '0') AS hist_rcvr_id_24,\n 448 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(24)], '0') AS hist_rcvr_id_25,\n 449 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(25)], '0') AS hist_rcvr_id_26,\n 450 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(26)], '0') AS hist_rcvr_id_27,\n 451 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(27)], '0') AS hist_rcvr_id_28,\n 452 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(28)], '0') AS hist_rcvr_id_29,\n 453 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(29)], '0') AS hist_rcvr_id_30,\n 454 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(30)], '0') AS hist_rcvr_id_31,\n 455 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(31)], '0') AS hist_rcvr_id_32,\n 456 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(32)], '0') AS hist_rcvr_id_33,\n 457 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(33)], '0') AS hist_rcvr_id_34,\n 458 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(34)], '0') AS hist_rcvr_id_35,\n 459 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(35)], '0') AS hist_rcvr_id_36,\n 460 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(36)], '0') AS hist_rcvr_id_37,\n 461 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(37)], '0') AS hist_rcvr_id_38,\n 462 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(38)], '0') AS hist_rcvr_id_39,\n 463 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(39)], '0') AS hist_rcvr_id_40,\n 464 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(40)], '0') AS hist_rcvr_id_41,\n 465 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(41)], '0') AS hist_rcvr_id_42,\n 466 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(42)], '0') AS hist_rcvr_id_43,\n 467 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(43)], '0') AS hist_rcvr_id_44,\n 468 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(44)], '0') AS hist_rcvr_id_45,\n 469 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(45)], '0') AS hist_rcvr_id_46,\n 470 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(46)], '0') AS hist_rcvr_id_47,\n 471 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(47)], '0') AS hist_rcvr_id_48,\n 472 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(48)], '0') AS hist_rcvr_id_49,\n 473 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(49)], '0') AS hist_rcvr_id_50,\n 474 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(50)], '0') AS hist_rcvr_id_51,\n 475 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(51)], '0') AS hist_rcvr_id_52,\n 476 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(52)], '0') AS hist_rcvr_id_53,\n 477 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(53)], '0') AS hist_rcvr_id_54,\n 478 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(54)], '0') AS hist_rcvr_id_55,\n 479 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(55)], '0') AS hist_rcvr_id_56,\n 480 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(56)], '0') AS hist_rcvr_id_57,\n 481 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(57)], '0') AS hist_rcvr_id_58,\n 482 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(58)], '0') AS hist_rcvr_id_59,\n 483 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(59)], '0') AS hist_rcvr_id_60,\n 484 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(60)], '0') AS hist_rcvr_id_61,\n 485 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(61)], '0') AS hist_rcvr_id_62,\n 486 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(62)], '0') AS hist_rcvr_id_63,\n 487 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(63)], '0') AS hist_rcvr_id_64,\n 488 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(64)], '0') AS hist_rcvr_id_65,\n 489 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(65)], '0') AS hist_rcvr_id_66,\n 490 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(66)], '0') AS hist_rcvr_id_67,\n 491 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(67)], '0') AS hist_rcvr_id_68,\n 492 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(68)], '0') AS hist_rcvr_id_69,\n 493 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(69)], '0') AS hist_rcvr_id_70,\n 494 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(70)], '0') AS hist_rcvr_id_71,\n 495 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(71)], '0') AS hist_rcvr_id_72,\n 496 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(72)], '0') AS hist_rcvr_id_73,\n 497 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(73)], '0') AS hist_rcvr_id_74,\n 498 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(74)], '0') AS hist_rcvr_id_75,\n 499 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(75)], '0') AS hist_rcvr_id_76,\n 500 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(76)], '0') AS hist_rcvr_id_77,\n 501 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(77)], '0') AS hist_rcvr_id_78,\n 502 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(78)], '0') AS hist_rcvr_id_79,\n 503 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(79)], '0') AS hist_rcvr_id_80,\n 504 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(80)], '0') AS hist_rcvr_id_81,\n 505 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(81)], '0') AS hist_rcvr_id_82,\n 506 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(82)], '0') AS hist_rcvr_id_83,\n 507 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(83)], '0') AS hist_rcvr_id_84,\n 508 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(84)], '0') AS hist_rcvr_id_85,\n 509 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(85)], '0') AS hist_rcvr_id_86,\n 510 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(86)], '0') AS hist_rcvr_id_87,\n 511 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(87)], '0') AS hist_rcvr_id_88,\n 512 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(88)], '0') AS hist_rcvr_id_89,\n 513 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(89)], '0') AS hist_rcvr_id_90,\n 514 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(90)], '0') AS hist_rcvr_id_91,\n 515 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(91)], '0') AS hist_rcvr_id_92,\n 516 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(92)], '0') AS hist_rcvr_id_93,\n 517 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(93)], '0') AS hist_rcvr_id_94,\n 518 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(94)], '0') AS hist_rcvr_id_95,\n 519 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(95)], '0') AS hist_rcvr_id_96,\n 520 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(96)], '0') AS hist_rcvr_id_97,\n 521 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(97)], '0') AS hist_rcvr_id_98,\n 522 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(98)], '0') AS hist_rcvr_id_99,\n 523 | IFNULL(SPLIT(sndr_most_recent_100_merch_list, ',')[SAFE_OFFSET(99)], '0') AS hist_rcvr_id_100,\n 524 | case when sndr_most_recent_100_merch_category='0' then '0' else IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(0)], '0') end AS hist_gpt_1st_category_1,\n 525 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(1)], '0') AS hist_gpt_1st_category_2,\n 526 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(2)], '0') AS hist_gpt_1st_category_3,\n 527 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(3)], '0') AS hist_gpt_1st_category_4,\n 528 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(4)], '0') AS hist_gpt_1st_category_5,\n 529 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(5)], '0') AS hist_gpt_1st_category_6,\n 530 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(6)], '0') AS hist_gpt_1st_category_7,\n 531 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(7)], '0') AS hist_gpt_1st_category_8,\n 532 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(8)], '0') AS hist_gpt_1st_category_9,\n 533 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(9)], '0') AS hist_gpt_1st_category_10,\n 534 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(10)], '0') AS hist_gpt_1st_category_11,\n 535 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(11)], '0') AS hist_gpt_1st_category_12,\n 536 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(12)], '0') AS hist_gpt_1st_category_13,\n 537 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(13)], '0') AS hist_gpt_1st_category_14,\n 538 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(14)], '0') AS hist_gpt_1st_category_15,\n 539 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(15)], '0') AS hist_gpt_1st_category_16,\n 540 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(16)], '0') AS hist_gpt_1st_category_17,\n 541 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(17)], '0') AS hist_gpt_1st_category_18,\n 542 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(18)], '0') AS hist_gpt_1st_category_19,\n 543 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(19)], '0') AS hist_gpt_1st_category_20,\n 544 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(20)], '0') AS hist_gpt_1st_category_21,\n 545 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(21)], '0') AS hist_gpt_1st_category_22,\n 546 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(22)], '0') AS hist_gpt_1st_category_23,\n 547 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(23)], '0') AS hist_gpt_1st_category_24,\n 548 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(24)], '0') AS hist_gpt_1st_category_25,\n 549 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(25)], '0') AS hist_gpt_1st_category_26,\n 550 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(26)], '0') AS hist_gpt_1st_category_27,\n 551 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(27)], '0') AS hist_gpt_1st_category_28,\n 552 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(28)], '0') AS hist_gpt_1st_category_29,\n 553 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(29)], '0') AS hist_gpt_1st_category_30,\n 554 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(30)], '0') AS hist_gpt_1st_category_31,\n 555 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(31)], '0') AS hist_gpt_1st_category_32,\n 556 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(32)], '0') AS hist_gpt_1st_category_33,\n 557 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(33)], '0') AS hist_gpt_1st_category_34,\n 558 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(34)], '0') AS hist_gpt_1st_category_35,\n 559 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(35)], '0') AS hist_gpt_1st_category_36,\n 560 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(36)], '0') AS hist_gpt_1st_category_37,\n 561 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(37)], '0') AS hist_gpt_1st_category_38,\n 562 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(38)], '0') AS hist_gpt_1st_category_39,\n 563 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(39)], '0') AS hist_gpt_1st_category_40,\n 564 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(40)], '0') AS hist_gpt_1st_category_41,\n 565 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(41)], '0') AS hist_gpt_1st_category_42,\n 566 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(42)], '0') AS hist_gpt_1st_category_43,\n 567 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(43)], '0') AS hist_gpt_1st_category_44,\n 568 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(44)], '0') AS hist_gpt_1st_category_45,\n 569 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(45)], '0') AS hist_gpt_1st_category_46,\n 570 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(46)], '0') AS hist_gpt_1st_category_47,\n 571 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(47)], '0') AS hist_gpt_1st_category_48,\n 572 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(48)], '0') AS hist_gpt_1st_category_49,\n 573 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(49)], '0') AS hist_gpt_1st_category_50,\n 574 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(50)], '0') AS hist_gpt_1st_category_51,\n 575 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(51)], '0') AS hist_gpt_1st_category_52,\n 576 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(52)], '0') AS hist_gpt_1st_category_53,\n 577 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(53)], '0') AS hist_gpt_1st_category_54,\n 578 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(54)], '0') AS hist_gpt_1st_category_55,\n 579 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(55)], '0') AS hist_gpt_1st_category_56,\n 580 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(56)], '0') AS hist_gpt_1st_category_57,\n 581 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(57)], '0') AS hist_gpt_1st_category_58,\n 582 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(58)], '0') AS hist_gpt_1st_category_59,\n 583 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(59)], '0') AS hist_gpt_1st_category_60,\n 584 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(60)], '0') AS hist_gpt_1st_category_61,\n 585 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(61)], '0') AS hist_gpt_1st_category_62,\n 586 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(62)], '0') AS hist_gpt_1st_category_63,\n 587 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(63)], '0') AS hist_gpt_1st_category_64,\n 588 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(64)], '0') AS hist_gpt_1st_category_65,\n 589 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(65)], '0') AS hist_gpt_1st_category_66,\n 590 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(66)], '0') AS hist_gpt_1st_category_67,\n 591 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(67)], '0') AS hist_gpt_1st_category_68,\n 592 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(68)], '0') AS hist_gpt_1st_category_69,\n 593 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(69)], '0') AS hist_gpt_1st_category_70,\n 594 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(70)], '0') AS hist_gpt_1st_category_71,\n 595 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(71)], '0') AS hist_gpt_1st_category_72,\n 596 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(72)], '0') AS hist_gpt_1st_category_73,\n 597 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(73)], '0') AS hist_gpt_1st_category_74,\n 598 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(74)], '0') AS hist_gpt_1st_category_75,\n 599 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(75)], '0') AS hist_gpt_1st_category_76,\n 600 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(76)], '0') AS hist_gpt_1st_category_77,\n 601 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(77)], '0') AS hist_gpt_1st_category_78,\n 602 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(78)], '0') AS hist_gpt_1st_category_79,\n 603 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(79)], '0') AS hist_gpt_1st_category_80,\n 604 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(80)], '0') AS hist_gpt_1st_category_81,\n 605 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(81)], '0') AS hist_gpt_1st_category_82,\n 606 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(82)], '0') AS hist_gpt_1st_category_83,\n 607 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(83)], '0') AS hist_gpt_1st_category_84,\n 608 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(84)], '0') AS hist_gpt_1st_category_85,\n 609 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(85)], '0') AS hist_gpt_1st_category_86,\n 610 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(86)], '0') AS hist_gpt_1st_category_87,\n 611 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(87)], '0') AS hist_gpt_1st_category_88,\n 612 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(88)], '0') AS hist_gpt_1st_category_89,\n 613 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(89)], '0') AS hist_gpt_1st_category_90,\n 614 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(90)], '0') AS hist_gpt_1st_category_91,\n 615 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(91)], '0') AS hist_gpt_1st_category_92,\n 616 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(92)], '0') AS hist_gpt_1st_category_93,\n 617 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(93)], '0') AS hist_gpt_1st_category_94,\n 618 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(94)], '0') AS hist_gpt_1st_category_95,\n 619 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(95)], '0') AS hist_gpt_1st_category_96,\n 620 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(96)], '0') AS hist_gpt_1st_category_97,\n 621 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(97)], '0') AS hist_gpt_1st_category_98,\n 622 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(98)], '0') AS hist_gpt_1st_category_99,\n 623 | IFNULL(SPLIT(sndr_most_recent_100_merch_category, ',')[SAFE_OFFSET(99)], '0') AS hist_gpt_1st_category_100,\n 624 | from {bq_prefix}driver_oot_features;\n 625 | \"\"\"\n 626 | # %ppbq $q\n 627 | # %ppauth\n 628 | # !gsutil ls gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/\n 629 | # !gsutil rm -r gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_dev_features\n 630 | # %%ppbq\n 631 | EXPORT DATA\n 632 | OPTIONS (\n 633 | uri = 'gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_dev_features/part*.parquet',\n 634 | format = 'parquet',\n 635 | overwrite = true)\n 636 | AS (\n 637 | SELECT *\n 638 | FROM pypl-bods.gds_pacman_prod.ql_store_rmr_driver_dev_features\n 639 | );\n 640 | # !rm -r ../data/ql_store_rmr_driver_dev_features\n 641 | # !gsutil cp -r gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_dev_features ../data\n 642 | # !gsutil ls gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_driver_dev_features",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/03_prepare_training_data.py": "   1 | import os\n   2 | import pickle\n   3 | from tqdm import tqdm\n   4 | from datetime import datetime\n   5 | import numpy as np\n   6 | import pandas as pd\n   7 | from sklearn.preprocessing import StandardScaler,LabelEncoder\n   8 | from tensorflow.keras.preprocessing.sequence import pad_sequences\n   9 | from tensorflow.keras.preprocessing.text import Tokenizer\n  10 | today_date = datetime.now().date().strftime(\"%Y%m%d\")\n  11 | model_version = \"din_\"+str(today_date)\n  12 | model_version_base = os.path.join('../artifacts/',model_version)\n  13 | # !rm -r $model_version_base\n  14 | if not os.path.exists(model_version_base):\n  15 |     os.mkdir(model_version_base)\n  16 | exported_feature_transformer = os.path.join(model_version_base,'exported_feature_transformer')\n  17 | if not os.path.exists(exported_feature_transformer):\n  18 |     os.mkdir(exported_feature_transformer)\n  19 | with open('../_current_model_version', 'wb') as f:\n  20 |     pickle.dump(model_version, f)\n  21 | categorical_feature_encoders = {}\n  22 | numerical_feature_scalars = {}\n  23 | directory = '../data/ql_store_rmr_driver_dev_features'\n  24 | parquet_files = [f for f in os.listdir(directory) if f.endswith(\".parquet\")]\n  25 | dfs = []\n  26 | for file in tqdm(parquet_files,total=len(parquet_files)):\n  27 |     file_path = os.path.join(directory, file)\n  28 |     f = pd.read_parquet(file_path)\n  29 |     dfs.append(f)\n  30 | data = pd.concat(dfs, ignore_index=True)\n  31 | state_to_abbreviation = {\n  32 |     'ALABAMA': 'AL',\n  33 |     'ALASKA': 'AK',\n  34 |     'ARIZONA': 'AZ',\n  35 |     'ARKANSAS': 'AR',\n  36 |     'CALIFORNIA': 'CA',\n  37 |     'COLORADO': 'CO',\n  38 |     'CONNECTICUT': 'CT',\n  39 |     'DELAWARE': 'DE',\n  40 |     'FLORIDA': 'FL',\n  41 |     'GEORGIA': 'GA',\n  42 |     'HAWAII': 'HI',\n  43 |     'IDAHO': 'ID',\n  44 |     'ILLINOIS': 'IL',\n  45 |     'INDIANA': 'IN',\n  46 |     'IOWA': 'IA',\n  47 |     'KANSAS': 'KS',\n  48 |     'KENTUCKY': 'KY',\n  49 |     'LOUISIANA': 'LA',\n  50 |     'MAINE': 'ME',\n  51 |     'MARYLAND': 'MD',\n  52 |     'MASSACHUSETTS': 'MA',\n  53 |     'MICHIGAN': 'MI',\n  54 |     'MINNESOTA': 'MN',\n  55 |     'MISSISSIPPI': 'MS',\n  56 |     'MISSOURI': 'MO',\n  57 |     'MONTANA': 'MT',\n  58 |     'NEBRASKA': 'NE',\n  59 |     'NEVADA': 'NV',\n  60 |     'NEW HAMPSHIRE': 'NH',\n  61 |     'NEW JERSEY': 'NJ',\n  62 |     'NEW MEXICO': 'NM',\n  63 |     'NEW YORK': 'NY',\n  64 |     'NORTH CAROLINA': 'NC',\n  65 |     'NORTH DAKOTA': 'ND',\n  66 |     'OHIO': 'OH',\n  67 |     'OKLAHOMA': 'OK',\n  68 |     'OREGON': 'OR',\n  69 |     'PENNSYLVANIA': 'PA',\n  70 |     'RHODE ISLAND': 'RI',\n  71 |     'SOUTH CAROLINA': 'SC',\n  72 |     'SOUTH DAKOTA': 'SD',\n  73 |     'TENNESSEE': 'TN',\n  74 |     'TEXAS': 'TX',\n  75 |     'UTAH': 'UT',\n  76 |     'VERMONT': 'VT',\n  77 |     'VIRGINIA': 'VA',\n  78 |     'WASHINGTON': 'WA',\n  79 |     'WEST VIRGINIA': 'WV',\n  80 |     'WISCONSIN': 'WI',\n  81 |     'WYOMING': 'WY',\n  82 |     'PUERTO RICO': 'PR'\n  83 | }\n  84 | state_map = {}\n  85 | for state in np.unique(data['sndr_prmry_addr_state'].values).tolist():\n  86 |     if len(state)>2 and state.upper() in state_to_abbreviation:\n  87 |         state_map[state.upper()] = state_to_abbreviation[state.upper()]\n  88 | def clean_states(x):\n  89 |     if len(x)==2:\n  90 |         return x.upper()\n  91 |     elif x.upper() in state_map:\n  92 |         return state_map[x.upper()]\n  93 |     else:\n  94 |         return '#'\n  95 | data['sndr_prmry_addr_state']=data['sndr_prmry_addr_state'].apply(clean_states)\n  96 | lbe = LabelEncoder()\n  97 | data['sndr_prmry_addr_state'] = lbe.fit_transform(data['sndr_prmry_addr_state'].values)\n  98 | state_encoder_dict = {}\n  99 | labels = lbe.transform(lbe.classes_)\n 100 | for i in range(len(lbe.classes_)):\n 101 |     state_encoder_dict[lbe.classes_[i]] = labels[i]\n 102 | for state in state_map:\n 103 |     state_encoder_dict[state] = lbe.transform([state_map[state]])[0]\n 104 | categorical_feature_encoders['sndr_prmry_addr_state'] = state_encoder_dict\n 105 | for feat in ['sndr_consu_engagmnt_seg_key','sndr_ebay_member_y_n','gender','sndr_prmry_cc_type_code','sndr_consu_age_band_key','sndr_consu_dmgrphc_seg_key']:\n 106 |     lbe = LabelEncoder()\n 107 |     data[feat] = lbe.fit_transform(data[feat].values)\n 108 |     labels = lbe.transform(lbe.classes_)\n 109 |     encoder_dict={}\n 110 |     for i in range(len(lbe.classes_)):\n 111 |         encoder_dict[lbe.classes_[i]] = labels[i]\n 112 |     categorical_feature_encoders[feat] = encoder_dict\n 113 | numeric_features = [\"sndr_rcvr_txn_num_30d\",\"sndr_rcvr_txn_num_180d\",\"sndr_rcvr_txn_num_365d\",\"sndr_rcvr_txn_amt_30d\",\"sndr_rcvr_txn_amt_180d\",\n 114 |                     \"sndr_rcvr_txn_amt_365d\",\"sndr_last_5_txn_avg_amt\",\"sndr_last_10_txn_avg_amt\",\"sndr_rcvr_category_breadth_30d\",\"sndr_rcvr_category_breadth_180d\",\n 115 |                     \"sndr_rcvr_category_breadth_365d\",\"sndr_rcvr_category_txn_num_30d\",\"sndr_rcvr_category_txn_num_180d\",\"sndr_rcvr_category_txn_num_365d\",\n 116 |                     \"sndr_rcvr_category_txn_amt_30d\",\"sndr_rcvr_category_txn_amt_180d\",\"sndr_rcvr_category_txn_amt_365d\",\"sndr_rcvr_category_avg_txn_amt_30d\",\n 117 |                     \"sndr_rcvr_category_avg_txn_amt_180d\",\"sndr_rcvr_category_avg_txn_amt_365d\",\"sndr_1st_freq_merchant_category_cnt_30d\",\n 118 |                     \"sndr_2nd_freq_merchant_category_cnt_30d\",\"sndr_3rd_freq_merchant_category_cnt_30d\",\"sndr_1st_freq_merchant_category_cnt_180d\",\n 119 |                     \"sndr_2nd_freq_merchant_category_cnt_180d\",\"sndr_3rd_freq_merchant_category_cnt_180d\",\"sndr_1st_freq_merchant_category_cnt_365d\",\n 120 |                     \"sndr_2nd_freq_merchant_category_cnt_365d\",\"sndr_3rd_freq_merchant_category_cnt_365d\",\"rcvr_avg_price_30d\",\"rcvr_price_10_penentile_30d\",\n 121 |                     \"rcvr_price_30_penentile_30d\",\"rcvr_price_50_penentile_30d\",\"rcvr_price_70_penentile_30d\",\"rcvr_price_90_penentile_30d\",\"rcvr_rcvd_txn_num_30d\",\n 122 |                     \"rcvr_rcvd_distinct_consumer_num_30d\",\"rcvr_rcvd_txn_amt_30d\",\"sndr_last_1_txn_avg_amt_rcvr_avg_price_diff\",\n 123 |                     \"sndr_last_1_txn_avg_amt_rcvr_median_price_diff\",\"sndr_last_5_txn_avg_amt_rcvr_avg_price_diff\",\"sndr_last_5_txn_avg_amt_rcvr_median_price_diff\",\n 124 |                     \"sndr_last_10_txn_avg_amt_rcvr_avg_price_diff\",\"sndr_last_10_txn_avg_amt_rcvr_median_price_diff\",\"sndr_rcvr_num_save_7day\",\n 125 |                     \"sndr_rcvr_num_save_30day\",\"sndr_rcvr_num_save_180day\",\"sndr_num_save_7day\",\"sndr_num_save_30day\",\"sndr_num_save_180day\",\n 126 |                     \"sndr_rcvr_num_sameindustry_save_7day\",\"sndr_rcvr_num_sameindustry_save_30day\",\"sndr_rcvr_num_sameindustry_save_180day\",\n 127 |                     \"rcvr_save_cnt_30d\",\"rcvr_save_cnt_deals_explore_tertiary_30d\",\"rcvr_save_cnt_ql_home_30d\",\"rcvr_save_cnt_rewards_zone_new_30d\",\n 128 |                     \"rcvr_save_cnt_reboarding_30d\",\"rcvr_save_cnt_high_engaged_30d\",\"rcvr_save_cnt_mid_engaged_30d\",\"rcvr_save_cnt_low_engaged_30d\",\n 129 |                     \"rcvr_save_cnt_likely_to_churn_30d\",\"rcvr_save_cnt_new_not_active_30d\",\"rcvr_save_cnt_never_active_30d\",\"rcvr_save_cnt_churned_30d\",\n 130 |                     \"rcvr_save_cnt_re_engaged_30d\",\"rcvr_save_cnt_new_active_30d\",\"sndr_days_on_file\",\"sndr_days_appweb_visit\",\"rcvr_tpv_score\"]\n 131 | for feat in tqdm(numeric_features,total=len(numeric_features)):\n 132 |     scaler = StandardScaler()\n 133 |     data[feat] = scaler.fit_transform(data[feat].values.reshape(-1, 1)).reshape(-1)\n 134 |     numerical_feature_scalars[feat] = {'mean':scaler.mean_[0],'std':np.sqrt(scaler.var_[0])}\n 135 | data['sndr_most_recent_100_merch_category'].replace(['0'], pd.NA, inplace=True)\n 136 | data['sndr_most_recent_100_merch_category'].fillna('', inplace=True)\n 137 | df_seq = data['sndr_most_recent_100_merch_category'].apply(lambda x: [] if not x else list(map(int, x.split(','))))\n 138 | df_pad = pad_sequences(df_seq,maxlen=100,truncating='pre',padding='pre',value=0)\n 139 | data['hist_gpt_1st_category_l2_index'] = df_pad.tolist()\n 140 | data['sndr_most_recent_100_merch_list'].replace(['0'], pd.NA, inplace=True)\n 141 | data['sndr_most_recent_100_merch_list'].fillna('', inplace=True)\n 142 | rcvr_id_tokenizer = Tokenizer(num_words=1000, oov_token='<OOV>')\n 143 | rcvr_id_tokenizer.fit_on_texts(data['sndr_most_recent_100_merch_list'])\n 144 | df_seq = rcvr_id_tokenizer.texts_to_sequences(data['sndr_most_recent_100_merch_list'])\n 145 | df_pad = pad_sequences(df_seq,maxlen=100,truncating=\"pre\",padding=\"pre\",value=0)\n 146 | data['token']=df_pad.tolist()\n 147 | data.rename(columns={'token': 'hist_rcvr_id'}, inplace=True)\n 148 | from itertools import chain\n 149 | for feat in ['rcvr_id']:\n 150 |     z_seq=rcvr_id_tokenizer.texts_to_sequences(data[feat])\n 151 |     z_seq=list(chain.from_iterable(z_seq))\n 152 |     data[feat]=z_seq\n 153 | data.drop(['sndr_most_recent_100_merch_list', 'sndr_most_recent_100_merch_category'], axis=1,inplace=True)\n 154 | def write_chunk_to_parquet(df_chunk, chunk_index, output_dir):\n 155 |     filename = os.path.join(output_dir, f'part_{chunk_index}.parquet')\n 156 |     df_chunk.to_parquet(filename, index=False)\n 157 | output_dir = '../data/ql_store_rmr_driver_dev_features_transformed'\n 158 | # !rm -r $output_dir\n 159 | os.makedirs(output_dir, exist_ok=True)\n 160 | chunk_size = 1000000\n 161 | num_chunks = (len(data) // chunk_size) + 1\n 162 | for i in range(num_chunks):\n 163 |     start_idx = i * chunk_size\n 164 |     end_idx = (i + 1) * chunk_size\n 165 |     df_chunk = data[start_idx:end_idx]\n 166 |     write_chunk_to_parquet(df_chunk, i, output_dir)\n 167 | export_path = os.path.join(exported_feature_transformer,'rcvr_id_tokenizer') \n 168 | with open(export_path, 'wb') as f:\n 169 |     pickle.dump(rcvr_id_tokenizer, f)\n 170 | export_path = os.path.join(exported_feature_transformer,'categorical_feature_encoders') \n 171 | with open(export_path, 'wb') as f:\n 172 |     pickle.dump(categorical_feature_encoders, f)\n 173 | export_path = os.path.join(exported_feature_transformer,'numerical_feature_scalars') \n 174 | with open(export_path, 'wb') as f:\n 175 |     pickle.dump(numerical_feature_scalars, f)\n 176 | # %ppauth\n 177 | # !gsutil rm gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/rcvr_id_tokenizer\n 178 | path = os.path.join(exported_feature_transformer,'rcvr_id_tokenizer')\n 179 | # !gsutil cp $path  gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/rcvr_id_tokenizer\n 180 | # !gsutil rm gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/categorical_feature_encoders\n 181 | path = os.path.join(exported_feature_transformer,'categorical_feature_encoders')\n 182 | # !gsutil cp $path  gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/categorical_feature_encoders\n 183 | # !gsutil rm gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/numerical_feature_scalars\n 184 | path = os.path.join(exported_feature_transformer,'numerical_feature_scalars')\n 185 | # !gsutil cp $path  gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/numerical_feature_scalars",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/04_training.py": "   1 | # !pip install deepctr pyarrow\n   2 | import os\n   3 | import pickle\n   4 | from tqdm import tqdm\n   5 | import yaml\n   6 | import tensorflow as tf\n   7 | import numpy as np\n   8 | import pandas as pd\n   9 | from tensorflow.python.keras.optimizers import adam_v2\n  10 | from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n  11 | from deepctr.models import DIN\n  12 | gpus = tf.config.experimental.list_physical_devices('GPU')\n  13 | for i in range(len(gpus)):\n  14 |     tf.config.experimental.set_memory_growth(gpus[i], True)\n  15 | def load_yaml_file(file_path):\n  16 |     try:\n  17 |         with open(file_path, 'r') as file:\n  18 |             yaml_content = yaml.safe_load(file)\n  19 |         return yaml_content\n  20 |     except FileNotFoundError:\n  21 |         return None\n  22 | file_path = '../config/base_config.yaml'  # Path to your YAML file\n  23 | config = load_yaml_file(file_path)\n  24 | if config is not None:\n  25 | with open('../_current_model_version', \"rb\") as f:\n  26 |     model_version = pickle.load(f)\n  27 | model_version_base = os.path.join('../artifacts/',model_version)\n  28 | exported_feature_transformer = os.path.join(model_version_base,'exported_feature_transformer')\n  29 | model_version_base = os.path.join(model_version_base,'19')\n  30 | if not os.path.exists(model_version_base):\n  31 |     os.mkdir(model_version_base)\n  32 | exported_model_base = os.path.join(model_version_base,'exported_models')\n  33 | if not os.path.exists(exported_model_base):\n  34 |     os.mkdir(exported_model_base)\n  35 | # !cp ../config/base_config.yaml $model_version_base\n  36 | directory = '../data/ql_store_rmr_driver_dev_features_transformed'\n  37 | parquet_files = [f for f in os.listdir(directory) if f.endswith(\".parquet\")]\n  38 | dfs = []\n  39 | for file in tqdm(parquet_files,total=len(parquet_files)):\n  40 |     file_path = os.path.join(directory, file)\n  41 |     f = pd.read_parquet(file_path)\n  42 |     dfs.append(f)\n  43 | data = pd.concat(dfs, ignore_index=True)\n  44 | with open(os.path.join(exported_feature_transformer,'categorical_feature_encoders'), \"rb\") as f:\n  45 |     categorical_feature_encoders = pickle.load(f)\n  46 | with open(os.path.join(exported_feature_transformer,'rcvr_id_tokenizer'), \"rb\") as f:\n  47 |     rcvr_id_tokenizer = pickle.load(f)\n  48 | data_train = data[data['split']=='train'].copy()\n  49 | data_val = data[data['split']=='val'].copy()\n  50 | # from sklearn.model_selection import train_test_split\n  51 | # data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n  52 | numeric_names = [\"sndr_rcvr_txn_num_30d\",\"sndr_rcvr_txn_num_180d\",\"sndr_rcvr_txn_num_365d\",\"sndr_rcvr_txn_amt_30d\",\"sndr_rcvr_txn_amt_180d\",\n  53 |                     \"sndr_rcvr_txn_amt_365d\",\"sndr_last_5_txn_avg_amt\",\"sndr_last_10_txn_avg_amt\",\"sndr_rcvr_category_breadth_30d\",\"sndr_rcvr_category_breadth_180d\",\n  54 |                     \"sndr_rcvr_category_breadth_365d\",\"sndr_rcvr_category_txn_num_30d\",\"sndr_rcvr_category_txn_num_180d\",\"sndr_rcvr_category_txn_num_365d\",\n  55 |                     \"sndr_rcvr_category_txn_amt_30d\",\"sndr_rcvr_category_txn_amt_180d\",\"sndr_rcvr_category_txn_amt_365d\",\"sndr_rcvr_category_avg_txn_amt_30d\",\n  56 |                     \"sndr_rcvr_category_avg_txn_amt_180d\",\"sndr_rcvr_category_avg_txn_amt_365d\",\"sndr_1st_freq_merchant_category_cnt_30d\",\n  57 |                     \"sndr_2nd_freq_merchant_category_cnt_30d\",\"sndr_3rd_freq_merchant_category_cnt_30d\",\"sndr_1st_freq_merchant_category_cnt_180d\",\n  58 |                     \"sndr_2nd_freq_merchant_category_cnt_180d\",\"sndr_3rd_freq_merchant_category_cnt_180d\",\"sndr_1st_freq_merchant_category_cnt_365d\",\n  59 |                     \"sndr_2nd_freq_merchant_category_cnt_365d\",\"sndr_3rd_freq_merchant_category_cnt_365d\",\"rcvr_avg_price_30d\",\"rcvr_price_10_penentile_30d\",\n  60 |                     \"rcvr_price_30_penentile_30d\",\"rcvr_price_50_penentile_30d\",\"rcvr_price_70_penentile_30d\",\"rcvr_price_90_penentile_30d\",\"rcvr_rcvd_txn_num_30d\",\n  61 |                     \"rcvr_rcvd_distinct_consumer_num_30d\",\"rcvr_rcvd_txn_amt_30d\",\"sndr_last_1_txn_avg_amt_rcvr_avg_price_diff\",\n  62 |                     \"sndr_last_1_txn_avg_amt_rcvr_median_price_diff\",\"sndr_last_5_txn_avg_amt_rcvr_avg_price_diff\",\"sndr_last_5_txn_avg_amt_rcvr_median_price_diff\",\n  63 |                     \"sndr_last_10_txn_avg_amt_rcvr_avg_price_diff\",\"sndr_last_10_txn_avg_amt_rcvr_median_price_diff\",\"sndr_rcvr_num_save_7day\",\n  64 |                     \"sndr_rcvr_num_save_30day\",\"sndr_rcvr_num_save_180day\",\"sndr_num_save_7day\",\"sndr_num_save_30day\",\"sndr_num_save_180day\",\n  65 |                     \"sndr_rcvr_num_sameindustry_save_7day\",\"sndr_rcvr_num_sameindustry_save_30day\",\"sndr_rcvr_num_sameindustry_save_180day\",\n  66 |                     \"rcvr_save_cnt_30d\",\"rcvr_save_cnt_deals_explore_tertiary_30d\",\"rcvr_save_cnt_ql_home_30d\",\"rcvr_save_cnt_rewards_zone_new_30d\",\n  67 |                     \"rcvr_save_cnt_reboarding_30d\",\"rcvr_save_cnt_high_engaged_30d\",\"rcvr_save_cnt_mid_engaged_30d\",\"rcvr_save_cnt_low_engaged_30d\",\n  68 |                     \"rcvr_save_cnt_likely_to_churn_30d\",\"rcvr_save_cnt_new_not_active_30d\",\"rcvr_save_cnt_never_active_30d\",\"rcvr_save_cnt_churned_30d\",\n  69 |                     \"rcvr_save_cnt_re_engaged_30d\",\"rcvr_save_cnt_new_active_30d\",\"sndr_days_on_file\",\"sndr_days_appweb_visit\",\"rcvr_tpv_score\"]+[f\"embedding_{i+1}\" for i in range(32)]\n  70 | rcvr_id_names = ['rcvr_id']\n  71 | gpt_cate_names = ['gpt_1st_category_l2_index',              \n  72 |     'sndr_1st_freq_merchant_category_30d','sndr_2nd_freq_merchant_category_30d','sndr_3rd_freq_merchant_category_30d',\n  73 |     'sndr_1st_freq_merchant_category_180d','sndr_2nd_freq_merchant_category_180d','sndr_3rd_freq_merchant_category_180d',\n  74 |     'sndr_1st_freq_merchant_category_365d','sndr_2nd_freq_merchant_category_365d','sndr_3rd_freq_merchant_category_365d']\n  75 | def get_xy_fd_share_embdding(data,numeric_names,rcvr_id_names,gpt_cate_names):\n  76 |     feature_columns = []\n  77 |     for column_name in numeric_names:\n  78 |         feature_columns.append(DenseFeat(column_name, 1))\n  79 |     feature_columns.append(SparseFeat('sndr_prmry_addr_state',len(categorical_feature_encoders['sndr_prmry_addr_state'])+1, embedding_dim=\"auto\"))\n  80 |     feature_columns.append(SparseFeat('sndr_consu_engagmnt_seg_key',len(categorical_feature_encoders['sndr_consu_engagmnt_seg_key'])+1, embedding_dim=\"auto\"))\n  81 |     feature_columns.append(SparseFeat('sndr_ebay_member_y_n',len(categorical_feature_encoders['sndr_ebay_member_y_n'])+1, embedding_dim=\"auto\"))\n  82 |     feature_columns.append(SparseFeat('gender',len(categorical_feature_encoders['gender'])+1, embedding_dim=\"auto\"))\n  83 |     feature_columns.append(SparseFeat('sndr_prmry_cc_type_code',len(categorical_feature_encoders['sndr_prmry_cc_type_code'])+1, embedding_dim=\"auto\"))\n  84 |     feature_columns.append(SparseFeat('sndr_consu_age_band_key',len(categorical_feature_encoders['sndr_consu_age_band_key'])+1, embedding_dim=\"auto\"))\n  85 |     feature_columns.append(SparseFeat('sndr_consu_dmgrphc_seg_key',len(categorical_feature_encoders['sndr_consu_dmgrphc_seg_key'])+1, embedding_dim=\"auto\"))\n  86 |     # feature_columns.append(SparseFeat('cust_id',1000,embedding_dim=30,use_hash=True))\n  87 |     for column_name in rcvr_id_names:\n  88 |         feature_columns.append(SparseFeat(column_name, max(rcvr_id_tokenizer.word_index.values())+1, embedding_dim=\"auto\", embedding_name='rcvr_id'))\n  89 |     for column_name in gpt_cate_names:\n  90 |         feature_columns.append(SparseFeat(column_name, 51+1, embedding_dim=\"auto\", embedding_name='gpt_1st_category_l2_index'))\n  91 |     feature_columns += [\n  92 |         VarLenSparseFeat(SparseFeat('hist_rcvr_id', max(rcvr_id_tokenizer.word_index.values())+1, embedding_dim='auto', embedding_name='rcvr_id'),\n  93 |                          maxlen=100),\n  94 |         VarLenSparseFeat(SparseFeat('hist_gpt_1st_category_l2_index', 51+1, embedding_dim='auto', embedding_name='gpt_1st_category_l2_index'),\n  95 |                          maxlen=100)\n  96 |     ]\n  97 |     dnn_feature_columns = feature_columns\n  98 |     feature_names = get_feature_names(feature_columns)\n  99 |     behavior_feature_list = [\"rcvr_id\",\"gpt_1st_category_l2_index\"]\n 100 |     x = {name: data[name].values for name in feature_names}\n 101 |     token = data['hist_rcvr_id']\n 102 |     x['hist_rcvr_id']=np.array(token.values.tolist())\n 103 |     token = data['hist_gpt_1st_category_l2_index']\n 104 |     x['hist_gpt_1st_category_l2_index']=np.array(token.values.tolist())\n 105 |     y = data['target'].values\n 106 |     return x, y, dnn_feature_columns,behavior_feature_list\n 107 | x_train, y_train, dnn_feature_columns,behavior_feature_list=get_xy_fd_share_embdding(data_train,numeric_names,rcvr_id_names,gpt_cate_names)\n 108 | x_val, y_val, _, _ = get_xy_fd_share_embdding(data_val,numeric_names,rcvr_id_names,gpt_cate_names)\n 109 | feature_names = get_feature_names(dnn_feature_columns)\n 110 | def data_generator(x_data, y_data, batch_size):\n 111 |     keys = list(x_data.keys())\n 112 |     length = len(y_data)\n 113 |     while True:\n 114 |         indices = np.random.permutation(length)\n 115 |         for start in range(0, length, batch_size):\n 116 |             end = min(start + batch_size, length)\n 117 |             batch_indices = indices[start:end]\n 118 |             x_batch = {key: np.array([x_data[key][i] for i in batch_indices]) for key in keys}\n 119 |             y_batch = np.array([y_data[i] for i in batch_indices])\n 120 |             yield x_batch, y_batch\n 121 | # Parameters\n 122 | batch_size = config['training_config']['DIN']['batch_size']\n 123 | # Create training and validation datasets\n 124 | train_dataset = tf.data.Dataset.from_generator(\n 125 |     lambda: data_generator(x_train, y_train, batch_size),\n 126 |     output_signature=(\n 127 |         {key: tf.TensorSpec(shape=(None, *x_train[key].shape[1:]), dtype=tf.float32) for key in x_train.keys()},\n 128 |         tf.TensorSpec(shape=(None,), dtype=tf.float32)\n 129 |     )\n 130 | ).shuffle(len(x_train))\n 131 | val_dataset = tf.data.Dataset.from_generator(\n 132 |     lambda: data_generator(x_val, y_val, batch_size),\n 133 |     output_signature=(\n 134 |         {key: tf.TensorSpec(shape=(None, *x_val[key].shape[1:]), dtype=tf.float32) for key in x_val.keys()},\n 135 |         tf.TensorSpec(shape=(None,), dtype=tf.float32)\n 136 |     )\n 137 | ).shuffle(len(x_val))\n 138 | steps_per_epoch = len(y_train) // batch_size\n 139 | validation_steps = len(y_val) // batch_size\n 140 | strategy = tf.distribute.MirroredStrategy([]) # single machine multiple gpu\n 141 | with strategy.scope():\n 142 |     adam=adam_v2.Adam(learning_rate = config['training_config']['DIN']['learning_rate'])\n 143 |     model = DIN(dnn_feature_columns, behavior_feature_list,\n 144 |                 dnn_use_bn=config['training_config']['DIN']['dnn_use_bn'],\n 145 |                 dnn_hidden_units=config['training_config']['DIN']['dnn_hidden_units'],\n 146 |                 dnn_activation=config['training_config']['DIN']['dnn_activation'],\n 147 |                 att_hidden_size=config['training_config']['DIN']['att_hidden_size'],\n 148 |                 att_activation=config['training_config']['DIN']['att_activation'],\n 149 |                 att_weight_normalization=config['training_config']['DIN']['att_weight_normalization'],\n 150 |                 l2_reg_dnn=config['training_config']['DIN']['l2_reg_dnn'],\n 151 |                 l2_reg_embedding=config['training_config']['DIN']['l2_reg_embedding'],\n 152 |                 dnn_dropout=config['training_config']['DIN']['dnn_dropout'],\n 153 |                 seed=config['training_config']['DIN']['seed'],\n 154 |                 task='binary')\n 155 |     model.compile(adam, loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC()])\n 156 | early_stopping = tf.keras.callbacks.EarlyStopping(\n 157 |     monitor='val_loss',\n 158 |     patience=3,\n 159 |     mode='max',\n 160 |     restore_best_weights=True,\n 161 |     verbose=1\n 162 | )\n 163 | history = model.fit(\n 164 |     train_dataset,\n 165 |     steps_per_epoch=steps_per_epoch,\n 166 |     epochs=config['training_config']['DIN']['epochs'],\n 167 |     validation_data=val_dataset,\n 168 |     validation_steps=validation_steps,\n 169 |     callbacks=[early_stopping]\n 170 | )\n 171 | from tensorflow.python.keras.models import save_model\n 172 | h5_model_path = os.path.join(exported_model_base,'din.h5')\n 173 | save_model(model,h5_model_path)\n 174 | tf_model_path = os.path.join(exported_model_base,'din_saved_model')\n 175 | model.save(tf_model_path)\n 176 | from pyScoring.graph import Graph\n 177 | from pyScoring.onnx.support.tf2.tf2_to_onnx import tf_model_to_onnx_node,tf_model_to_onnx_as_spec\n 178 | from pyScoring.node import ReNameBuilder, LookupBuilder, ScalerBuilder\n 179 | onnx_spec = tf_model_to_onnx_as_spec(tf_model=model,\n 180 |                                      input_mappings={\n 181 |                                         'hist_rcvr_id': [f'hist_rcvr_id_{i}' for i in range(1,101)],\n 182 |                                         'hist_gpt_1st_category_l2_index': [f'hist_gpt_1st_category_{i}' for i in range(1,101)]\n 183 |                                      },\n 184 |                                      output_mappings={model.output.name[:-2]: 'out'})\n 185 | assert(len(onnx_spec.outputs)==1)\n 186 | onnx_spec.save(exported_model_base)\n 187 | onnx_spec\n 188 | if not os.path.exists(os.path.join(exported_model_base,'oot_scoring')):\n 189 |     os.mkdir(os.path.join(exported_model_base,'oot_scoring'))\n 190 | file = os.path.join(exported_model_base,'tf_2_onnx_model.m')\n 191 | rename_file = os.path.join(exported_model_base,'oot_scoring/din_expand_seq.m')\n 192 | # !mv $file $rename_file\n 193 | # # UME with preprocessing layers\n 194 | # %ppauth\n 195 | # !gsutil cp $rename_file gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/oot_scoring\n 196 | def is_ascii(s):\n 197 |     try:\n 198 |         str(s).encode('ascii')\n 199 |         return True\n 200 |     except UnicodeEncodeError:\n 201 |         return False\n 202 | for cat_feat in categorical_feature_encoders:\n 203 |     for key in categorical_feature_encoders[cat_feat].keys():\n 204 |         categorical_feature_encoders[cat_feat] = {k:v for k,v in categorical_feature_encoders[cat_feat].items() if is_ascii(key)}\n 205 | with open(os.path.join(exported_feature_transformer,'numerical_feature_scalars'), \"rb\") as f:\n 206 |     numerical_feature_scalars = pickle.load(f)\n 207 | g = Graph()\n 208 | base_model_node,_,_ = tf_model_to_onnx_node(tf_model=model)\n 209 | g.add_node(base_model_node[0])\n 210 | node = ReNameBuilder('output', base_model_node[0].outputs[0]).build()\n 211 | g.add_node(node)\n 212 | #Categorical features\n 213 | for key in categorical_feature_encoders:\n 214 |     node = LookupBuilder(key, f'{key}_raw',\n 215 |                          {str(k):v for k,v in categorical_feature_encoders[key].items()}).set_default(0).build()\n 216 |     g.add_node(node)\n 217 | #Numerical feature transformation\n 218 | for key in numerical_feature_scalars:\n 219 |     node = ScalerBuilder(f'{key}_scalar',\n 220 |                      [f'{key}_raw'],\n 221 |                      [key],\n 222 |                      [numerical_feature_scalars[key]['mean']],\n 223 |                      [1/numerical_feature_scalars[key]['std']]\n 224 |                     ).build()\n 225 |     g.add_node(node)\n 226 | prod_model = g.generate_model_by_graph(model_name='din_prod',optimization=True)\n 227 | prod_model.save(exported_model_base)\n 228 | path = exported_model_base+'/din_prod.m'\n 229 | # !gsutil cp $path gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/\n 230 | test_df = data[(data['cust_id']==test_cust)&(data['run_date']==test_date)]\n 231 | # test_df = pd.concat([test_df] * 130, ignore_index=True)\n 232 | # test_data, _, _, _ = get_xy_fd_share_embdding(test_df,numeric_names,rcvr_id_names,gpt_cate_names)\n 233 | test_data_local={}\n 234 | for feat in model.inputs:\n 235 |     if feat.name in categorical_feature_encoders or feat.name in numerical_feature_scalars:\n 236 |         test_data_local[feat.name+'_raw'] = [test_df[feat.name].values[i].tolist() for i in range(len(test_df))]\n 237 |     else:\n 238 |         test_data_local[feat.name] = [test_df[feat.name].values[i].tolist() for i in range(len(test_df))]\n 239 | re = prod_model.predict(test_data_local)\n 240 | inputs = [k for k in test_data_local.keys()]\n 241 | test_data = {\"data\":{\"names\":inputs,\"ndarray\":[test_data_local[feat][0] for feat in inputs]}}\n 242 | import json\n 243 | if not os.path.exists('./testdata'):\n 244 |     os.mkdir('./testdata')\n 245 | output_file = './testdata/testdata.json'\n 246 | # Save dictionary to JSON file\n 247 | with open(output_file, 'w') as file:\n 248 |     json.dump(test_data, file)\n 249 | # !tar -czvf testdata.tar.gz testdata\n 250 | # # ONNX\n 251 | saved_model_path = os.path.join(exported_model_base,'din_saved_model')\n 252 | onnx_output_path = os.path.join(exported_model_base,'din.onnx')\n 253 | # !python -m tf2onnx.convert --saved-model $saved_model_path --output $onnx_output_path\n 254 | import onnxruntime as ort\n 255 | sess = ort.InferenceSession(onnx_output_path, providers=[\"CPUExecutionProvider\"])\n 256 | test_df = data[(data['cust_id']==test_cust)&(data['run_date']==test_date)]\n 257 | # test_df = pd.concat([test_df] * 130, ignore_index=True)\n 258 | # test_data, _, _, _ = get_xy_fd_share_embdding(test_df,numeric_names,rcvr_id_names,gpt_cate_names)\n 259 | test_data_tf={}\n 260 | for feat in model.inputs:\n 261 |     test_data_tf[feat.name] = np.array([test_df[feat.name].values[i].tolist() for i in range(len(test_df))],dtype=np.float32)\n 262 | test_data_onnx = {key: [[item] for item in value] for key, value in test_data_tf.items()}\n 263 | test_data_onnx['hist_gpt_1st_category_l2_index'] = [item[0] for item in test_data_onnx['hist_gpt_1st_category_l2_index']]\n 264 | test_data_onnx['hist_rcvr_id'] = [item[0] for item in test_data_onnx['hist_rcvr_id']]\n 265 | result_tf = model.predict(test_data_tf)\n 266 | results_ort = sess.run(None, test_data_onnx)\n 267 | np.testing.assert_allclose(results_ort[0], result_tf, rtol=1e-5, atol=1e-5)\n 268 | results_ort = sess.run(None, test_data_onnx)\n 269 | test_data_tf",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/05_scoring_oot.py": "   1 | # %ppauth\n   2 | from rmr_config.simple_config import Config\n   3 | from automation_utils.gcp.GSUtil import GSUtilHelper\n   4 | from model_automation.utils.rmr import run_cmd\n   5 | from model_automation.gcp import dataproc_config\n   6 | from aml import cloud_v1 as cloud\n   7 | import os, sys, ast\n   8 | from datetime import datetime\n   9 | # TODO: set working directory\n  10 | working_path = \"/projects/gds-packman/apps/ql-store-recommendation-prod/research\"\n  11 | username = os.environ['NB_USER']\n  12 | params_path = os.path.join(working_path, 'config')\n  13 | config = Config(params_path)\n  14 | # set working directory\n  15 | os.chdir(working_path)\n  16 | if not config:\n  17 |     raise ValueError('config is not correctly setup')\n  18 | section_name = \"oot_data_scoring\"\n  19 | import pickle\n  20 | with open(os.path.join(working_path,'_current_model_version'), \"rb\") as f:\n  21 |     model_version = pickle.load(f)\n  22 | model_version_base = os.path.join(working_path,'artifacts',model_version)\n  23 | exported_model_base = os.path.join(model_version_base,'exported_models')\n  24 | exported_model_base\n  25 | # define function run on gcp\n  26 | def oot_data_eval(oot_data_path, eval_result_path, m_file_list, score_list, keep_cols=[]):\n  27 |     from pyScoring.model import ModelScorer\n  28 |     from pyScoring import UMEModel\n  29 |     from automation_utils.gcp.GSUtil import GSUtilHelper\n  30 |     import os, sys\n  31 |     from py_dpu import load_parquet\n  32 |     oot_df = load_parquet(spark, oot_data_path)\n  33 |     local_m_path = []\n  34 |     for file_path in m_file_list:\n  35 |         model_name = file_path.split('/')[-1]\n  36 |         GSUtilHelper.cp(file_path, f'/tmp/model_spec/{model_name}')\n  37 |         local_m_path.append(f'/tmp/model_spec/{model_name}')\n  38 |     scorer = ModelScorer(spark, validate=False)\n  39 |     # output score name = {model_name}_{score_name}\n  40 |     eval_df = scorer.create_score_df(input_df=oot_df, mfile_paths= local_m_path, outputs=score_list)\n  41 |     if keep_cols:\n  42 |         # flatten score output names and add them to keep cols\n  43 |         for model_path, outputs in zip(local_m_path, score_list):\n  44 |             model_name = UMEModel(model_path).name\n  45 |             keep_cols += [f\"{model_name}_{score}\" for score in outputs]\n  46 |         eval_df = eval_df.select(*keep_cols)\n  47 |     # save scoring data\n  48 |     eval_df.coalesce(100).write.parquet(eval_result_path, mode=\"overwrite\")\n  49 | m_local_folder = os.path.join(exported_model_base,\"oot_scoring\")\n  50 | m_local_folder = '/projects/gds-packman/apps/ql-store-recommendation-prod/research/artifacts/din_20240708/18/exported_models/oot_scoring'\n  51 | m_gcp_folder = \"gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/challenger/oot_scoring\"\n  52 | oot_data_path = \"gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_oot_transformed\"\n  53 | eval_path = \"gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_oot_transformed_scored\"\n  54 | mo_name = config.get('general', 'mo_name')\n  55 | from pyScoring import UMEModel\n  56 | m_gcp_path_list = []\n  57 | score_list = []\n  58 | # # copy model spec to gcs\n  59 | for file_name in os.listdir(m_local_folder):\n  60 |     if not file_name.endswith(\".m\"):\n  61 |         continue\n  62 |     m_local_path = os.path.join(m_local_folder, file_name)\n  63 |     model_spec = UMEModel(m_local_path)\n  64 |     score_list.append(model_spec.outputs)\n  65 |     m_gcp_path = os.path.join(m_gcp_folder, file_name)\n  66 |     # GSUtilHelper.cp(m_local_path, m_gcp_path)\n  67 |     m_gcp_path_list.append(m_gcp_path)\n  68 | m_gcp_path_list\n  69 | score_list\n  70 | ## submit spark job to gcp\n  71 | gcp_project = config.get('general', 'dataproc_project_name')\n  72 | client = cloud.TrainingClient(gcp_project=gcp_project)\n  73 | job_id = client.create_spark_job(\n  74 |     # task function\n  75 |     func= oot_data_eval,\n  76 |     packages_to_install = ['automation_utils==0.3.0', 'pyScoring==0.8.0.1.post1', 'gcsfs', 'PyDPU==1.1.0','pyjnius<1.5.0'],\n  77 |     custom_billing_tag = f\"{mo_name}_{section_name}\".lower(),\n  78 |     # func kwargs\n  79 |     oot_data_path = oot_data_path,\n  80 |     eval_result_path = eval_path,\n  81 |     m_file_list= m_gcp_path_list,\n  82 |     score_list = score_list,\n  83 |     # gcp config\n  84 |     **dataproc_config['large']\n  85 | )\n  86 | job_id\n  87 | # check job status and kill cluster if needed\n  88 | status = client.wait_job_for_completion(job_id, time_to_sleep=300)\n  89 | # # save job log\n  90 | file_name = job_id.split(\"/\")[-1]\n  91 | log_file = os.path.join(working_path,'logs',f\"{file_name}.log\")\n  92 | with open(log_file, 'w') as f:\n  93 |     f.write(job_id + '\\n')\n  94 |     client.get_job_driver_logs(job_id, file=f)\n  95 | # !gsutil ls gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_oot_transformed_scored\n  96 | # %reload_ext cloudmagics.bigquery\n  97 | # %config PPMagics.domain=\"ccg24-hrzana-gds-pacman\"\n  98 | # %config PPMagics.autolimit = 0\n  99 | # %%ppbq\n 100 | CREATE OR REPLACE EXTERNAL TABLE pypl-bods.gds_pacman_prod.ql_store_rmr_oot_transformed_scored\n 101 | OPTIONS (\n 102 |   format = \"PARQUET\",\n 103 |   uris = [\"gs://pypl-bkt-rsh-row-std-gds-pacman/user/chenzhao/prod/ql-store-rmr/data/ql_store_rmr_oot_transformed_scored/part*\"]\n 104 | )",
    "rmr_agent/repos/ql-store-recommendation-prod/research/pipeline/06_evaluation.py": "   1 | # %reload_ext cloudmagics.bigquery\n   2 | # %config PPMagics.domain=\"ccg24-hrzana-gds-pacman\"\n   3 | # %config PPMagics.autolimit = 0\n   4 | import os\n   5 | import pickle\n   6 | with open('../_current_model_version', \"rb\") as f:\n   7 |     model_version = pickle.load(f)\n   8 | model_version_base = os.path.join('../artifacts/',model_version,'18')\n   9 | exported_eval_readout_base = os.path.join(model_version_base,'exported_eval_readouts')\n  10 | if not os.path.exists(exported_eval_readout_base):\n  11 |     os.mkdir(exported_eval_readout_base)\n  12 | exported_eval_readout_base\n  13 | import yaml\n  14 | def load_yaml_file(file_path):\n  15 |     try:\n  16 |         with open(file_path, 'r') as file:\n  17 |             yaml_content = yaml.safe_load(file)\n  18 |         return yaml_content\n  19 |     except FileNotFoundError:\n  20 |         return None\n  21 | file_path = '../config/base_config.yaml'\n  22 | config = load_yaml_file(file_path)\n  23 | if config is not None:\n  24 | bq_prefix = config['general_config']['bq_project_dataset_prefix']\n  25 | bq_prefix\n  26 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_txn_365d;\n  27 | create table  {bq_prefix}driver_oot_txn_365d as\n  28 | select a.*,b.transaction_created_ts as last_puchase_ts\n  29 | from {bq_prefix}driver_oot a\n  30 | left join (\n  31 |     select payment_transid,\n  32 |     tran_customer_id,\n  33 |     customer_counterparty,\n  34 |     transaction_created_date,\n  35 |     transaction_created_ts,\n  36 |     from pypl-edw.pp_access_views.dw_payment_sent\n  37 |     where transaction_status='S'\n  38 |     and transaction_created_date >= date_sub({config['driver_config']['oot_start_date']},INTERVAL 365 DAY)\n  39 | )b\n  40 | on a.cust_id = b.tran_customer_id\n  41 | and a.rcvr_id = b.customer_counterparty\n  42 | and a.run_date>b.transaction_created_date\n  43 | and a.run_date<=date_add(b.transaction_created_date, interval 365 day)\n  44 | qualify row_number() over (partition by cust_id,rcvr_id,run_date order by transaction_created_ts desc)=1;\n  45 | \"\"\"\n  46 | # %ppbq $q\n  47 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_txn_save_365d;\n  48 | create table  {bq_prefix}driver_oot_txn_save_365d as\n  49 | select a.*,b.evnt_dt as last_save_date\n  50 | from {bq_prefix}driver_oot_txn_365d a\n  51 | left join \n  52 | (\n  53 |   select a.cust_id,a.evnt_dt,b.customer_id as rcvr_id\n  54 |     from pypl-edw.pp_scratch.tmp_offers_output_dedup_archive  a\n  55 |     join pypl-edw.pp_access_views.dw_customer_map b ON a.pp_merchant_id=b.dienc13i6_id\n  56 |     where evnt_dt >= date_sub({config['driver_config']['oot_start_date']},INTERVAL 365 DAY)\n  57 |     and coalesce(saves_clk_unique_cnt,0)+coalesce(saves_outclick_unique_cnt,0)+coalesce(saves_save_unique_cnt,0)>0\n  58 |     and cust_id is not null\n  59 |     and pp_merchant_id is not null\n  60 | ) b\n  61 | on a.cust_id = b.cust_id\n  62 | and a.rcvr_id = b.rcvr_id\n  63 | and a.run_date>date_add(b.evnt_dt, interval 14 day)\n  64 | and a.run_date<=date_add(b.evnt_dt, interval 365 day)\n  65 | qualify row_number() over (partition by cust_id,rcvr_id,run_date order by evnt_dt desc)=1;\n  66 | \"\"\"\n  67 | # %ppbq $q\n  68 | q=f\"\"\"drop table if exists {bq_prefix}mlv2_gpt_similar_map_snapshot;\n  69 | create table  {bq_prefix}mlv2_gpt_similar_map_snapshot as\n  70 | with t as (\n  71 | select * from pypl-bods.gds_pacman_prod.cg_a1_plus_similar_merchant_map\n  72 | where dt=(select max(dt) from pypl-bods.gds_pacman_prod.cg_a1_plus_similar_merchant_map)\n  73 | )\n  74 | select t0.rcvr_id,\n  75 | t1.rcvr_id as rcvr_id_1,\n  76 | t2.rcvr_id as rcvr_id_2,\n  77 | t3.rcvr_id as rcvr_id_3,\n  78 | t4.rcvr_id as rcvr_id_4,\n  79 | t5.rcvr_id as rcvr_id_5,\n  80 | t6.rcvr_id as rcvr_id_6,\n  81 | t7.rcvr_id as rcvr_id_7,\n  82 | t8.rcvr_id as rcvr_id_8,\n  83 | t9.rcvr_id as rcvr_id_9,\n  84 | t10.rcvr_id as rcvr_id_10,\n  85 | t11.rcvr_id as rcvr_id_11,\n  86 | t12.rcvr_id as rcvr_id_12,\n  87 | t13.rcvr_id as rcvr_id_13,\n  88 | t14.rcvr_id as rcvr_id_14,\n  89 | t15.rcvr_id as rcvr_id_15,\n  90 | t16.rcvr_id as rcvr_id_16,\n  91 | t17.rcvr_id as rcvr_id_17,\n  92 | t18.rcvr_id as rcvr_id_18,\n  93 | t19.rcvr_id as rcvr_id_19,\n  94 | t20.rcvr_id as rcvr_id_20\n  95 | from t\n  96 | join {bq_prefix}live_unique_merchants_train t0\n  97 | on t.encrypted_merch_id = t0.encrypt_id\n  98 | left join {bq_prefix}live_unique_merchants_train t1\n  99 | on t.rank_1 = t1.encrypt_id\n 100 | left join {bq_prefix}live_unique_merchants_train t2\n 101 | on t.rank_2 = t2.encrypt_id\n 102 | left join {bq_prefix}live_unique_merchants_train t3\n 103 | on t.rank_3 = t3.encrypt_id\n 104 | left join {bq_prefix}live_unique_merchants_train t4\n 105 | on t.rank_4 = t4.encrypt_id\n 106 | left join {bq_prefix}live_unique_merchants_train t5\n 107 | on t.rank_5 = t5.encrypt_id\n 108 | left join {bq_prefix}live_unique_merchants_train t6\n 109 | on t.rank_6 = t6.encrypt_id\n 110 | left join {bq_prefix}live_unique_merchants_train t7\n 111 | on t.rank_7 = t7.encrypt_id\n 112 | left join {bq_prefix}live_unique_merchants_train t8\n 113 | on t.rank_8 = t8.encrypt_id\n 114 | left join {bq_prefix}live_unique_merchants_train t9\n 115 | on t.rank_9 = t9.encrypt_id\n 116 | left join {bq_prefix}live_unique_merchants_train t10\n 117 | on t.rank_10 = t10.encrypt_id\n 118 | left join {bq_prefix}live_unique_merchants_train t11\n 119 | on t.rank_11 = t11.encrypt_id\n 120 | left join {bq_prefix}live_unique_merchants_train t12\n 121 | on t.rank_12 = t12.encrypt_id\n 122 | left join {bq_prefix}live_unique_merchants_train t13\n 123 | on t.rank_13 = t13.encrypt_id\n 124 | left join {bq_prefix}live_unique_merchants_train t14\n 125 | on t.rank_14 = t14.encrypt_id\n 126 | left join {bq_prefix}live_unique_merchants_train t15\n 127 | on t.rank_15 = t15.encrypt_id\n 128 | left join {bq_prefix}live_unique_merchants_train t16\n 129 | on t.rank_16 = t16.encrypt_id\n 130 | left join {bq_prefix}live_unique_merchants_train t17\n 131 | on t.rank_17 = t17.encrypt_id\n 132 | left join {bq_prefix}live_unique_merchants_train t18\n 133 | on t.rank_18 = t18.encrypt_id\n 134 | left join {bq_prefix}live_unique_merchants_train t19\n 135 | on t.rank_19 = t19.encrypt_id\n 136 | left join {bq_prefix}live_unique_merchants_train t20\n 137 | on t.rank_20 = t20.encrypt_id;\n 138 | \"\"\"\n 139 | # %ppbq $q\n 140 | q=f\"\"\"drop table if exists {bq_prefix}mlv2_gpt_similar_map_snapshot_1;\n 141 | create table  {bq_prefix}mlv2_gpt_similar_map_snapshot_1 as\n 142 | with t as (select rcvr_id,\n 143 | CONCAT(\n 144 | IF(rcvr_id_1 IS NOT NULL, CONCAT(rcvr_id_1, ','), ''),\n 145 | IF(rcvr_id_2 IS NOT NULL, CONCAT(rcvr_id_2, ','), ''),\n 146 | IF(rcvr_id_3 IS NOT NULL, CONCAT(rcvr_id_3, ','), ''),\n 147 | IF(rcvr_id_4 IS NOT NULL, CONCAT(rcvr_id_4, ','), ''),\n 148 | IF(rcvr_id_5 IS NOT NULL, CONCAT(rcvr_id_5, ','), ''),\n 149 | IF(rcvr_id_6 IS NOT NULL, CONCAT(rcvr_id_6, ','), ''),\n 150 | IF(rcvr_id_7 IS NOT NULL, CONCAT(rcvr_id_7, ','), ''),\n 151 | IF(rcvr_id_8 IS NOT NULL, CONCAT(rcvr_id_8, ','), ''),\n 152 | IF(rcvr_id_9 IS NOT NULL, CONCAT(rcvr_id_9, ','), ''),\n 153 | IF(rcvr_id_10 IS NOT NULL, CONCAT(rcvr_id_10, ','), ''),\n 154 | IF(rcvr_id_11 IS NOT NULL, CONCAT(rcvr_id_11, ','), ''),\n 155 | IF(rcvr_id_12 IS NOT NULL, CONCAT(rcvr_id_12, ','), ''),\n 156 | IF(rcvr_id_13 IS NOT NULL, CONCAT(rcvr_id_13, ','), ''),\n 157 | IF(rcvr_id_14 IS NOT NULL, CONCAT(rcvr_id_14, ','), ''),\n 158 | IF(rcvr_id_15 IS NOT NULL, CONCAT(rcvr_id_15, ','), ''),\n 159 | IF(rcvr_id_16 IS NOT NULL, CONCAT(rcvr_id_16, ','), ''),\n 160 | IF(rcvr_id_17 IS NOT NULL, CONCAT(rcvr_id_17, ','), ''),\n 161 | IF(rcvr_id_18 IS NOT NULL, CONCAT(rcvr_id_18, ','), ''),\n 162 | IF(rcvr_id_19 IS NOT NULL, CONCAT(rcvr_id_19, ','), ''),\n 163 | IF(rcvr_id_20 IS NOT NULL, CONCAT(rcvr_id_20, ','), '')\n 164 | ) AS similar_list\n 165 | from {bq_prefix}mlv2_gpt_similar_map_snapshot\n 166 | ),\n 167 | t1 as (\n 168 | select rcvr_id,\n 169 | LEFT(similar_list, LENGTH(similar_list) - 1) AS similar_list\n 170 | from t\n 171 | WHERE LENGTH(similar_list)>0)\n 172 | select rcvr_id,\n 173 | SPLIT(similar_list, ',')[SAFE_OFFSET(0)] AS similar_1,\n 174 | SPLIT(similar_list, ',')[SAFE_OFFSET(1)] AS similar_2,\n 175 | SPLIT(similar_list, ',')[SAFE_OFFSET(2)] AS similar_3,\n 176 | SPLIT(similar_list, ',')[SAFE_OFFSET(3)] AS similar_4,\n 177 | SPLIT(similar_list, ',')[SAFE_OFFSET(4)] AS similar_5,\n 178 | SPLIT(similar_list, ',')[SAFE_OFFSET(5)] AS similar_6,\n 179 | SPLIT(similar_list, ',')[SAFE_OFFSET(6)] AS similar_7,\n 180 | SPLIT(similar_list, ',')[SAFE_OFFSET(7)] AS similar_8,\n 181 | SPLIT(similar_list, ',')[SAFE_OFFSET(8)] AS similar_9,\n 182 | SPLIT(similar_list, ',')[SAFE_OFFSET(9)] AS similar_10,\n 183 | SPLIT(similar_list, ',')[SAFE_OFFSET(10)] AS similar_11,\n 184 | SPLIT(similar_list, ',')[SAFE_OFFSET(11)] AS similar_12,\n 185 | SPLIT(similar_list, ',')[SAFE_OFFSET(12)] AS similar_13,\n 186 | SPLIT(similar_list, ',')[SAFE_OFFSET(13)] AS similar_14,\n 187 | SPLIT(similar_list, ',')[SAFE_OFFSET(14)] AS similar_15,\n 188 | SPLIT(similar_list, ',')[SAFE_OFFSET(15)] AS similar_16,\n 189 | SPLIT(similar_list, ',')[SAFE_OFFSET(16)] AS similar_17,\n 190 | SPLIT(similar_list, ',')[SAFE_OFFSET(17)] AS similar_18,\n 191 | SPLIT(similar_list, ',')[SAFE_OFFSET(18)] AS similar_19,\n 192 | SPLIT(similar_list, ',')[SAFE_OFFSET(19)] AS similar_20\n 193 | from t1;\n 194 | \"\"\"\n 195 | # %ppbq $q\n 196 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_txn_save_365d_similar;\n 197 | create table  {bq_prefix}driver_oot_txn_save_365d_similar as\n 198 | select a.*,\n 199 | case when a.last_puchase_ts is not null and a.last_save_date is not null then concat('b_purchase_',cast(a.last_puchase_ts as string),'a_save_',cast(a.last_save_date as string))\n 200 | when a.last_puchase_ts is not null and a.last_save_date is null then concat('b_purchase_',cast(a.last_puchase_ts as string))\n 201 | else concat('a_save_',cast(a.last_save_date as string)) end as similar_to,\n 202 | similar_1,similar_2,similar_3,similar_4,similar_5,similar_6,similar_7,similar_8,similar_9,similar_10,similar_11,similar_12,similar_13,similar_14,similar_15,similar_16,similar_17,similar_18,similar_19,similar_20\n 203 | from {bq_prefix}driver_oot_txn_save_365d a\n 204 | left join {bq_prefix}mlv2_gpt_similar_map_snapshot_1 b\n 205 | on a.rcvr_id=b.rcvr_id\n 206 | where a.last_puchase_ts is not null or a.last_save_date is not null;\n 207 | \"\"\"\n 208 | # %ppbq $q\n 209 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_txn_save_365d_similar_dedup;\n 210 | create table  {bq_prefix}driver_oot_txn_save_365d_similar_dedup as\n 211 | with t as (select cust_id,run_date,\n 212 |            ARRAY_CONCAT(\n 213 |             ARRAY_AGG(rcvr_id IGNORE NULLS order by similar_to desc),\n 214 |             IFNULL(ARRAY_AGG(similar_1 IGNORE NULLS order by similar_to desc),[]),\n 215 |             IFNULL(ARRAY_AGG(similar_2 IGNORE NULLS order by similar_to desc),[]),\n 216 |             IFNULL(ARRAY_AGG(similar_3 IGNORE NULLS order by similar_to desc),[]),\n 217 |             IFNULL(ARRAY_AGG(similar_4 IGNORE NULLS order by similar_to desc),[]),\n 218 |             IFNULL(ARRAY_AGG(similar_5 IGNORE NULLS order by similar_to desc),[]),\n 219 |             IFNULL(ARRAY_AGG(similar_6 IGNORE NULLS order by similar_to desc),[]),\n 220 |             IFNULL(ARRAY_AGG(similar_7 IGNORE NULLS order by similar_to desc),[]),\n 221 |             IFNULL(ARRAY_AGG(similar_8 IGNORE NULLS order by similar_to desc),[]),\n 222 |             IFNULL(ARRAY_AGG(similar_9 IGNORE NULLS order by similar_to desc),[]),\n 223 |             IFNULL(ARRAY_AGG(similar_10 IGNORE NULLS order by similar_to desc),[]),\n 224 |             IFNULL(ARRAY_AGG(similar_11 IGNORE NULLS order by similar_to desc),[]),\n 225 |             IFNULL(ARRAY_AGG(similar_12 IGNORE NULLS order by similar_to desc),[]),\n 226 |             IFNULL(ARRAY_AGG(similar_13 IGNORE NULLS order by similar_to desc),[]),\n 227 |             IFNULL(ARRAY_AGG(similar_14 IGNORE NULLS order by similar_to desc),[]),\n 228 |             IFNULL(ARRAY_AGG(similar_15 IGNORE NULLS order by similar_to desc),[]),\n 229 |             IFNULL(ARRAY_AGG(similar_16 IGNORE NULLS order by similar_to desc),[]),\n 230 |             IFNULL(ARRAY_AGG(similar_17 IGNORE NULLS order by similar_to desc),[]),\n 231 |             IFNULL(ARRAY_AGG(similar_18 IGNORE NULLS order by similar_to desc),[]),\n 232 |             IFNULL(ARRAY_AGG(similar_19 IGNORE NULLS order by similar_to desc),[]),\n 233 |             IFNULL(ARRAY_AGG(similar_20 IGNORE NULLS order by similar_to desc),[])\n 234 |            ) as concat_similar\n 235 | from {bq_prefix}driver_oot_txn_save_365d_similar\n 236 | group by 1,2),\n 237 | t1 as (\n 238 | select t.*,\n 239 |  ARRAY(\n 240 |     SELECT DISTINCT element\n 241 |     FROM UNNEST(concat_similar) AS element\n 242 |   ) AS concat_similar_dedup\n 243 | FROM t\n 244 |     )\n 245 | select cust_id,run_date,similar_merch,similar_merch_index+1 as past_txn_save_similar_rank\n 246 | from t1,UNNEST(concat_similar_dedup) AS similar_merch WITH OFFSET AS similar_merch_index;\n 247 | \"\"\"\n 248 | # %ppbq $q\n 249 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_two_tower_similar_score;\n 250 | create table  {bq_prefix}driver_oot_two_tower_similar_score as\n 251 | with cust_tower as \n 252 | (\n 253 |     select * from pypl-bods.gds_pacman_prod.mlv1_retrieval_cust_embedding\n 254 |     where dt=(select max(dt) from pypl-bods.gds_pacman_prod.mlv1_retrieval_cust_embedding)\n 255 |     and sndr_id in (select distinct cust_id from {bq_prefix}driver_oot)\n 256 | ),\n 257 | merchant_tower as\n 258 | (\n 259 |     select a.*,b.rcvr_id\n 260 |     from pypl-bods.gds_pacman_prod.mlv1_retrieval_merch_embedding a\n 261 |     join {bq_prefix}live_merchants b\n 262 |     on a.encrypt_rcvrid=b.encrypt_id\n 263 |     where a.dt=(select max(dt) from pypl-bods.gds_pacman_prod.mlv1_retrieval_merch_embedding)\n 264 | )\n 265 | select \n 266 | oot.cust_id,oot.run_date,oot.rcvr_id,\n 267 | max(cust_tower.output_1_0*merchant_tower.output_1_0 +\n 268 |  cust_tower.output_1_1*merchant_tower.output_1_1 +\n 269 |  cust_tower.output_1_2*merchant_tower.output_1_2 +\n 270 |  cust_tower.output_1_3*merchant_tower.output_1_3 +\n 271 |  cust_tower.output_1_4*merchant_tower.output_1_4 +\n 272 |  cust_tower.output_1_5*merchant_tower.output_1_5 +\n 273 |  cust_tower.output_1_6*merchant_tower.output_1_6 +\n 274 |  cust_tower.output_1_7*merchant_tower.output_1_7 +\n 275 |  cust_tower.output_1_8*merchant_tower.output_1_8 +\n 276 |  cust_tower.output_1_9*merchant_tower.output_1_9 +\n 277 |  cust_tower.output_1_10*merchant_tower.output_1_10 +\n 278 |  cust_tower.output_1_11*merchant_tower.output_1_11 +\n 279 |  cust_tower.output_1_12*merchant_tower.output_1_12 +\n 280 |  cust_tower.output_1_13*merchant_tower.output_1_13 +\n 281 |  cust_tower.output_1_14*merchant_tower.output_1_14 +\n 282 |  cust_tower.output_1_15*merchant_tower.output_1_15 +\n 283 |  cust_tower.output_1_16*merchant_tower.output_1_16 +\n 284 |  cust_tower.output_1_17*merchant_tower.output_1_17 +\n 285 |  cust_tower.output_1_18*merchant_tower.output_1_18 +\n 286 |  cust_tower.output_1_19*merchant_tower.output_1_19 +\n 287 |  cust_tower.output_1_20*merchant_tower.output_1_20 +\n 288 |  cust_tower.output_1_21*merchant_tower.output_1_21 +\n 289 |  cust_tower.output_1_22*merchant_tower.output_1_22 +\n 290 |  cust_tower.output_1_23*merchant_tower.output_1_23 +\n 291 |  cust_tower.output_1_24*merchant_tower.output_1_24 +\n 292 |  cust_tower.output_1_25*merchant_tower.output_1_25 +\n 293 |  cust_tower.output_1_26*merchant_tower.output_1_26 +\n 294 |  cust_tower.output_1_27*merchant_tower.output_1_27 +\n 295 |  cust_tower.output_1_28*merchant_tower.output_1_28 +\n 296 |  cust_tower.output_1_29*merchant_tower.output_1_29 +\n 297 |  cust_tower.output_1_30*merchant_tower.output_1_30 +\n 298 |  cust_tower.output_1_31*merchant_tower.output_1_31 +\n 299 |  cust_tower.output_1_32*merchant_tower.output_1_32 +\n 300 |  cust_tower.output_1_33*merchant_tower.output_1_33 +\n 301 |  cust_tower.output_1_34*merchant_tower.output_1_34 +\n 302 |  cust_tower.output_1_35*merchant_tower.output_1_35 +\n 303 |  cust_tower.output_1_36*merchant_tower.output_1_36 +\n 304 |  cust_tower.output_1_37*merchant_tower.output_1_37 +\n 305 |  cust_tower.output_1_38*merchant_tower.output_1_38 +\n 306 |  cust_tower.output_1_39*merchant_tower.output_1_39 +\n 307 |  cust_tower.output_1_40*merchant_tower.output_1_40 +\n 308 |  cust_tower.output_1_41*merchant_tower.output_1_41 +\n 309 |  cust_tower.output_1_42*merchant_tower.output_1_42 +\n 310 |  cust_tower.output_1_43*merchant_tower.output_1_43 +\n 311 |  cust_tower.output_1_44*merchant_tower.output_1_44 +\n 312 |  cust_tower.output_1_45*merchant_tower.output_1_45 +\n 313 |  cust_tower.output_1_46*merchant_tower.output_1_46 +\n 314 |  cust_tower.output_1_47*merchant_tower.output_1_47 +\n 315 |  cust_tower.output_1_48*merchant_tower.output_1_48 +\n 316 |  cust_tower.output_1_49*merchant_tower.output_1_49 +\n 317 |  cust_tower.output_1_50*merchant_tower.output_1_50 +\n 318 |  cust_tower.output_1_51*merchant_tower.output_1_51 +\n 319 |  cust_tower.output_1_52*merchant_tower.output_1_52 +\n 320 |  cust_tower.output_1_53*merchant_tower.output_1_53 +\n 321 |  cust_tower.output_1_54*merchant_tower.output_1_54 +\n 322 |  cust_tower.output_1_55*merchant_tower.output_1_55 +\n 323 |  cust_tower.output_1_56*merchant_tower.output_1_56 +\n 324 |  cust_tower.output_1_57*merchant_tower.output_1_57 +\n 325 |  cust_tower.output_1_58*merchant_tower.output_1_58 +\n 326 |  cust_tower.output_1_59*merchant_tower.output_1_59 +\n 327 |  cust_tower.output_1_60*merchant_tower.output_1_60 +\n 328 |  cust_tower.output_1_61*merchant_tower.output_1_61 +\n 329 |  cust_tower.output_1_62*merchant_tower.output_1_62 +\n 330 |  cust_tower.output_1_63*merchant_tower.output_1_63) as dot_prod\n 331 | from {bq_prefix}driver_oot oot\n 332 | join cust_tower\n 333 | on oot.cust_id=cust_tower.sndr_id\n 334 | join merchant_tower\n 335 | on oot.rcvr_id=merchant_tower.rcvr_id\n 336 | group by 1,2,3;\n 337 | \"\"\"\n 338 | # %ppbq $q\n 339 | q=f\"\"\"drop table if exists {bq_prefix}driver_oot_hueristic_model_comparison;\n 340 | create table  {bq_prefix}driver_oot_hueristic_model_comparison as\n 341 | with din as (\n 342 | select cust_id,run_date,pp_merchant_id,max(cast(tf_2_onnx_model_out as numeric)) as tf_2_onnx_model_out\n 343 |     from {bq_prefix}oot_transformed_scored \n 344 |     group by 1,2,3\n 345 | ),\n 346 | temp as (\n 347 | select t.*,\n 348 | coalesce(past_txn_save_similar_rank,999) as past_txn_save_similar_rank,\n 349 | coalesce(-dot_prod,999) as two_tower_rank,\n 350 | coalesce(-score_transformed,999) as tpv_rank,\n 351 | din.tf_2_onnx_model_out as mlv3_score,\n 352 | from {bq_prefix}driver_oot t\n 353 | left join {bq_prefix}driver_oot_txn_save_365d_similar_dedup t1\n 354 | on t.cust_id=t1.cust_id\n 355 | and t.run_date=t1.run_date\n 356 | and t.rcvr_id=t1.similar_merch\n 357 | left join {bq_prefix}driver_oot_two_tower_similar_score t2\n 358 | on t.cust_id=t2.cust_id\n 359 | and t.run_date=t2.run_date\n 360 | and t.rcvr_id=t2.rcvr_id\n 361 | left join pypl-bods.gds_pacman_prod.ql_store_honey_merch_quality_scores_external t3\n 362 | on t.rcvr_id=t3.rcvr_id\n 363 | left join din\n 364 | on cast(t.cust_id as string)=cast(din.cust_id as string)\n 365 | and cast(t.run_date as string)=cast(din.run_date as string)\n 366 | and cast(t.rcvr_id as string)=cast(din.pp_merchant_id as string)\n 367 | )\n 368 | select cust_id,run_date,rcvr_id,gpt_1st_category_l2_index,pos_tag_type,target,\n 369 | DENSE_RANK() over (partition by cust_id,run_date order by past_txn_save_similar_rank,two_tower_rank,tpv_rank) as mlv2_rank,\n 370 | DENSE_RANK() over (partition by cust_id,run_date order by tpv_rank) as tpv_rank,\n 371 | DENSE_RANK() over (partition by cust_id,run_date order by mlv3_score desc) as mlv3_rank\n 372 | from temp;\n 373 | \"\"\"\n 374 | # %ppbq $q\n 375 | q=f\"\"\"with temp as (select \n 376 | 'tpv' as model,\n 377 | sum(case when tpv_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 378 | sum(case when tpv_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 379 | sum(case when tpv_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 380 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 381 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 382 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 383 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 384 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 385 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 386 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 387 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 388 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 389 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 390 | group by 1\n 391 | union all\n 392 | select\n 393 | 'mlv2' as model,\n 394 | sum(case when mlv2_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 395 | sum(case when mlv2_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 396 | sum(case when mlv2_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 397 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 398 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 399 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 400 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 401 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 402 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 403 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 404 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 405 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 406 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 407 | group by 1\n 408 | union all\n 409 | select\n 410 | 'mlv3' as model,\n 411 | sum(case when mlv3_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 412 | sum(case when mlv3_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 413 | sum(case when mlv3_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 414 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 415 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 416 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 417 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 418 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 419 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 420 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 421 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 422 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 423 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 424 | group by 1)\n 425 | select * from temp\n 426 | order by case model\n 427 |   when 'tpv' then 1\n 428 |   when 'mlv2' then 2\n 429 |   when 'mlv3' then 3\n 430 | END;\n 431 | \"\"\"\n 432 | # df_all = %ppbq $q\n 433 | df_all.to_csv(os.path.join(exported_eval_readout_base,'performane_all.csv'),index=False)\n 434 | import seaborn as sns\n 435 | import matplotlib.pyplot as plt\n 436 | fig, axes = plt.subplots(4, 3, figsize=(5, 5))\n 437 | axes = axes.flatten()\n 438 | for i in range(12):\n 439 |     sub_df = df_all[['model',df_all.columns[i+1]]]\n 440 |     sns.barplot(x=sub_df.columns[0], y=sub_df.columns[1], ax=axes[i], data=sub_df)\n 441 |     axes[i].set_xlabel('')\n 442 |     axes[i].tick_params(axis='x', labelsize=5)\n 443 |     axes[i].tick_params(axis='y', labelsize=5)\n 444 |     axes[i].set_ylabel(axes[i].get_ylabel(), fontsize=5)\n 445 | plt.tight_layout()\n 446 | plt.savefig(os.path.join(exported_eval_readout_base,'performane_all.png'),dpi=300)\n 447 | plt.show()\n 448 | q=f\"\"\"\n 449 | with temp as (select \n 450 | 'tpv' as model,\n 451 | sum(case when tpv_rank<=1 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_1,\n 452 | sum(case when tpv_rank<=2 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_2,\n 453 | sum(case when tpv_rank<=5 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_5,\n 454 | sum(case when tpv_rank<=1 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 455 | sum(case when tpv_rank<=2 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 456 | sum(case when tpv_rank<=5 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 457 | sum(case when tpv_rank<=1 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 458 | sum(case when tpv_rank<=2 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 459 | sum(case when tpv_rank<=5 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 460 | sum(case when tpv_rank<=1 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 461 | sum(case when tpv_rank<=2 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 462 | sum(case when tpv_rank<=5 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 463 | from {bq_prefix}driver_oot_hueristic_model_comparison a\n 464 | join {bq_prefix}driver_oot_features_expand_seq b\n 465 | on a.cust_id=b.cust_id and a.rcvr_id=b.rcvr_id and a.run_date=b.run_date\n 466 | where b.sndr_most_recent_100_merch_category = '0'\n 467 | group by 1\n 468 | union all\n 469 | select\n 470 | 'mlv2' as model,\n 471 | sum(case when mlv2_rank<=1 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_1,\n 472 | sum(case when mlv2_rank<=2 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_2,\n 473 | sum(case when mlv2_rank<=5 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_5,\n 474 | sum(case when mlv2_rank<=1 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 475 | sum(case when mlv2_rank<=2 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 476 | sum(case when mlv2_rank<=5 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 477 | sum(case when mlv2_rank<=1 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 478 | sum(case when mlv2_rank<=2 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 479 | sum(case when mlv2_rank<=5 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 480 | sum(case when mlv2_rank<=1 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 481 | sum(case when mlv2_rank<=2 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 482 | sum(case when mlv2_rank<=5 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 483 | from {bq_prefix}driver_oot_hueristic_model_comparison a\n 484 | join {bq_prefix}driver_oot_features_expand_seq b\n 485 | on a.cust_id=b.cust_id and a.rcvr_id=b.rcvr_id and a.run_date=b.run_date\n 486 | where b.sndr_most_recent_100_merch_category = '0'\n 487 | group by 1\n 488 | union all\n 489 | select\n 490 | 'mlv3' as model,\n 491 | sum(case when mlv3_rank<=1 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_1,\n 492 | sum(case when mlv3_rank<=2 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_2,\n 493 | sum(case when mlv3_rank<=5 and a.target=1 then 1 else 0 end)/sum(case when a.target=1 then 1 else 0 end) as recall_at_5,\n 494 | sum(case when mlv3_rank<=1 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 495 | sum(case when mlv3_rank<=2 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 496 | sum(case when mlv3_rank<=5 and a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 497 | sum(case when mlv3_rank<=1 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 498 | sum(case when mlv3_rank<=2 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 499 | sum(case when mlv3_rank<=5 and a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 500 | sum(case when mlv3_rank<=1 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 501 | sum(case when mlv3_rank<=2 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 502 | sum(case when mlv3_rank<=5 and a.target=1 and a.pos_tag_type='save' then 1 else 0 end)/sum(case when a.target=1 and a.pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 503 | from {bq_prefix}driver_oot_hueristic_model_comparison a\n 504 | join {bq_prefix}driver_oot_features_expand_seq b\n 505 | on a.cust_id=b.cust_id and a.rcvr_id=b.rcvr_id and a.run_date=b.run_date\n 506 | where b.sndr_most_recent_100_merch_category = '0'\n 507 | group by 1)\n 508 | select * from temp\n 509 | order by case model\n 510 |   when 'tpv' then 1\n 511 |   when 'mlv2' then 2\n 512 |   when 'mlv3' then 3\n 513 | END;\n 514 | \"\"\"\n 515 | # df_ftu = %ppbq $q\n 516 | df_ftu.to_csv(os.path.join(exported_eval_readout_base,'performane_ftu.csv'),index=False)\n 517 | import seaborn as sns\n 518 | import matplotlib.pyplot as plt\n 519 | fig, axes = plt.subplots(4, 3, figsize=(5, 5))\n 520 | axes = axes.flatten()\n 521 | for i in range(12):\n 522 |     sub_df = df_ftu[['model',df_ftu.columns[i+1]]].copy()\n 523 |     sns.barplot(x=sub_df.columns[0], y=sub_df.columns[1], data=sub_df, ax=axes[i])\n 524 |     axes[i].set_xlabel('')\n 525 |     axes[i].tick_params(axis='x', labelsize=5)\n 526 |     axes[i].tick_params(axis='y', labelsize=5)\n 527 |     axes[i].set_ylabel(axes[i].get_ylabel(), fontsize=5)\n 528 | plt.tight_layout()\n 529 | plt.savefig(os.path.join(exported_eval_readout_base,'performane_ftu.png'),dpi=300)\n 530 | plt.show()\n 531 | remove_list = \"'1365556366671835703','2254348706417584521','1581565211190403045','1157330454984142772','1339933886421356550','1812170125034785903','6053464759929799123','1587111025150613712','1672368731209095395','1365556366671835703','6085552794250364378','1954349237309389875'\"\n 532 | q=f\"\"\"with temp as (select \n 533 | 'tpv' as model,\n 534 | sum(case when tpv_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 535 | sum(case when tpv_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 536 | sum(case when tpv_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 537 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 538 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 539 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 540 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 541 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 542 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 543 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 544 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 545 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 546 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 547 | where rcvr_id not in ({remove_list})\n 548 | group by 1\n 549 | union all\n 550 | select\n 551 | 'mlv2' as model,\n 552 | sum(case when mlv2_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 553 | sum(case when mlv2_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 554 | sum(case when mlv2_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 555 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 556 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 557 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 558 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 559 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 560 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 561 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 562 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 563 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 564 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 565 | where rcvr_id not in ({remove_list})\n 566 | group by 1\n 567 | union all\n 568 | select\n 569 | 'mlv3' as model,\n 570 | sum(case when mlv3_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 571 | sum(case when mlv3_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 572 | sum(case when mlv3_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 573 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 574 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 575 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 576 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 577 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 578 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 579 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 580 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 581 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 582 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 583 | where rcvr_id not in ({remove_list})\n 584 | group by 1)\n 585 | select * from temp\n 586 | order by case model\n 587 |   when 'tpv' then 1\n 588 |   when 'mlv2' then 2\n 589 |   when 'mlv3' then 3\n 590 | END;\n 591 | \"\"\"\n 592 | # df_wo_ebay = %ppbq $q\n 593 | df_wo_ebay.to_csv(os.path.join(exported_eval_readout_base,'performane_wo_ebay.csv'),index=False)\n 594 | import seaborn as sns\n 595 | import matplotlib.pyplot as plt\n 596 | fig, axes = plt.subplots(4, 3, figsize=(5, 5))\n 597 | axes = axes.flatten()\n 598 | for i in range(12):\n 599 |     sub_df = df_wo_ebay[['model',df_wo_ebay.columns[i+1]]].copy()\n 600 |     sns.barplot(x=sub_df.columns[0], y=sub_df.columns[1], data=sub_df, ax=axes[i])\n 601 |     axes[i].set_xlabel('')\n 602 |     axes[i].tick_params(axis='x', labelsize=5)\n 603 |     axes[i].tick_params(axis='y', labelsize=5)\n 604 |     axes[i].set_ylabel(axes[i].get_ylabel(), fontsize=5)\n 605 | plt.tight_layout()\n 606 | plt.savefig(os.path.join(exported_eval_readout_base,'performane_wo_ebay.png'),dpi=300)\n 607 | plt.show()\n 608 | q=f\"\"\"with temp as (select \n 609 | 'tpv' as model,\n 610 | sum(case when tpv_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 611 | sum(case when tpv_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 612 | sum(case when tpv_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 613 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 614 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 615 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 616 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 617 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 618 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 619 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 620 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 621 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 622 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 623 | where run_date >=current_date-7\n 624 | group by 1\n 625 | union all\n 626 | select\n 627 | 'mlv2' as model,\n 628 | sum(case when mlv2_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 629 | sum(case when mlv2_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 630 | sum(case when mlv2_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 631 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 632 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 633 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 634 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 635 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 636 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 637 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 638 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 639 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 640 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 641 | where run_date >=current_date-7\n 642 | group by 1\n 643 | union all\n 644 | select\n 645 | 'mlv3' as model,\n 646 | sum(case when mlv3_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 647 | sum(case when mlv3_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 648 | sum(case when mlv3_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 649 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 650 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 651 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 652 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 653 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 654 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 655 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 656 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 657 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 658 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 659 | where run_date >=current_date-7\n 660 | group by 1)\n 661 | select * from temp\n 662 | order by case model\n 663 |   when 'tpv' then 1\n 664 |   when 'mlv2' then 2\n 665 |   when 'mlv3' then 3\n 666 | END;\n 667 | \"\"\"\n 668 | # df_wo_ebay = %ppbq $q\n 669 | # df_wo_ebay.to_csv(os.path.join(exported_eval_readout_base,'performane_wo_ebay.csv'),index=False)\n 670 | q=f\"\"\"with temp as (select \n 671 | 'tpv' as model,\n 672 | sum(case when tpv_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 673 | sum(case when tpv_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 674 | sum(case when tpv_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 675 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 676 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 677 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 678 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 679 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 680 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 681 | sum(case when tpv_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 682 | sum(case when tpv_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 683 | sum(case when tpv_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 684 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 685 | where run_date >=current_date-7\n 686 | group by 1\n 687 | union all\n 688 | select\n 689 | 'mlv2' as model,\n 690 | sum(case when mlv2_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 691 | sum(case when mlv2_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 692 | sum(case when mlv2_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 693 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 694 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 695 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 696 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 697 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 698 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 699 | sum(case when mlv2_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 700 | sum(case when mlv2_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 701 | sum(case when mlv2_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 702 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 703 | where run_date >=current_date-7\n 704 | group by 1\n 705 | union all\n 706 | select\n 707 | 'mlv3' as model,\n 708 | sum(case when mlv3_rank<=1 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_1,\n 709 | sum(case when mlv3_rank<=2 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_2,\n 710 | sum(case when mlv3_rank<=5 and target=1 then 1 else 0 end)/sum(case when target=1 then 1 else 0 end) as recall_at_5,\n 711 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_1,\n 712 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_2,\n 713 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='attributed_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='attributed_txn' then 1 else 0 end) as attributed_txn_recall_at_5,\n 714 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_1,\n 715 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_2,\n 716 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='pure_organirc_txn' then 1 else 0 end) as pure_organirc_txn_recall_at_5,\n 717 | sum(case when mlv3_rank<=1 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_1,\n 718 | sum(case when mlv3_rank<=2 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_2,\n 719 | sum(case when mlv3_rank<=5 and target=1 and pos_tag_type='save' then 1 else 0 end)/sum(case when target=1 and pos_tag_type='save' then 1 else 0 end) as save_recall_at_5,\n 720 | from {bq_prefix}driver_oot_hueristic_model_comparison\n 721 | where run_date <current_date-7\n 722 | group by 1)\n 723 | select * from temp\n 724 | order by case model\n 725 |   when 'tpv' then 1\n 726 |   when 'mlv2' then 2\n 727 |   when 'mlv3' then 3\n 728 | END;\n 729 | \"\"\"\n 730 | # df_wo_ebay = %ppbq $q\n 731 | # df_wo_ebay.to_csv(os.path.join(exported_eval_readout_base,'performane_wo_ebay.csv'),index=False)"
  }
}