{
  "summaries": {
    "rmr_agent/repos/PEP_PS-Model/modeling_script/01_raw_data_reading.py": "**[Importing necessary libraries and setting up configurations] (Lines 3-12):**\n- Imports essential libraries like pandas, numpy, and pickle.\n- Configures display options for pandas and IPython shell.\n\n**[Defining data sources] (Lines 14-31):**\n- Creates a dictionary `read_dict` that maps data source names to their respective server, file path, and separator.\n\n**[Function to read data from various sources] (Lines 33-52):**\n- Defines `read_data` function to read data from different sources (local files or HDFS) based on `read_dict`.\n- Processes and cleans the data, ensuring no duplicates and converting column names to lowercase.\n- Checks for primary keys in the data and returns a dictionary of dataframes.\n\n**[Function to check primary keys] (Lines 53-69):**\n- Defines `check_pk` function to identify primary keys in a dataframe.\n- Converts primary key columns to appropriate data types and checks for uniqueness.\n\n**[Reading data into a dictionary] (Lines 70-70):**\n- Calls `read_data` function with `read_dict` to read all data sources into `data_dict`.\n\n**[Categorizing variables into different types] (Lines 71-75):**\n- Initializes dictionaries to categorize variables into case, alert, hit, and account variables.\n\n**[Processing and categorizing each data source] (Lines 76-198):**\n- Iterates through each data source in `data_dict`, extracting keys and features.\n- Categorizes the variables into `case_var`, `alert_var`, `hit_var`, and `account_var` based on their type.\n\n**[Merging datasets] (Lines 199-231):**\n- Merges various datasets step-by-step:\n  - Merges account-based variables.\n  - Merges case-level variables.\n  - Merges alert-level variables.\n  - Merges hit-level variables.\n  - Manually merges the attack document data.\n\n**[Fixing and cleaning merged dataset] (Lines 232-248):**\n- Removes duplicated variables and fixes column names in the merged dataset.\n\n**[Saving the cleaned dataset] (Lines 250-252):**\n- Saves the cleaned and merged dataset to a pickle file.\n\n**[Auditing and exporting data for specific disciplines] (Lines 254-285):**\n- Loads the cleaned dataset and performs auditing for specific disciplines.\n- Samples data before and after certain dates, exports to CSV, and uploads to HDFS.",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/02-modeling_pep.py": "**[Import necessary libraries and set configurations] (Lines 2-24):**\n- Import libraries for file system operations, data manipulation, machine learning, and other utilities.\n- Set display options and filter warnings.\n\n**[Read and filter dataset] (Lines 25-36):**\n- Load dataset from a pickle file.\n- Filter dataset based on specific conditions.\n\n**[Define dataset columns] (Lines 37-50):**\n- Identify and categorize columns into metadata, numerical, and categorical columns.\n- Exclude certain columns from categorical and numerical lists.\n\n**[Convert specific categorical columns to numerical] (Lines 51-60):**\n- Convert specified categorical columns to numerical and update column lists.\n\n**[Convert remaining categorical columns to string] (Lines 61-63):**\n- Ensure all categorical columns are of string type.\n\n**[Analyze dataset statistics] (Lines 64-68):**\n- Display value counts and date range statistics for specific columns.\n\n**[Define functions to identify columns with high missing values and zero standard deviation] (Lines 69-84):**\n- Create functions to identify columns with high missing values and zero standard deviation.\n\n**[Clean dataset columns] (Lines 85-92):**\n- Identify and remove columns with high missing values and zero standard deviation from categorical and numerical lists.\n\n**[Split dataset into development and out-of-time sets] (Lines 93-101):**\n- Split dataset based on date ranges into development and out-of-time sets.\n\n**[Read and process additional dataset for feature shift analysis] (Lines 102-110):**\n- Load additional dataset and identify columns with significant feature shift.\n- Remove these columns from categorical and numerical lists.\n\n**[Save column names] (Lines 125-126):**\n- Save the final lists of categorical and numerical columns to a pickle file.\n\n**[Redefine tagging to multi-label] (Lines 127-135):**\n- Create new binary columns for multi-label classification based on existing tags.\n\n**[Impute missing values] (Lines 136-138):**\n- Fill missing values in categorical columns with 'unknown' and in numerical columns with -999.\n\n**[Build encoding dictionary and normalize numerical columns] (Lines 139-167):**\n- Create label encoders for categorical columns and save them.\n- Normalize numerical columns and save mean and standard deviation.\n- Save categorical embedding sizes.\n\n**[Split development dataset into training and testing sets] (Lines 170-183):**\n- Remove specific tags and split the development dataset into training and testing sets.\n- Save the indices of the training and testing sets.\n\n**[Prepare data for modeling] (Lines 190-191):**\n- Create data bundles for training and testing using a custom dataset class.\n\n**[Define model training function] (Lines 193-313):**\n- Define a function to train a multi-label model with specified parameters.\n- Include data loaders, loss calculation, accuracy measurement, and early stopping.\n\n**[Define objective function for hyperparameter tuning] (Lines 314-335):**\n- Define an objective function for Optuna to optimize model training parameters.\n\n**[Define custom callbacks for Optuna] (Lines 336-352):**\n- Create custom callbacks for stopping trials and saving study progress.\n\n**[Run hyperparameter optimization with Optuna] (Lines 353-365):**\n- Set up and run Optuna study to optimize model training parameters.\n- Save the study results.",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/03-modeling_ps.py": "**[Import necessary libraries and set configurations] (Lines 2-23):**\n- Import various libraries for data manipulation, machine learning, and system operations.\n- Set display options and filter warnings.\n\n**[Read and preprocess dataset] (Lines 24-54):**\n- Load dataset from a pickle file.\n- Filter dataset based on specific conditions.\n- Remove specific entries from the dataset.\n\n**[Read additional dataset from HDFS and preprocess] (Lines 32-44):**\n- Read a CSV file from HDFS.\n- Filter and clean the dataset based on specific conditions.\n\n**[Identify and handle duplicate columns] (Lines 45-54):**\n- Identify columns with specific suffixes and check their presence in the dataset.\n\n**[Define dataset columns] (Lines 55-70):**\n- Define metadata columns and separate numerical and categorical columns.\n- Handle specific data issues by filtering out bad data.\n\n**[Convert specific categorical columns to numerical] (Lines 71-80):**\n- Convert certain categorical columns to numerical and update column lists.\n\n**[Convert remaining categorical columns to string] (Lines 81-83):**\n- Convert remaining categorical columns to string type.\n\n**[Analyze dataset statistics] (Lines 84-88):**\n- Display value counts and time range statistics for specific columns.\n\n**[Define functions to identify columns with high missing values and zero standard deviation] (Lines 89-104):**\n- Define functions to identify columns with high missing values and zero standard deviation.\n\n**[Clean dataset by removing columns with high missing values and zero standard deviation] (Lines 105-112):**\n- Clean dataset by removing identified columns.\n\n**[Split dataset into development and out-of-time datasets] (Lines 113-121):**\n- Split dataset based on time_created column into development and out-of-time datasets.\n\n**[Read and preprocess STAR dataset] (Lines 122-136):**\n- Read STAR dataset and filter columns based on specific conditions.\n- Remove specific variables related to date of birth.\n\n**[Save column names to a pickle file] (Lines 140-141):**\n- Save the list of categorical and numerical columns to a pickle file.\n\n**[Redefine tagging to multi-label] (Lines 142-150):**\n- Create new binary columns for multi-label classification based on existing tags.\n\n**[Impute missing values] (Lines 151-153):**\n- Fill missing values in categorical columns with 'unknown' and in numerical columns with -999.\n\n**[Build encoding dictionary and normalize numerical columns] (Lines 154-182):**\n- Create label encoders for categorical columns and save them.\n- Normalize numerical columns and save mean and standard deviation.\n\n**[Dataset split for development dataset] (Lines 185-198):**\n- Split development dataset into training and testing sets.\n- Save the split indices to a pickle file.\n\n**[Prepare data for modeling] (Lines 202-204):**\n- Create data bundles for training and testing using a custom dataset class.\n\n**[Define model training function] (Lines 206-327):**\n- Define a function to train a multi-label model with specified parameters.\n- Include early stopping, loss calculation, and accuracy measurement.\n\n**[Train model with best parameters] (Lines 329-341):**\n- Define best parameters and train the model using the defined function.",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/04-model_evaluation.py": "**[Import necessary libraries and set configurations] (Lines 2-23):**\n- Import various libraries for data manipulation, machine learning, and visualization.\n- Set display options for pandas and configure IPython shell for interactive output.\n\n**[Define eval_oot function] (Lines 24-139):**\n- Define a function to evaluate out-of-time (OOT) datasets using a multi-label model.\n- Load model and preprocess dataset.\n- Make predictions and calculate probabilities for different tags.\n- Generate confusion matrices and aggregate evaluation results.\n\n**[Define eval_oot_lgbm function] (Lines 140-220):**\n- Define a function to evaluate OOT datasets using a LightGBM model.\n- Load model and preprocess dataset.\n- Make predictions and calculate probabilities for a specific tag.\n- Generate confusion matrices and aggregate evaluation results.\n\n**[Define eval_ds_auc function] (Lines 221-325):**\n- Define a function to evaluate datasets and calculate AUC scores.\n- Load model and preprocess dataset.\n- Make predictions and calculate probabilities for different tags.\n- Calculate and return AUC scores for each tag.\n\n**[Define slice_by_cut function] (Lines 326-348):**\n- Define a function to slice data by a probability cutoff and calculate recall and automation metrics.\n\n**[Define eval_train_val_oot function] (Lines 349-439):**\n- Define a function to evaluate training, validation, and OOT datasets.\n- Load model and preprocess datasets.\n- Make predictions and calculate probabilities for different tags.\n- Aggregate evaluation results and calculate AUC scores for different time periods.\n\n**[Define tvo_plot function] (Lines 440-458):**\n- Define a function to plot train-validation-OOT AUC scores over time.\n- Generate bar and line plots for the number of cases and AUC scores.\n\n**[Define gainChart function] (Lines 459-484):**\n- Define a function to create a gain chart for model predictions.\n- Bin predictions and calculate cumulative metrics.\n\n**[Define eval_model function] (Lines 485-504):**\n- Define a function to evaluate model precision and recall.\n- Calculate cumulative precision and recall for model predictions and ideal scenario.\n\n**[Define pt_roc_auc function] (Lines 505-519):**\n- Define a function to plot ROC curve and calculate AUC score.\n\n**[Define pr_line function] (Lines 520-561):**\n- Define a function to plot precision and recall lines.\n- Generate line plots for precision and recall by operation point and model score.\n\n**[Define eval_comb function] (Lines 562-566):**\n- Define a function to evaluate combined model results.\n- Generate ROC curve, precision-recall lines, and gain chart.\n\n**[Load and preprocess datasets for PEP v23.1] (Lines 567-655):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PS v24.1] (Lines 657-765):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v23.2] (Lines 782-874):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v23.3] (Lines 935-1001):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v23.4 LGBM] (Lines 1002-1052):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load LightGBM models and make predictions.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v25.1] (Lines 1053-1111):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v25.1 (2-layer)] (Lines 1112-1171):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PS v26.1] (Lines 1172-1227):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PS v26.2] (Lines 1228-1294):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v25.3] (Lines 1295-1354):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v25.5] (Lines 1355-1414):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v25.6] (Lines 1415-1474):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.\n\n**[Load and preprocess datasets for PEP v25.6 with new dob] (Lines 1475-1572):**\n- Load column names, dataset, and preprocess data.\n- Split dataset into training, validation, and OOT sets.\n- Load model and evaluation parameters.\n- Evaluate model and plot results.",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/05-lgbm_feature_importance_PEP.py": "**[Import necessary libraries and set configurations] (Lines 2-12):**\n- Imports LightGBM, pandas, IPython, scikit-learn, numpy, pickle, and warnings.\n- Configures IPython to display all outputs.\n- Sets pandas display options for maximum columns and rows.\n- Ignores warnings.\n\n**[Read and filter dataset] (Lines 14-15):**\n- Reads dataset from a pickle file.\n- Filters dataset based on specific conditions.\n\n**[Define and process dataset columns] (Lines 17-29):**\n- Loads categorical and numerical column names from a pickle file.\n- Converts categorical columns to object type and numerical columns to float type if necessary.\n- Converts 'discipline_id' column to string type.\n\n**[Split dataset into development and out-of-time sets] (Lines 30-37):**\n- Splits dataset into development and out-of-time sets based on 'time_created' column.\n- Creates new binary columns in both sets based on specific conditions.\n\n**[Convert categorical columns to category type] (Lines 39-40):**\n- Converts categorical columns in development and out-of-time sets to category type.\n\n**[Save processed datasets] (Lines 41-44):**\n- Saves the processed development and out-of-time datasets to pickle files.\n\n**[Split development dataset for training and testing] (Lines 50-58):**\n- Reads additional dataset and filters it.\n- Splits the filtered development dataset into training and testing sets.\n- Calculates and displays mean values of specific columns in training and testing sets.\n\n**[Define LightGBM model parameters] (Lines 60-76):**\n- Sets parameters for the LightGBM model, including task type, boosting type, objective, metric, and other hyperparameters.\n\n**[Train and save LightGBM models] (Lines 82-96):**\n- Iterates over specific discipline IDs and tags.\n- Creates LightGBM datasets for training and testing.\n- Trains LightGBM models and saves them to pickle files.\n\n**[Calculate and save feature importance for all features] (Lines 100-120):**\n- Iterates over discipline IDs and tags.\n- Loads trained models from pickle files.\n- Calculates feature importance for each model.\n- Saves feature importance to an Excel file.\n\n**[Calculate and display feature importance for top 10 features] (Lines 122-136):**\n- Iterates over discipline IDs and tags.\n- Loads trained models from pickle files.\n- Calculates and scales feature importance for each model.\n- Displays feature importance for the top 10 features.",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/06-lgbm_feature_importance_PS.py": "**[Import necessary libraries and set configurations] (Lines 2-12):**\n- Imports LightGBM, pandas, numpy, pickle, and warnings libraries.\n- Configures IPython to display all outputs.\n- Sets pandas display options for maximum columns and rows.\n- Ignores warnings.\n\n**[Read and filter dataset] (Lines 14-15):**\n- Reads dataset from a pickle file.\n- Filters dataset based on specific conditions.\n\n**[Define and process dataset columns] (Lines 17-30):**\n- Loads categorical and numerical column names from a pickle file.\n- Converts specific columns to appropriate data types.\n\n**[Split dataset into development and out-of-time sets] (Lines 31-38):**\n- Splits the dataset into development and out-of-time sets based on a date condition.\n- Creates new binary columns based on specific conditions.\n\n**[Convert categorical columns to category type] (Lines 40-41):**\n- Converts categorical columns in both development and out-of-time sets to category data type.\n\n**[Split development dataset for training and testing] (Lines 42-55):**\n- Splits the development dataset into training and testing sets.\n- Calculates and displays the mean of specific tags in both sets.\n\n**[Define LightGBM model parameters] (Lines 56-73):**\n- Sets parameters for the LightGBM model, including task type, boosting type, objective, metric, and other hyperparameters.\n\n**[Train and save LightGBM models] (Lines 79-93):**\n- Iterates over specific discipline IDs and tags.\n- Creates LightGBM datasets for training and testing.\n- Trains the LightGBM model and saves it to a pickle file.\n\n**[Calculate and save feature importance for all features] (Lines 97-117):**\n- Loads trained models from pickle files.\n- Calculates feature importance for each model.\n- Saves the feature importance data to an Excel file.\n\n**[Calculate and display feature importance for top 10 features] (Lines 119-133):**\n- Loads trained models from pickle files.\n- Calculates feature importance for each model.\n- Displays the feature importance for the top 10 features."
  },
  "cleaned_code": {
    "rmr_agent/repos/PEP_PS-Model/modeling_script/01_raw_data_reading.py": "   1 | # ## This script consolidates all variables into a raw dataset that can be used by model\n   2 | # %hive_horton\n   3 | import pandas as pd\n   4 | from hdfs3 import HDFileSystem\n   5 | hdfs_s = HDFileSystem(host='stampy')\n   6 | hdfs_h = HDFileSystem(host='horton')\n   7 | import numpy as np\n   8 | from IPython.core.interactiveshell import InteractiveShell\n   9 | InteractiveShell.ast_node_interactivity = \"all\"\n  10 | pd.set_option('display.max_columns', 500)\n  11 | pd.set_option('display.max_rows', 500)\n  12 | from functools import reduce\n  13 | import pickle\n  14 | read_dict={\n  15 |     'driver':['gn','/home/chaoychen/shared_data/data/keyuchen/pep_ps_scm_hits_driver_v2.pkl',''],\n  16 |     'bert':['gn','/home/chaoychen/shared_data/data/keyuchen/final_bert_score_v2.csv',','],\n  17 |     'context':['horton','/apps/risk/qpull/out/chaoychen_1659461390_tdmovetpt_fexp.csv','\\x07'],\n  18 |     'attack':['horton','/apps/risk/qpull/out/chaoychen_1659461423_tdmovetpt_fexp.csv','\\x07'],\n  19 |     'gib':['horton','/user/chaoychen/tmp_load/pep_ps_scm_gib_after_function2_v2.csv','\\x07'],\n  20 |     'lokale':['horton','/user/chaoychen/pep_ps/all_var_v6/driver_alert_lokale_fea_v2.csv','\\x07'],\n  21 |     'graph':['stampy','/user/chaoychen/pep_ps/all_var_v6/pep_ps_scm_cases_tag_driver_v2_graph_vars_txn.csv','\\x07'],\n  22 |     'match':['horton','/user/chaoychen/pep_ps/all_var_v6/driver_match_can_eav_lokale_agg_fea_v2.csv','\\x07'],\n  23 |     'dobmatch':['gn','/home/chaoychen/shared_data/data/keyuchen/scm_vars/df_dob_vars_final_v2_new.pkl',''],# new\n  24 |     'basicmatch':['gn','/home/chaoychen/shared_data/data/keyuchen/similarity_scores/df_basic_match_v2_new.pkl',''],# new\n  25 |     'meta':['horton','/apps/risk/qpull/out/chaoychen_1659461961_tdmovetpt_fexp.csv','\\x07'],\n  26 |     'latin':['horton','/apps/risk/qpull/out/chaoychen_1659462393_tdmovetpt_fexp.csv','\\x07'],\n  27 |     'if_primary':['horton','/apps/risk/qpull/out/chaoychen_1660842135_tdmovetpt_fexp.csv','\\x07'],# new\n  28 |     'bert_sim':['gn','/home/chaoychen/shared_data/data/keyuchen/similarity_scores/df_location_full_bert_scores_agg_v2.pkl',''],\n  29 |     'geo_sim':['gn','/home/chaoychen/shared_data/data/keyuchen/similarity_scores/df_location_geo_fuzz_v2_new.pkl',''],#new\n  30 |     'fuzz_sim':['gn','/home/chaoychen/shared_data/data/keyuchen/similarity_scores/df_location_fuzz_v2_new.pkl',''],#new\n  31 |     'hits_per_case':['horton','/apps/risk/qpull/out/chaoychen_1659462422_tdmovetpt_fexp.csv','\\x07']\n  32 | }\n  33 | def read_data(read_dict):\n  34 |     return_dict={}\n  35 |     for key, comb in read_dict.items():\n  36 |         server,path,sep=comb[0],comb[1],comb[2]\n  37 |         if server=='gn':\n  38 |             if sep=='':\n  39 |                 with open(path,'rb') as f:\n  40 |                     _data=pickle.load(f).drop_duplicates()\n  41 |             else:\n  42 |                 _data = pd.read_csv(path,sep=sep)\n  43 |         else:\n  44 |             hdfs = HDFileSystem(host=server)\n  45 |             with hdfs.open(path) as f:\n  46 |                 _data = pd.read_csv(f,sep=sep).drop_duplicates()\n  47 |         _data.columns = _data.columns.str.lower()\n  48 |         if key=='driver':\n  49 |             _data = _data.loc[_data['new_logic_label']!='Auto-Dis',:]\n  50 |         pk = check_pk(_data)\n  51 |         return_dict[key] = [pk,_data]\n  52 |     return return_dict\n  53 | def check_pk(df):\n  54 |     pk_ls=['tid','alert_cust_id','entity_id']\n  55 |     for pk in pk_ls:\n  56 |         if pk in df.columns:\n  57 |             try:\n  58 |                 df[pk] = df[pk].astype('int64')\n  59 |             except:\n  60 |                 df[pk] = df[pk].astype('float64')\n  61 |     n_row = df.shape[0]\n  62 |     for i in range(1,len(pk_ls)+1):\n  63 |         try:\n  64 |             n_row_test = df[pk_ls[:i]].drop_duplicates().shape[0]\n  65 |         except:\n  66 |             n_row_test=0\n  67 |         if n_row_test==n_row:\n  68 |             return pk_ls[:i]\n  69 |     return\n  70 | data_dict = read_data(read_dict)\n  71 | # every variable set is categorized into four types, they will be merged by their key later\n  72 | case_var = {}\n  73 | alert_var = {}\n  74 | hit_var = {}\n  75 | account_var = {}\n  76 | # ## 00 - Driver Tag\n  77 | data_dict['driver'][0]\n  78 | data_dict['driver'][1].shape\n  79 | # ## 01 - Context\n  80 | data_dict['context'][0]\n  81 | data_dict['context'][1].shape\n  82 | key_context = data_dict['context'][0]\n  83 | fea_context = data_dict['context'][1].columns[1:].tolist()\n  84 | fea_context\n  85 | case_var['context'] = data_dict['context'][1].loc[:,key_context+fea_context]\n  86 | # ## 02 - Attack doc\n  87 | data_dict['attack'][0]\n  88 | data_dict['attack'][1].shape\n  89 | data_dict['attack'][1][['alert_cust_id','entity_id']].drop_duplicates().shape\n  90 | key_attackdoc = ['alert_cust_id','entity_id']\n  91 | fea_attackdoc = data_dict['attack'][1].columns[2:].tolist()\n  92 | fea_attackdoc\n  93 | # ## 03 - Gibberish component\n  94 | data_dict['gib'][0]\n  95 | data_dict['gib'][1].shape\n  96 | key_gib = data_dict['gib'][0]\n  97 | fea_gib = data_dict['gib'][1].columns[3:].tolist()\n  98 | fea_gib\n  99 | alert_var['gib'] = data_dict['gib'][1].loc[:,key_gib+fea_gib]\n 100 | # ## 04 - Lokale Var\n 101 | data_dict['lokale'][0]\n 102 | data_dict['lokale'][1].shape\n 103 | key_lokale = data_dict['lokale'][0]\n 104 | fea_lokale = data_dict['lokale'][1].columns[7:-1].tolist()\n 105 | fea_lokale\n 106 | len(fea_lokale)\n 107 | hit_var['lokale'] = data_dict['lokale'][1].loc[:,key_lokale+fea_lokale]\n 108 | # ## 05-Graph Var\n 109 | data_dict['graph'][0]\n 110 | data_dict['graph'][1].shape\n 111 | data_dict['graph'][1][['accountnumber','pit_context']].drop_duplicates().shape\n 112 | key_graph = ['accountnumber','pit_context']\n 113 | fea_graph = [i for i in data_dict['graph'][1].columns[3:] if not any(['pep' in i,'sanction' in i])]\n 114 | len(fea_graph)\n 115 | fea_graph\n 116 | # ## 06 - Match\n 117 | data_dict['match'][0]\n 118 | data_dict['match'][1].shape\n 119 | key_match = data_dict['match'][0]\n 120 | fea_match = data_dict['match'][1].columns[6:-1].tolist()\n 121 | len(fea_match)\n 122 | fea_match\n 123 | hit_var['match'] = data_dict['match'][1].loc[:,key_match+fea_match]\n 124 | # ## 07 - Name Matching\n 125 | data_dict['dobmatch'][0]\n 126 | data_dict['dobmatch'][1].shape\n 127 | key_namematch = data_dict['dobmatch'][0]\n 128 | fea_namematch = data_dict['dobmatch'][1].columns[4:].tolist()\n 129 | len(fea_namematch)\n 130 | fea_namematch\n 131 | hit_var['dobmatch'] = data_dict['dobmatch'][1].loc[:,key_namematch+fea_namematch]\n 132 | # ## 08 - meta\n 133 | data_dict['meta'][0]\n 134 | data_dict['meta'][1].shape\n 135 | key_meta = data_dict['meta'][0]\n 136 | fea_meta = data_dict['meta'][1].columns[3:].tolist()\n 137 | len(fea_meta)\n 138 | fea_meta\n 139 | hit_var['meta'] = data_dict['meta'][1].loc[:,key_meta+fea_meta]\n 140 | # ## 09 - Latin\n 141 | data_dict['latin'][1]['tid'] = data_dict['latin'][1]['tid'].astype('int64')\n 142 | data_dict['latin'][0]\n 143 | data_dict['latin'][1].shape\n 144 | data_dict['latin'][1][['alert_cust_id','entity_id']].drop_duplicates().shape\n 145 | key_latin = data_dict['latin'][0]\n 146 | fea_latin = data_dict['latin'][1].columns[3:].tolist()\n 147 | len(fea_latin)\n 148 | fea_latin\n 149 | hit_var['latin'] = data_dict['latin'][1].loc[:,key_latin+fea_latin]\n 150 | # ## 10 - Bert\n 151 | data_dict['bert'][0]\n 152 | data_dict['bert'][1].shape\n 153 | key_bert = data_dict['bert'][0]\n 154 | fea_bert = data_dict['bert'][1].columns[4:].tolist()\n 155 | len(fea_bert)\n 156 | fea_bert\n 157 | hit_var['bert'] = data_dict['bert'][1].loc[:,key_bert+fea_bert]\n 158 | # ## 11 - bert_sim\n 159 | data_dict['bert_sim'][0]\n 160 | data_dict['bert_sim'][1].shape\n 161 | key_bert_sim = data_dict['bert_sim'][0]\n 162 | fea_bert_sim = data_dict['bert_sim'][1].columns[3:].tolist()\n 163 | fea_bert_sim\n 164 | hit_var['bert_sim'] = data_dict['bert_sim'][1].loc[:,key_bert_sim+fea_bert_sim]\n 165 | data_dict['geo_sim'][0]\n 166 | data_dict['geo_sim'][1].shape\n 167 | key_geo_sim = data_dict['geo_sim'][0]\n 168 | fea_geo_sim = data_dict['geo_sim'][1].columns[3:].tolist()\n 169 | fea_geo_sim\n 170 | hit_var['geo_sim'] = data_dict['geo_sim'][1].loc[:,key_geo_sim+fea_geo_sim]\n 171 | data_dict['fuzz_sim'][0]\n 172 | data_dict['fuzz_sim'][1].shape\n 173 | data_dict['geo_sim'][1][['tid','alert_cust_id','entity_id']].dtypes\n 174 | key_fuzz_sim = data_dict['fuzz_sim'][0]\n 175 | fea_fuzz_sim = data_dict['fuzz_sim'][1].columns[3:].tolist()\n 176 | fea_fuzz_sim\n 177 | hit_var['fuzz_sim'] = data_dict['fuzz_sim'][1].loc[:,key_fuzz_sim+fea_fuzz_sim]\n 178 | # ## 12 - hit_per_case\n 179 | data_dict['hits_per_case'][0]\n 180 | data_dict['hits_per_case'][1].shape\n 181 | key_hits_per_case = data_dict['hits_per_case'][0]\n 182 | fea_hits_per_case = data_dict['hits_per_case'][1].columns[1:].tolist()\n 183 | fea_hits_per_case\n 184 | case_var['hits_per_case'] = data_dict['hits_per_case'][1].loc[:,key_hits_per_case+fea_hits_per_case]\n 185 | # ## 13 - Basic Match\n 186 | data_dict['basicmatch'][0]\n 187 | data_dict['basicmatch'][1].shape\n 188 | key_basicmatch = data_dict['basicmatch'][0]\n 189 | fea_basicmatch = data_dict['basicmatch'][1].columns[8:].tolist()\n 190 | fea_basicmatch\n 191 | hit_var['basicmatch'] = data_dict['basicmatch'][1].loc[:,key_basicmatch+fea_basicmatch]\n 192 | # ## 14 - if parimary\n 193 | data_dict['if_primary'][0]\n 194 | data_dict['if_primary'][1].shape\n 195 | key_ifprimary = data_dict['if_primary'][0]\n 196 | fea_ifprimary = data_dict['if_primary'][1].columns[3:].tolist()\n 197 | fea_ifprimary\n 198 | hit_var['if_primary'] = data_dict['if_primary'][1].loc[:,key_ifprimary+fea_ifprimary]\n 199 | # ## Merging dataset\n 200 | # ### P0 - merging account based variables - 1 seg: graph\n 201 | # get unique account pit join key\n 202 | raw_dri = data_dict['driver'][1]\n 203 | raw_graph = data_dict['graph'][1]\n 204 | raw_dri['pit_context'] = (pd.to_datetime(raw_dri.loc[:,'time_created'])-pd.Timestamp(\"1970-01-01 00:00:00\")) // pd.Timedelta('1s')\n 205 | raw_dri['account_pit'] = raw_dri['entity_reference_id'].astype('str') +'_'+ raw_dri['pit_context'].astype('str')\n 206 | raw_graph['pit_context'] = (pd.to_datetime(raw_graph.loc[:,'pit_timestamp'].str[:19])-pd.Timestamp(\"1970-01-01 00:00:00\")) // pd.Timedelta('1s')\n 207 | raw_graph['account_pit'] = raw_graph['accountnumber'].astype('str') +'_'+ raw_graph['pit_context'].astype('str')\n 208 | ## Validate - all keys in driver should exist in graph - 99% found\n 209 | np.sum(raw_dri['account_pit'].isin(raw_graph['account_pit']))\n 210 | raw_dri.shape\n 211 | all_var1 = pd.merge(raw_dri, raw_graph[['account_pit']+fea_graph], on='account_pit', how='left')\n 212 | all_var1.drop(columns=['account_pit'],inplace=True)\n 213 | # ### P1 - merging case level variables - 2 seg (Context,hits_per_case)\n 214 | len(case_var)\n 215 | all_var2 = reduce(lambda left,right: pd.merge(left,right,on='tid',how='left'), [all_var1]+[i for i in case_var.values()]\n 216 |                  )\n 217 | # ### P2 - merging alert level variables - 1 seg (Gib)\n 218 | len(alert_var)\n 219 | all_var3 = reduce(lambda left,right: pd.merge(left,right,on=['tid','alert_cust_id'],how='left')\n 220 |                   , [all_var2]+ [i for i in alert_var.values()]\n 221 |                  )\n 222 | # ### P3 - merging hit level variables - 11 seg (Lokale,match,dobmatch,basicmatch,meta,latin,bert,location1 & 2 & 3, if_primary)\n 223 | len(hit_var)\n 224 | all_var4 = reduce(lambda left,right: pd.merge(left,right,on=['tid','alert_cust_id','entity_id'],how='left')\n 225 |                   , [all_var3]+ [i for i in hit_var.values()]\n 226 |                  )\n 227 | # ## P4 - merging mannually - 1 seg (AttackDoc)\n 228 | all_var5 = reduce(lambda left,right: pd.merge(left,right,on=['alert_cust_id','entity_id'],how='left')\n 229 |                   , [all_var4]\n 230 |                   +[data_dict['attack'][1]]\n 231 |                  )\n 232 | # ## Fixing categoricals and numericals\n 233 | # ### Removing duplicated variables\n 234 | dup_x_col = [i for i in all_var5.columns if i.endswith('_x')]\n 235 | dup_y_col = [i for i in all_var5.columns if i.endswith('_y')]\n 236 | dup_z_col = [i for i in all_var5.columns if i.endswith('_z')]\n 237 | dup_x_col\n 238 | dup_y_col\n 239 | dup_z_col\n 240 | [i[:-2] for i in dup_x_col]\n 241 | [i[:-2] in all_var5.columns for i in dup_x_col]\n 242 | all_var5.shape\n 243 | all_var5.drop(columns=['entity_type_x'],inplace=True)\n 244 | all_var5.drop(columns=['entity_type_y'],inplace=True)\n 245 | all_var5.shape\n 246 | all_var5.shape\n 247 | all_var5.drop(columns=['entity_type_name_x'],inplace=True)\n 248 | all_var5.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n 249 | all_var5.shape\n 250 | # ## Saving to pk\n 251 | with open('./PEP_PS/dataset/clean_all_var_v10.pk','wb') as f:\n 252 |     pickle.dump(all_var5,f,protocol=4)\n 253 | # ## Star auditing\n 254 | all_var5 = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.pk')\n 255 | all_var5['time_created'].max()\n 256 | # for PS\n 257 | for dis in [1001]:\n 258 |     star_before = all_var5.loc[(all_var5['discipline_id']==dis) \n 259 |                                      & (all_var5['time_created']>='2021-08-01')\n 260 |                                      & (all_var5['time_created']<='2022-03-31'),:].sample(10000)\n 261 |     star_after = all_var5.loc[(all_var5['discipline_id']==dis) & (all_var5['time_created']>='2022-04-01'),:].sample(10000)\n 262 |     star_before.shape\n 263 |     star_after.shape\n 264 |     _path = './PEP_PS/STAR/'\n 265 |     _f_bf = 'all_var_clean_bf_'+str(dis)+'_aug21_v10.csv'\n 266 |     _f_af = 'all_var_clean_af_'+str(dis)+'_aug21_v10.csv'\n 267 |     star_before.to_csv(_path+_f_bf,sep='\\u0007',index=False)\n 268 |     star_after.to_csv(_path+_f_af,sep='\\u0007',index=False)\n 269 |     hdfs_h.put(_path+_f_bf,'/user/chaoychen/pep_ps/'+_f_bf)\n 270 |     hdfs_h.put(_path+_f_af,'/user/chaoychen/pep_ps/'+_f_af)\n 271 | # for PEP\n 272 | for dis in [1002]:\n 273 |     star_before = all_var5.loc[(all_var5['discipline_id']==dis) \n 274 |                                      & (all_var5['time_created']>='2022-02-01')\n 275 |                                      & (all_var5['time_created']<='2022-04-31'),:].sample(10000)\n 276 |     star_after = all_var5.loc[(all_var5['discipline_id']==dis) & (all_var5['time_created']>='2022-05-01'),:].sample(10000)\n 277 |     star_before.shape\n 278 |     star_after.shape\n 279 |     _path = './PEP_PS/STAR/'\n 280 |     _f_bf = 'all_var_clean_bf_'+str(dis)+'_Feb22_v10.csv'\n 281 |     _f_af = 'all_var_clean_af_'+str(dis)+'_Feb22_v10.csv'\n 282 |     star_before.to_csv(_path+_f_bf,sep='\\u0007',index=False)\n 283 |     star_after.to_csv(_path+_f_af,sep='\\u0007',index=False)\n 284 |     hdfs_h.put(_path+_f_bf,'/user/chaoychen/pep_ps/'+_f_bf)\n 285 |     hdfs_h.put(_path+_f_af,'/user/chaoychen/pep_ps/'+_f_af)",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/02-modeling_pep.py": "   1 | # %hive_horton\n   2 | from hdfs3 import HDFileSystem\n   3 | hdfs = HDFileSystem(host='horton')\n   4 | import pandas as pd\n   5 | import numpy as np\n   6 | import torch\n   7 | import torch.nn as nn\n   8 | from tqdm import tqdm\n   9 | from sklearn.model_selection import train_test_split\n  10 | import warnings \n  11 | warnings.filterwarnings('ignore')\n  12 | import pickle\n  13 | import optuna\n  14 | import os\n  15 | from IPython.core.interactiveshell import InteractiveShell\n  16 | InteractiveShell.ast_node_interactivity = \"all\"\n  17 | pd.set_option('display.max_columns', 500)\n  18 | from sklearn.preprocessing import LabelEncoder\n  19 | from tqdm import tqdm\n  20 | # !nvidia-smi\n  21 | # %load_ext autoreload\n  22 | # %autoreload 2\n  23 | from common.multi import MultiLabelModel, MultiLabelDs\n  24 | from datetime import datetime\n  25 | # ## 1 - Reading dataset\n  26 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.1.pk')\n  27 | all_dataset=all_dataset.loc[(all_dataset['discipline_id']==1002) & (all_dataset['time_created']>'2022-02-15 23:59:59'),:]\n  28 | dup_x_col = [i for i in all_dataset.columns if i.endswith('_x')]\n  29 | dup_y_col = [i for i in all_dataset.columns if i.endswith('_y')]\n  30 | dup_z_col = [i for i in all_dataset.columns if i.endswith('_z')]\n  31 | dup_x_col\n  32 | dup_y_col\n  33 | dup_z_col\n  34 | [i[:-2] for i in dup_x_col]\n  35 | [i[:-2] in all_dataset.columns for i in dup_x_col]\n  36 | all_dataset.shape\n  37 | # ## 2 - Define dataset\n  38 | all_dataset.columns[:17]\n  39 | all_dataset.columns[17:]\n  40 | meta_col = ['tid', 'entity_reference_id', 'time_created',\n  41 |        'new_logic_label','new_logic_label_v2', 'customer_id', 'alert_cust_id', 'ps_decision',\n  42 |        'ps_decision_reason', 'tag',\n  43 |        'entity_id', 'entity_uid', 'label_with_autorfi', 'pit_context', 'txn_grph_linked_account_list']\n  44 | all_var = [i for i in all_dataset.columns if not i in meta_col]\n  45 | tag = 'new_logic_label'\n  46 | num_col = [i for i in all_var if not any([i in cat_col])]\n  47 | rev_cat = ['case_identifier','s_nm','s_first_nm','s_middle_nm','s_last_nm','s_bus_nm','s_trade_nm','dt','scenario_name',\n  48 |           'seg_reason','s_cntry','customer_dob_available']\n  49 | cat_col = [i for i in cat_col if not i in rev_cat]\n  50 | num_col = [i for i in num_col if not i in rev_cat]\n  51 | ## Define cat_2_num\n  52 | cat_2_num = ['length_s_trade_nm','s_gibscore_name','s_cust_name_profanity','s_busn_name_profanity','s_trade_name_profanity']\n  53 | for cat in cat_2_num:\n  54 |     if cat in cat_col:\n  55 |         cat_col.remove(cat)\n  56 |     if cat not in num_col:\n  57 |         num_col.append(cat)\n  58 |         all_dataset[cat] = all_dataset[cat].astype('float64')\n  59 | cat_col = list(set(cat_col))\n  60 | num_col = list(set(num_col))\n  61 | for cat in cat_col:\n  62 |     all_dataset[cat] = all_dataset[cat].astype('string')\n  63 |     all_dataset[cat] = all_dataset[cat].astype('O')\n  64 | all_dataset[tag].value_counts(normalize=True)\n  65 | all_dataset.time_created.agg({'min','max'})\n  66 | all_dataset.loc[all_dataset['discipline_id']=='1001','time_created'].agg({'min','max'})\n  67 | all_dataset.loc[all_dataset['discipline_id']=='1002','time_created'].agg({'min','max'})\n  68 | all_dataset.discipline_id.value_counts()\n  69 | def high_missing(df):\n  70 |     percent_missing = df.isnull().sum() * 100 / len(df)\n  71 |     missing_value_df = pd.DataFrame({'column_name': df.columns,\n  72 |                                      'percent_missing': percent_missing})\n  73 |     missing_value_df.sort_values('percent_missing', inplace=True)\n  74 |     high_missing_cols = missing_value_df[missing_value_df['percent_missing']>98].index.tolist()\n  75 |     high_missing_cols\n  76 |     return high_missing_cols\n  77 | def zero_std(df):\n  78 |     num_std = df.std()\n  79 |     zero_std_col = pd.DataFrame(num_std).loc[pd.DataFrame(num_std)[0]==0].index.to_list()\n  80 |     df[all_cat] = df[all_cat].fillna('unknown')\n  81 |     cat_cardinal = df[all_cat].nunique()\n  82 |     single_cardinal_col = pd.DataFrame(cat_cardinal).loc[pd.DataFrame(cat_cardinal)[0]<=1].index.to_list()\n  83 |     all_zero_std = zero_std_col + single_cardinal_col\n  84 |     return all_zero_std\n  85 | def cleaning_col(df):\n  86 |     all_col = df.columns.to_list()\n  87 |     high_missing_cols = high_missing(df)\n  88 |     zero_std_cols = zero_std(df)\n  89 |     return high_missing_cols, zero_std_cols\n  90 | high_missing_cols, zero_std_cols = cleaning_col(all_dataset)\n  91 | cat_col = [i for i in cat_col if not any([i in high_missing_cols, i in zero_std_cols])]\n  92 | num_col = [i for i in num_col if not any([i in high_missing_cols, i in zero_std_cols])]\n  93 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-02-15 23:59:59']\n  94 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n  95 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n  96 | dev_ds.time_created.agg({'min','max'})\n  97 | dev_ds.shape\n  98 | dev_ds.discipline_id.value_counts()\n  99 | oot_ds.time_created.agg({'min','max'})\n 100 | oot_ds.shape\n 101 | oot_ds.discipline_id.value_counts()\n 102 | # STAR\n 103 | ps_star_aug21 = pd.read_csv('./PEP_PS/STAR/pepps_PEP_V10.1.csv',sep=',')\n 104 | meta_col = ['tid','pit_context','entity_reference_id','entity_id','alert_cust_id','discipline_id','customer_id']\n 105 | shift_col_ps2 = ps_star_aug21.loc[(ps_star_aug21['PSI Base']>0.1) \n 106 |                            & (~ps_star_aug21['Variable Name Base'].isin(meta_col)),:].drop(columns=['Variable Name Chall','Count Chall','PSI Chall'])\n 107 | shift_col_ps2.sort_values(by='PSI Base',ascending=False, inplace=True)\n 108 | shift_all = list(set(shift_col_ps2['Variable Name Base'].tolist()))\n 109 | cat_col = [i for i in cat_col if not i in shift_all]\n 110 | num_col = [i for i in num_col if not i in shift_all]\n 111 | # Remove DOB match variables\n 112 | # If in DOB variables cannot be used in future, execute below code to remove them\n 113 | #dob_var = ['itself_dob_available_sum','linked_dob_available_sum','dob_match_sum','linked_dob_match_sum','year_match_sum','linked_year_match_sum'\n 114 | #           ,'itself_dob_diff_min','itself_dob_diff_max','itself_dob_diff_mean','linked_dob_diff_min','linked_dob_diff_max','linked_dob_diff_mean'\n 115 | #           ,'itself_year_diff_min','itself_year_diff_max','itself_year_diff_mean','linked_year_diff_min','linked_year_diff_max','linked_year_diff_mean']\n 116 | #print('Total {} DOB vars'.format(len(dob_var)))\n 117 | #print('Total {} num before, {} cat before'.format(len(num_col), len(cat_col)))\n 118 | #cat_col = [i for i in cat_col if not i in dob_var]\n 119 | #num_col = [i for i in num_col if not i in dob_var]\n 120 | len(cat_col) == len(set(cat_col))\n 121 | len(num_col) == len(set(num_col))\n 122 | len(cat_col+num_col) == len(set(cat_col+num_col))\n 123 | [i for i in cat_col if 'dob' in i]\n 124 | [i for i in num_col if 'dob' in i]\n 125 | with open(\"./PEP_PS/model_w25/col_names_25.5_pep.pk\", \"wb\") as f:\n 126 |     pickle.dump((cat_col, num_col), f, protocol=4)\n 127 | # Redefine tagging to multi-label\n 128 | # 'Auto-Dis', 'RFI', 'Man-Dis', 'Man-Esca', 'Confirmed PS','Confirmed PEP'\n 129 | dev_ds['tag_esc'] = np.where(dev_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 130 | dev_ds['tag_rfi'] = np.where(dev_ds[tag].isin(['RFI']),1,0)\n 131 | dev_ds['tag_em'] = np.where(dev_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 132 | oot_ds['tag_esc'] = np.where(oot_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 133 | oot_ds['tag_rfi'] = np.where(oot_ds[tag].isin(['RFI']),1,0)\n 134 | oot_ds['tag_em'] = np.where(oot_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 135 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n 136 | # ## 3 - Imputation\n 137 | dev_ds[cat_col] = dev_ds[cat_col].fillna('unknown')\n 138 | dev_ds[num_col] = dev_ds[num_col].fillna(-999)\n 139 | # ## 4 - Build encoding dict, normalize numericals\n 140 | enc_dic = {}\n 141 | for cat in cat_col:\n 142 |     encoder = LabelEncoder()\n 143 |     encoder.fit(dev_ds[cat].tolist()+['UNSEEN'])\n 144 |     enc_dic[cat] = encoder\n 145 | with open('./PEP_PS/model_w25/enc_dic_splitcase_25.5_pep.pk','wb') as f:\n 146 |     pickle.dump(enc_dic,f)\n 147 | def process_categories(dataset):\n 148 |     datset = dataset.copy()\n 149 |     categorical_embedding_sizes = []\n 150 |     for category in tqdm(cat_col):\n 151 |     #for category in tqdm(['discipline_id']):\n 152 |         _tmp = np.where(datset[category].isin(enc_dic[category].classes_),datset[category],'UNSEEN')\n 153 |         datset[category] = enc_dic[category].transform(_tmp)\n 154 |         #return datset[category]\n 155 |         #index offset and -1 column for NaN\n 156 |         col_size = len(enc_dic[category].classes_)\n 157 |         #if -1 not in datset[category].cat.codes.values:\n 158 |         categorical_embedding_sizes.append((col_size, min(20, (col_size+1)//2)))\n 159 |     return categorical_embedding_sizes, datset\n 160 | categorical_embedding_sizes, dev_processed = process_categories(dev_ds)\n 161 | dev_mean = dev_processed[num_col].mean()\n 162 | dev_std = dev_processed[num_col].std()\n 163 | dev_processed[num_col] = (dev_processed[num_col] - dev_mean)/dev_std\n 164 | with open(\"./PEP_PS/model_w25/num_mean_std_splitcase_25.5_pep.pk\", \"wb\") as f:\n 165 |     pickle.dump((dev_mean, dev_std), f, protocol=4)\n 166 | with open(\"./PEP_PS/model_w25/categorical_embedding_sizes_splitcase_25.5_pep.pk\", \"wb\") as f:\n 167 |     pickle.dump(categorical_embedding_sizes, f, protocol=4)\n 168 | dev_ds['discipline_id'].value_counts()\n 169 | dev_processed['discipline_id'].value_counts()\n 170 | # ## 5 - Dataset split - For Dev DS\n 171 | dev_processed.reset_index(inplace=True,drop=True)\n 172 | ## Remove Auto-Dis\n 173 | dev_processed.shape\n 174 | dev_processed2 = dev_processed.loc[dev_processed[tag]!='Auto-Dis',:]\n 175 | dev_processed2.shape\n 176 | dev_processed2[tag].value_counts()\n 177 | dev_processed2[tag_mt].value_counts()\n 178 | dev_processed2.set_index('tid',inplace=True)\n 179 | train_idx, test_idx = train_test_split(dev_processed2.index.unique(), test_size=0.2, random_state=42)\n 180 | train_ds = dev_processed2.loc[train_idx]\n 181 | test_ds = dev_processed2.loc[test_idx]\n 182 | with open(\"./PEP_PS/model_w25/dev_splitcase_25.5_pep.pk\", \"wb\") as f:\n 183 |     pickle.dump((train_ds.index.unique(), test_ds.index.unique()), f, protocol=4)\n 184 | len(train_ds)\n 185 | len(test_ds)\n 186 | len(train_ds)/len(test_ds)\n 187 | train_ds.time_created.agg(['min','max'])\n 188 | test_ds.time_created.agg(['min','max'])\n 189 | # use weight in sampler, the weight will be used in loss calculation\n 190 | train_ds_buddle = MultiLabelDs(train_ds, cat_col, num_col, tag_mt)\n 191 | test_ds_buddle = MultiLabelDs(test_ds, cat_col, num_col, tag_mt)\n 192 | # ## 6 - Modeling\n 193 | def model_train(params,trial):\n 194 |     l_r = params['lr']\n 195 |     w_d = params['wd']\n 196 |     dropout = params['dp']\n 197 |     n_unit = params['nu']\n 198 |     n_layer = params['n_layer']\n 199 |     b_size = params['batchsize']\n 200 |     epochs = params['epoch']\n 201 |     model_path = params['path']\n 202 |     _layer=[n_unit]\n 203 |     model_tag=params['tag']\n 204 |     last_out = n_unit//2\n 205 |     for i in range(n_layer-1):\n 206 |         _layer.append(last_out)\n 207 |         last_out//=2\n 208 |     if not os.path.isdir(model_path):\n 209 |         os.mkdir(model_path)\n 210 |     early_stop_tol=20\n 211 |     #print('a')\n 212 |     train_loader = torch.utils.data.DataLoader(train_ds_buddle,\n 213 |                                               batch_size=b_size,\n 214 |                                               num_workers = 0,\n 215 |                                            #sampler=weighted_sampler_train,\n 216 |                                               shuffle=True\n 217 |                                           )\n 218 |     val_loader = torch.utils.data.DataLoader(test_ds_buddle,\n 219 |                                                   batch_size=b_size,\n 220 |                                                   num_workers = 0,\n 221 |                                              #sampler=weighted_sampler_val,\n 222 |                                                   shuffle=True\n 223 |                                             )\n 224 |     #print('b')\n 225 |     def multi_acc(y_pred, y_test):\n 226 |         y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n 227 |         _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n 228 |         correct_pred = (y_pred_tags == y_test).float()\n 229 |         acc = correct_pred.sum() / len(correct_pred)\n 230 |         #acc = torch.round(acc * 100)\n 231 |         return acc*100.00\n 232 |     model = MultiLabelModel(np.array(categorical_embedding_sizes), len(num_col), 2, 2, 2, _layer, p=dropout)\n 233 |     device = 'cuda'\n 234 |     model = model.to(device)\n 235 |     torch.cuda.empty_cache()\n 236 |     #print('c')\n 237 |     tag_loss_function = nn.CrossEntropyLoss(reduction='none')\n 238 |     def criterion(loss_func,outputs,labels, weights, _type):\n 239 |         losses = 0\n 240 |         acc_ls = []\n 241 |         for i, key in enumerate(outputs):\n 242 |             if _type == 'val':\n 243 |                 losses += loss_func(outputs[key], labels[f'label_'+key].to(device)).mean()\n 244 |             elif _type == 'train':\n 245 |                 unweight_losses = loss_func(outputs[key], labels[f'label_'+key].to(device))\n 246 |                 weight_losses = (unweight_losses * weights[f'weight_'+key].to(device)).mean()\n 247 |                 losses += weight_losses\n 248 |             accuracy = multi_acc(outputs[key],labels[f'label_'+key].to(device))\n 249 |             acc_ls.append(accuracy)\n 250 |         return losses, acc_ls\n 251 |     #print('d')\n 252 |     optimizer = torch.optim.Adam(model.parameters(), lr=l_r, weight_decay = w_d)\n 253 |     #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 6, gamma=0.3)\n 254 |     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2,patience=2, mode = 'min')\n 255 |     current_time = datetime.now().strftime(\"%Y%m%d_%H_%M\")\n 256 |     earlystop_cnt = 0\n 257 |     aggregated_losses = []\n 258 |     aggregated_losses_val= []\n 259 |     aggregated_acc = []\n 260 |     aggregated_acc_val= []\n 261 |     best_loss = None\n 262 |     for i in tqdm(range(epochs)):\n 263 |         step_loss = []\n 264 |         step_accuracy = []\n 265 |         model.train()\n 266 |         #print('-'*10)\n 267 |         #print('start of epoch:', i)\n 268 |         k=0\n 269 |         for dat in train_loader:\n 270 |             catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n 271 |             multi_outs = model(catdata.to(device), numdata.to(device))\n 272 |             single_loss, accuracy_ls = criterion(tag_loss_function, multi_outs, labels, weights, 'train')\n 273 |             optimizer.zero_grad()\n 274 |             single_loss.backward()\n 275 |             optimizer.step()\n 276 |             step_loss.append(single_loss.item())\n 277 |             step_accuracy.append(accuracy_ls)\n 278 |         aggregated_losses.append(np.mean(step_loss))\n 279 |         aggregated_acc.append(np.mean(step_accuracy,axis=0))\n 280 |         with torch.no_grad():\n 281 |             model.eval()\n 282 |             step_loss_val = []\n 283 |             step_accuracy_val = []\n 284 |             for dat in val_loader:\n 285 |                 catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n 286 |                 multi_outs = model(catdata.to(device), numdata.to(device))\n 287 |                 single_loss, accuracy_ls = criterion(tag_loss_function, multi_outs, labels, weights, 'val')\n 288 |                 step_loss_val.append(single_loss.item())\n 289 |                 step_accuracy_val.append(accuracy_ls)\n 290 |             aggregated_losses_val.append(np.mean(step_loss_val))\n 291 |             aggregated_acc_val.append(np.mean(step_accuracy_val,axis=0))\n 292 |             if (len(aggregated_losses_val)>1):\n 293 |                 if aggregated_losses_val[-1]>best_loss:\n 294 |                     earlystop_cnt+=1\n 295 |                 else:\n 296 |                     earlystop_cnt=0\n 297 |             if earlystop_cnt>=early_stop_tol:\n 298 |                 return best_loss\n 299 |             scheduler.step(np.mean(step_loss_val))\n 300 |             if not best_loss or np.mean(step_loss_val) < best_loss:\n 301 |                 best_loss = np.mean(step_loss_val)\n 302 |                 #torch.save(model, f'./models/best_binary_{model_tag}.pt')\n 303 |                 _path = model_path+'{}_{}.bin'.format(model_tag, current_time)\n 304 |                 torch.save(model.state_dict(), _path)\n 305 |         trial.report(best_loss, i)\n 306 |         if trial.should_prune():\n 307 |             raise optuna.exceptions.TrialPruned()\n 308 |         #print('d')\n 309 |         if i%20 == 0:\n 310 |         #if False:\n 311 |             acc_esc, acc_rfi, acc_em = np.mean(step_accuracy, axis=0)\n 312 |             acc_esc, acc_rfi, acc_em = np.mean(step_accuracy_val, axis=0)\n 313 |     return best_loss\n 314 | def objective(trial):\n 315 |     params = {\n 316 |         'lr': trial.suggest_loguniform('lr', 1e-4, 1e-2)\n 317 |         ,'wd':trial.suggest_loguniform('wd',1e-5, 1e-2)\n 318 |         ,'dp': trial.suggest_float('dp',1e-1, 5e-1)\n 319 |         #'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n 320 |         ,'nu': trial.suggest_int('nu', 40, 120)\n 321 |         ,'batchsize': trial.suggest_int('batchsize', 50, 500)\n 322 |         ,'n_layer': trial.suggest_int('n_layer', 2, 4)\n 323 |         ,'epoch': 100\n 324 |         ,'path':'./PEP_PS/model_w25/hptuning/'\n 325 |         ,'tag':'25.5_pepht'\n 326 |               }\n 327 |     best_loss = model_train(params, trial)\n 328 |     with open('/home/chaoychen/PEP_PS/model_w25/hptuning/study_log.txt','a') as f:\n 329 |         _=f.write('trial: {} start time: {}\\n'.format(trial.number,trial.datetime_start))\n 330 |         for i,j in params.items():\n 331 |             _=f.write(i+':'+str(j)+' ')\n 332 |         _=f.write('loss: {}\\n'.format(best_loss))\n 333 |         _=f.write('='*20)\n 334 |         _=f.write('\\n')\n 335 |     return best_loss\n 336 | class StopWhenTrialKeepBeingPrunedCallback:\n 337 |     def __init__(self, threshold: int):\n 338 |         self.threshold = threshold\n 339 |         self._consequtive_pruned_count = 0\n 340 |     def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n 341 |         if trial.state == optuna.trial.TrialState.PRUNED:\n 342 |             self._consequtive_pruned_count += 1\n 343 |         else:\n 344 |             self._consequtive_pruned_count = 0\n 345 |         if self._consequtive_pruned_count >= self.threshold:\n 346 |             study.stop()\n 347 | class SaveStudy:\n 348 |     def __init__(self,studyname):\n 349 |         self.studyname = studyname\n 350 |     def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n 351 |         with open('/home/chaoychen/PEP_PS/model_w25/hptuning/{}.pk'.format(self.studyname),'wb') as f:\n 352 |             pickle.dump(study,f)\n 353 | current_time = datetime.now().strftime(\"%Y%m%d_%H_%M\")\n 354 | studyname = 'optuna_study_'+current_time\n 355 | optuna.logging.set_verbosity(optuna.logging.WARNING)\n 356 | study = optuna.create_study(direction=\"minimize\"\n 357 |                             , sampler=optuna.samplers.TPESampler()\n 358 |                             #, pruner=optuna.pruners.SuccessiveHalvingPruner()\n 359 |                             , pruner=optuna.pruners.PercentilePruner(25.0, n_startup_trials=5, n_warmup_steps=30, interval_steps=5, n_min_trials=10)\n 360 |                            , study_name=studyname)\n 361 | study.optimize(objective, n_trials=30, callbacks = [StopWhenTrialKeepBeingPrunedCallback(5),\n 362 |                                                    SaveStudy(studyname)\n 363 |                                                    ])\n 364 | with open('/home/chaoychen/PEP_PS/model_w25/hptuning/{}.pk'.format(studyname),'wb') as f:\n 365 |     pickle.dump(study,f)",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/03-modeling_ps.py": "   1 | # %hive_horton\n   2 | from hdfs3 import HDFileSystem\n   3 | hdfs = HDFileSystem(host='horton')\n   4 | import pandas as pd\n   5 | import numpy as np\n   6 | import torch\n   7 | import torch.nn as nn\n   8 | from tqdm import tqdm\n   9 | from sklearn.model_selection import train_test_split\n  10 | import warnings \n  11 | warnings.filterwarnings('ignore')\n  12 | import pickle\n  13 | import os\n  14 | from IPython.core.interactiveshell import InteractiveShell\n  15 | InteractiveShell.ast_node_interactivity = \"all\"\n  16 | pd.set_option('display.max_columns', 500)\n  17 | from sklearn.preprocessing import LabelEncoder\n  18 | from tqdm import tqdm\n  19 | # !nvidia-smi\n  20 | # %load_ext autoreload\n  21 | # %autoreload 2\n  22 | from common.multi import MultiLabelModel, MultiLabelDs\n  23 | from datetime import datetime\n  24 | # ## 1 - Reading dataset\n  25 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.pk')\n  26 | all_dataset=all_dataset.loc[(all_dataset['discipline_id']==1001) & (all_dataset['time_created']>'2021-07-31 23:59:59'),:]\n  27 | # Remove auto-rfi from dataset\n  28 | auto_rfi_caseid = all_dataset.loc[all_dataset['new_logic_label_v2']=='Auto-RFI','tid'].unique()\n  29 | all_dataset.shape\n  30 | all_dataset = all_dataset.loc[~all_dataset['tid'].isin(auto_rfi_caseid),:]\n  31 | all_dataset.shape\n  32 | path = '/apps/risk/qpull/out/chaoychen_1660156696_tdmovetpt_fexp.csv'\n  33 | sep='\\x07'\n  34 | with hdfs.open(path) as f:\n  35 |     ds_final_state = pd.read_csv(f,sep=sep).drop_duplicates()\n  36 | ds_final_state.columns = ds_final_state.columns.str.lower()\n  37 | ## Those RFI then dismiss population need to be cleaned\n  38 | ds_final_state=ds_final_state.loc[(ds_final_state['new_logic_label']=='RFI') & (ds_final_state['final_step_label']=='Man-Dis'),:]\n  39 | ds_final_state.shape\n  40 | # exclude RFI-dismiss in all dataset\n  41 | # clean dataset when decision changed from RFI to dismiss\n  42 | all_dataset['new_logic_label'].value_counts()\n  43 | all_dataset = all_dataset.loc[~all_dataset['tid'].isin(ds_final_state['tid']),:]\n  44 | all_dataset['new_logic_label'].value_counts()\n  45 | dup_x_col = [i for i in all_dataset.columns if i.endswith('_x')]\n  46 | dup_y_col = [i for i in all_dataset.columns if i.endswith('_y')]\n  47 | dup_z_col = [i for i in all_dataset.columns if i.endswith('_z')]\n  48 | dup_x_col\n  49 | dup_y_col\n  50 | dup_z_col\n  51 | [i[:-2] for i in dup_x_col]\n  52 | [i[:-2] in all_dataset.columns for i in dup_x_col]\n  53 | all_dataset.shape\n  54 | all_dataset['new_logic_label'].unique()\n  55 | # ## 2 - Define dataset\n  56 | all_dataset.columns[:17]\n  57 | all_dataset.columns[17:]\n  58 | meta_col = ['tid', 'entity_reference_id', 'time_created',\n  59 |        'new_logic_label','new_logic_label_v2', 'customer_id', 'alert_cust_id', 'ps_decision',\n  60 |        'ps_decision_reason', 'tag',\n  61 |        'entity_id', 'entity_uid', 'label_with_autorfi', 'pit_context', 'txn_grph_linked_account_list']\n  62 | all_var = [i for i in all_dataset.columns if not i in meta_col]\n  63 | tag = 'new_logic_label'\n  64 | num_col = [i for i in all_var if not any([i in cat_col])]\n  65 | rev_cat = ['case_identifier','s_nm','s_first_nm','s_middle_nm','s_last_nm','s_bus_nm','s_trade_nm','dt','scenario_name',\n  66 |           'seg_reason','s_cntry','customer_dob_available']\n  67 | cat_col = [i for i in cat_col if not i in rev_cat]\n  68 | num_col = [i for i in num_col if not i in rev_cat]\n  69 | ## Data issue - two rows have bad file reading\n  70 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n  71 | ## Define cat_2_num\n  72 | cat_2_num = ['length_s_trade_nm','s_gibscore_name','s_cust_name_profanity','s_busn_name_profanity','s_trade_name_profanity']\n  73 | for cat in cat_2_num:\n  74 |     if cat in cat_col:\n  75 |         cat_col.remove(cat)\n  76 |     if cat not in num_col:\n  77 |         num_col.append(cat)\n  78 |         all_dataset[cat] = all_dataset[cat].astype('float64')\n  79 | cat_col = list(set(cat_col))\n  80 | num_col = list(set(num_col))\n  81 | for cat in cat_col:\n  82 |     all_dataset[cat] = all_dataset[cat].astype('string')\n  83 |     all_dataset[cat] = all_dataset[cat].astype('O')\n  84 | all_dataset[tag].value_counts(normalize=True)\n  85 | all_dataset.time_created.agg({'min','max'})\n  86 | all_dataset.loc[all_dataset['discipline_id']=='1001','time_created'].agg({'min','max'})\n  87 | all_dataset.loc[all_dataset['discipline_id']=='1002','time_created'].agg({'min','max'})\n  88 | all_dataset.discipline_id.value_counts()\n  89 | def high_missing(df):\n  90 |     percent_missing = df.isnull().sum() * 100 / len(df)\n  91 |     missing_value_df = pd.DataFrame({'column_name': df.columns,\n  92 |                                      'percent_missing': percent_missing})\n  93 |     missing_value_df.sort_values('percent_missing', inplace=True)\n  94 |     high_missing_cols = missing_value_df[missing_value_df['percent_missing']>98].index.tolist()\n  95 |     high_missing_cols\n  96 |     return high_missing_cols\n  97 | def zero_std(df):\n  98 |     num_std = df.std()\n  99 |     zero_std_col = pd.DataFrame(num_std).loc[pd.DataFrame(num_std)[0]==0].index.to_list()\n 100 |     df[all_cat] = df[all_cat].fillna('unknown')\n 101 |     cat_cardinal = df[all_cat].nunique()\n 102 |     single_cardinal_col = pd.DataFrame(cat_cardinal).loc[pd.DataFrame(cat_cardinal)[0]<=1].index.to_list()\n 103 |     all_zero_std = zero_std_col + single_cardinal_col\n 104 |     return all_zero_std\n 105 | def cleaning_col(df):\n 106 |     all_col = df.columns.to_list()\n 107 |     high_missing_cols = high_missing(df)\n 108 |     zero_std_cols = zero_std(df)\n 109 |     return high_missing_cols, zero_std_cols\n 110 | high_missing_cols, zero_std_cols = cleaning_col(all_dataset)\n 111 | cat_col = [i for i in cat_col if not any([i in high_missing_cols, i in zero_std_cols])]\n 112 | num_col = [i for i in num_col if not any([i in high_missing_cols, i in zero_std_cols])]\n 113 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2021-07-31 23:59:59']\n 114 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-03-31 23:59:59']\n 115 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-04-01 00:00:00']\n 116 | dev_ds.time_created.agg({'min','max'})\n 117 | dev_ds.shape\n 118 | dev_ds.discipline_id.value_counts()\n 119 | oot_ds.time_created.agg({'min','max'})\n 120 | oot_ds.shape\n 121 | oot_ds.discipline_id.value_counts()\n 122 | # STAR\n 123 | ps_star_aug21 = pd.read_csv('./PEP_PS/STAR/pepps_PS_V9.csv',sep=',')\n 124 | meta_col = ['tid','pit_context','entity_reference_id','entity_id','alert_cust_id','discipline_id','customer_id']\n 125 | shift_col_ps2 = ps_star_aug21.loc[(ps_star_aug21['PSI Base']>0.1) \n 126 |                            & (~ps_star_aug21['Variable Name Base'].isin(meta_col)),:].drop(columns=['Variable Name Chall','Count Chall','PSI Chall'])\n 127 | shift_col_ps2.sort_values(by='PSI Base',ascending=False, inplace=True)\n 128 | shift_all = list(set(shift_col_ps2['Variable Name Base'].tolist()))\n 129 | cat_col = [i for i in cat_col if not i in shift_all]\n 130 | num_col = [i for i in num_col if not i in shift_all]\n 131 | # Remove DOB match variables\n 132 | dob_var = ['itself_dob_available_sum','linked_dob_available_sum','dob_match_sum','linked_dob_match_sum','year_match_sum','linked_year_match_sum'\n 133 |            ,'itself_dob_diff_min','itself_dob_diff_max','itself_dob_diff_mean','linked_dob_diff_min','linked_dob_diff_max','linked_dob_diff_mean'\n 134 |            ,'itself_year_diff_min','itself_year_diff_max','itself_year_diff_mean','linked_year_diff_min','linked_year_diff_max','linked_year_diff_mean']\n 135 | cat_col = [i for i in cat_col if not i in dob_var]\n 136 | num_col = [i for i in num_col if not i in dob_var]\n 137 | len(cat_col) == len(set(cat_col))\n 138 | len(num_col) == len(set(num_col))\n 139 | len(cat_col+num_col) == len(set(cat_col+num_col))\n 140 | with open(\"./PEP_PS/model_w26/col_names_26.2_ps.pk\", \"wb\") as f:\n 141 |     pickle.dump((cat_col, num_col), f, protocol=4)\n 142 | # Redefine tagging to multi-label\n 143 | # 'Auto-Dis', 'RFI', 'Man-Dis', 'Man-Esca', 'Confirmed PS','Confirmed PEP'\n 144 | dev_ds['tag_esc'] = np.where(dev_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 145 | dev_ds['tag_rfi'] = np.where(dev_ds[tag].isin(['RFI']),1,0)\n 146 | dev_ds['tag_em'] = np.where(dev_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 147 | oot_ds['tag_esc'] = np.where(oot_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 148 | oot_ds['tag_rfi'] = np.where(oot_ds[tag].isin(['RFI']),1,0)\n 149 | oot_ds['tag_em'] = np.where(oot_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 150 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n 151 | # ## 3 - Imputation\n 152 | dev_ds[cat_col] = dev_ds[cat_col].fillna('unknown')\n 153 | dev_ds[num_col] = dev_ds[num_col].fillna(-999)\n 154 | # ## 4 - Build encoding dict, normalize numericals\n 155 | enc_dic = {}\n 156 | for cat in cat_col:\n 157 |     encoder = LabelEncoder()\n 158 |     encoder.fit(dev_ds[cat].tolist()+['UNSEEN'])\n 159 |     enc_dic[cat] = encoder\n 160 | with open('./PEP_PS/model_w26/enc_dic_splitcase_26.2_ps.pk','wb') as f:\n 161 |     pickle.dump(enc_dic,f)\n 162 | def process_categories(dataset):\n 163 |     datset = dataset.copy()\n 164 |     categorical_embedding_sizes = []\n 165 |     for category in tqdm(cat_col):\n 166 |     #for category in tqdm(['discipline_id']):\n 167 |         _tmp = np.where(datset[category].isin(enc_dic[category].classes_),datset[category],'UNSEEN')\n 168 |         datset[category] = enc_dic[category].transform(_tmp)\n 169 |         #return datset[category]\n 170 |         #index offset and -1 column for NaN\n 171 |         col_size = len(enc_dic[category].classes_)\n 172 |         #if -1 not in datset[category].cat.codes.values:\n 173 |         categorical_embedding_sizes.append((col_size, min(20, (col_size+1)//2)))\n 174 |     return categorical_embedding_sizes, datset\n 175 | categorical_embedding_sizes, dev_processed = process_categories(dev_ds)\n 176 | dev_mean = dev_processed[num_col].mean()\n 177 | dev_std = dev_processed[num_col].std()\n 178 | dev_processed[num_col] = (dev_processed[num_col] - dev_mean)/dev_std\n 179 | with open(\"./PEP_PS/model_w26/num_mean_std_splitcase_26.2_ps.pk\", \"wb\") as f:\n 180 |     pickle.dump((dev_mean, dev_std), f, protocol=4)\n 181 | with open(\"./PEP_PS/model_w26/categorical_embedding_sizes_splitcase_26.2_ps.pk\", \"wb\") as f:\n 182 |     pickle.dump(categorical_embedding_sizes, f, protocol=4)\n 183 | dev_ds['discipline_id'].value_counts()\n 184 | dev_processed['discipline_id'].value_counts()\n 185 | # ## 5 - Dataset split - For Dev DS\n 186 | dev_processed.reset_index(inplace=True,drop=True)\n 187 | ## Remove Auto-Dis\n 188 | dev_processed.shape\n 189 | dev_processed2 = dev_processed.loc[dev_processed[tag]!='Auto-Dis',:]\n 190 | dev_processed2.shape\n 191 | dev_processed2[tag].value_counts()\n 192 | dev_processed2[tag_mt].value_counts()\n 193 | dev_processed2.set_index('tid',inplace=True)\n 194 | train_idx, test_idx = train_test_split(dev_processed2.index.unique(), test_size=0.2, random_state=42)\n 195 | train_ds = dev_processed2.loc[train_idx]\n 196 | test_ds = dev_processed2.loc[test_idx]\n 197 | with open(\"./PEP_PS/model_w26/dev_splitcase_26.2_ps.pk\", \"wb\") as f:\n 198 |     pickle.dump((train_ds.index.unique(), test_ds.index.unique()), f, protocol=4)\n 199 | len(train_ds)\n 200 | len(test_ds)\n 201 | len(train_ds)/len(test_ds)\n 202 | # use weight in sampler, the weight will be used in loss calculation\n 203 | train_ds_buddle = MultiLabelDs(train_ds, cat_col, num_col, tag_mt)\n 204 | test_ds_buddle = MultiLabelDs(test_ds, cat_col, num_col, tag_mt)\n 205 | # ## 6 - Modeling\n 206 | def model_train(params):\n 207 |     l_r = params['lr']\n 208 |     w_d = params['wd']\n 209 |     dropout = params['dp']\n 210 |     n_unit = params['nu']\n 211 |     n_layer = params['n_layer']\n 212 |     b_size = params['batchsize']\n 213 |     epochs = params['epoch']\n 214 |     model_path = params['path']\n 215 |     _layer=[n_unit]\n 216 |     model_tag=params['tag']\n 217 |     last_out = n_unit//2\n 218 |     for i in range(n_layer-1):\n 219 |         _layer.append(last_out)\n 220 |         last_out//=2\n 221 |     if not os.path.isdir(model_path):\n 222 |         os.mkdir(model_path)\n 223 |     early_stop_tol=10\n 224 |     #print('a')\n 225 |     train_loader = torch.utils.data.DataLoader(train_ds_buddle,\n 226 |                                               batch_size=b_size,\n 227 |                                               num_workers = 0,\n 228 |                                            #sampler=weighted_sampler_train,\n 229 |                                               shuffle=True\n 230 |                                           )\n 231 |     val_loader = torch.utils.data.DataLoader(test_ds_buddle,\n 232 |                                                   batch_size=b_size,\n 233 |                                                   num_workers = 0,\n 234 |                                              #sampler=weighted_sampler_val,\n 235 |                                                   shuffle=True\n 236 |                                             )\n 237 |     #print('b')\n 238 |     def multi_acc(y_pred, y_test):\n 239 |         y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n 240 |         _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n 241 |         correct_pred = (y_pred_tags == y_test).float()\n 242 |         acc = correct_pred.sum() / len(correct_pred)\n 243 |         #acc = torch.round(acc * 100)\n 244 |         return acc*100.00\n 245 |     model = MultiLabelModel(np.array(categorical_embedding_sizes), len(num_col), 2, 2, 2, _layer, p=dropout)\n 246 |     device = 'cuda'\n 247 |     model = model.to(device)\n 248 |     torch.cuda.empty_cache()\n 249 |     #print('c')\n 250 |     tag_loss_function = nn.CrossEntropyLoss(reduction='none')\n 251 |     def criterion(loss_func,outputs,labels, weights, _type):\n 252 |         losses = 0\n 253 |         acc_ls = []\n 254 |         for i, key in enumerate(outputs):\n 255 |             if _type == 'val':\n 256 |                 losses += loss_func(outputs[key], labels[f'label_'+key].to(device)).mean()\n 257 |             elif _type == 'train':\n 258 |                 unweight_losses = loss_func(outputs[key], labels[f'label_'+key].to(device))\n 259 |                 weight_losses = (unweight_losses * weights[f'weight_'+key].to(device)).mean()\n 260 |                 losses += weight_losses\n 261 |             accuracy = multi_acc(outputs[key],labels[f'label_'+key].to(device))\n 262 |             acc_ls.append(accuracy)\n 263 |         return losses, acc_ls\n 264 |     #print('d')\n 265 |     optimizer = torch.optim.Adam(model.parameters(), lr=l_r, weight_decay = w_d)\n 266 |     #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 6, gamma=0.3)\n 267 |     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2,patience=2, mode = 'min')\n 268 |     current_time = datetime.now().strftime(\"%Y%m%d_%H_%M\")\n 269 |     earlystop_cnt = 0\n 270 |     aggregated_losses = []\n 271 |     aggregated_losses_val= []\n 272 |     aggregated_acc = []\n 273 |     aggregated_acc_val= []\n 274 |     best_loss = None\n 275 |     for i in tqdm(range(epochs)):\n 276 |         step_loss = []\n 277 |         step_accuracy = []\n 278 |         model.train()\n 279 |         #print('-'*10)\n 280 |         #print('start of epoch:', i)\n 281 |         k=0\n 282 |         for dat in train_loader:\n 283 |             catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n 284 |             multi_outs = model(catdata.to(device), numdata.to(device))\n 285 |             single_loss, accuracy_ls = criterion(tag_loss_function, multi_outs, labels, weights, 'train')\n 286 |             optimizer.zero_grad()\n 287 |             single_loss.backward()\n 288 |             optimizer.step()\n 289 |             step_loss.append(single_loss.item())\n 290 |             step_accuracy.append(accuracy_ls)\n 291 |         aggregated_losses.append(np.mean(step_loss))\n 292 |         aggregated_acc.append(np.mean(step_accuracy,axis=0))\n 293 |         with torch.no_grad():\n 294 |             model.eval()\n 295 |             step_loss_val = []\n 296 |             step_accuracy_val = []\n 297 |             for dat in val_loader:\n 298 |                 catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n 299 |                 multi_outs = model(catdata.to(device), numdata.to(device))\n 300 |                 single_loss, accuracy_ls = criterion(tag_loss_function, multi_outs, labels, weights, 'val')\n 301 |                 step_loss_val.append(single_loss.item())\n 302 |                 step_accuracy_val.append(accuracy_ls)\n 303 |             aggregated_losses_val.append(np.mean(step_loss_val))\n 304 |             aggregated_acc_val.append(np.mean(step_accuracy_val,axis=0))\n 305 |             if (len(aggregated_losses_val)>1):\n 306 |                 if aggregated_losses_val[-1]>best_loss:\n 307 |                     earlystop_cnt+=1\n 308 |                 else:\n 309 |                     earlystop_cnt=0\n 310 |             if earlystop_cnt>=early_stop_tol:\n 311 |                 return best_loss\n 312 |             scheduler.step(np.mean(step_loss_val))\n 313 |             if not best_loss or np.mean(step_loss_val) < best_loss:\n 314 |                 best_loss = np.mean(step_loss_val)\n 315 |                 #torch.save(model, f'./models/best_binary_{model_tag}.pt')\n 316 |                 _path = model_path+'{}_{}.bin'.format(model_tag, current_time)\n 317 |                 torch.save(model.state_dict(), _path)\n 318 |         #print('d')\n 319 |         if i%5 == 0:\n 320 |         #if False:\n 321 |             acc_esc, acc_rfi, acc_em = np.mean(step_accuracy, axis=0)\n 322 |             acc_esc, acc_rfi, acc_em = np.mean(step_accuracy_val, axis=0)\n 323 |         #with tune.checkpoint_dir(step=i) as checkpoint_dir:\n 324 |         #    path = os.path.join(checkpoint_dir, \"checkpoint\")\n 325 |         #    torch.save((model.state_dict(), optimizer.state_dict()), path)\n 326 |         #tune.report(loss=np.mean(step_loss_val))\n 327 |     return best_loss\n 328 | # use best parameters\n 329 | params = {\n 330 | 'lr': 0.005,\n 331 | 'wd': 0.0002017676740751972,\n 332 | 'dp': 0.139544111255766,\n 333 | #'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n 334 | 'nu': 120,\n 335 | 'batchsize': 191,\n 336 | 'n_layer': 2,\n 337 | 'epoch':100,\n 338 | 'path':'./PEP_PS/model_w26/best_after_tuning/',\n 339 | 'tag':'26.2_ps'\n 340 |       }\n 341 | loss = model_train(params)",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/04-model_evaluation.py": "   1 | # ## This script is ued to evaluate either PS or PEP model\n   2 | import pandas as pd\n   3 | import numpy as np\n   4 | import torch\n   5 | from tqdm import tqdm\n   6 | import matplotlib.pyplot as plt\n   7 | from sklearn.model_selection import train_test_split\n   8 | import warnings\n   9 | warnings.filterwarnings('ignore')\n  10 | import pickle\n  11 | from IPython.core.interactiveshell import InteractiveShell\n  12 | InteractiveShell.ast_node_interactivity = \"all\"\n  13 | pd.set_option('display.max_columns', 500)\n  14 | pd.set_option('display.max_rows', 500)\n  15 | from tqdm import tqdm\n  16 | import seaborn as sns\n  17 | from sklearn.metrics import confusion_matrix, classification_report\n  18 | # !nvidia-smi\n  19 | # %load_ext autoreload\n  20 | # %autoreload 2\n  21 | from common.multi import MultiLabelModel,MultiLabelDs\n  22 | from sklearn.metrics import roc_curve\n  23 | from sklearn.metrics import auc\n  24 | def eval_oot(_model_input_dict):\n  25 |     cat_col, num_col = _model_input_dict['features']\n  26 |     enc_dic = _model_input_dict['cat_encoding']\n  27 |     dev_mean, dev_std = _model_input_dict['num_norm']\n  28 |     categorical_embedding_sizes = _model_input_dict['categorical_embedding_sizes']\n  29 |     path = _model_input_dict['model_path']\n  30 |     nu = _model_input_dict['nu']\n  31 |     dataset = _model_input_dict['oot_ds']\n  32 |     n_layer = _model_input_dict['n_layer']\n  33 |     _layer=[nu]\n  34 |     last_out = nu//2\n  35 |     for i in range(n_layer-1):\n  36 |         _layer.append(last_out)\n  37 |         last_out//=2\n  38 |     model = MultiLabelModel(np.array(categorical_embedding_sizes), len(num_col), 2,2,2, _layer, p=0.2)\n  39 |     model.load_state_dict(torch.load(path))\n  40 |     model.eval()\n  41 |     def process_categories(dataset):\n  42 |         datset = dataset.copy()\n  43 |         categorical_embedding_sizes = []\n  44 |         for category in tqdm(cat_col):\n  45 |             _tmp = np.where(datset[category].isin(enc_dic[category].classes_),datset[category],'UNSEEN')\n  46 |             datset[category] = enc_dic[category].transform(_tmp)\n  47 |             col_size = len(enc_dic[category].classes_)\n  48 |             categorical_embedding_sizes.append((col_size, min(100, (col_size+1)//2)))\n  49 |         return categorical_embedding_sizes, datset\n  50 |     dataset[cat_col] = dataset[cat_col].fillna('unknown')\n  51 |     dataset[num_col] = dataset[num_col].fillna(-999)\n  52 |     _, dataset_processed = process_categories(dataset)\n  53 |     dataset_processed[num_col] = (dataset_processed[num_col] - dev_mean)/dev_std\n  54 |     tag_mt = ['tag_esc', 'tag_rfi', 'tag_em']\n  55 |     dataset_buddle = MultiLabelDs(dataset_processed, cat_col, num_col, tag_mt)\n  56 |     oot_loader = torch.utils.data.DataLoader(dataset_buddle,\n  57 |                                          batch_size=500,\n  58 |                                          num_workers = 1,\n  59 |                                          shuffle=False)\n  60 |     # Prediction\n  61 |     y_pred_list = {'pred_esc':[], 'pred_rfi':[], 'pred_em':[]}\n  62 |     y_prob_list = {'prob_esc':[], 'prob_rfi':[], 'prob_em':[]}\n  63 |     labels_ls =  {'esc':[], 'rfi':[], 'em':[]}\n  64 |     #print('b')\n  65 |     device = 'cuda'\n  66 |     #print('a')\n  67 |     model = model.to(device)\n  68 |     with torch.no_grad():\n  69 |         model.eval()\n  70 |         for dat in oot_loader:\n  71 |             catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n  72 |             #return catdata,numdata\n  73 |             oot_outs = model(catdata.to(device), numdata.to(device))\n  74 |             #return oot_outs\n  75 |             for key in ['esc','rfi','em']:\n  76 |                 prob_class=torch.softmax(oot_outs[key],dim=1)[:,1]\n  77 |                 y_prob_list['prob_'+key].extend(prob_class.cpu().numpy())\n  78 |                 pred_class = torch.max(oot_outs[key],dim=1).indices\n  79 |                 y_pred_list['pred_'+key].extend(pred_class.cpu().numpy())\n  80 |                 labels_ls[key].extend(labels['label_'+key]) \n  81 |         #return y_pred_list\n  82 |     pred_prob_ls = []\n  83 |     confusion_dict = {}\n  84 |     for tag in ['esc','rfi','em']:\n  85 |         confusion_matrix_df = pd.DataFrame(confusion_matrix(y_pred_list['pred_'+tag], labels_ls[tag]))\n  86 |         confusion_dict[tag] = confusion_matrix_df\n  87 |         #sns.heatmap(confusion_matrix_df, annot=True)\n  88 |     case_eval_ds = dataset_processed[['tid','alert_cust_id','entity_id','entity_reference_id', 'discipline_id', 'new_logic_label_v2']+tag_mt]\n  89 |     case_eval_ds=case_eval_ds.reset_index(drop='True')\n  90 |     case_eval_ds2 = pd.concat([case_eval_ds, pd.DataFrame(y_pred_list), pd.DataFrame(y_prob_list)], axis=1)\n  91 |     case_eval_ds2['tag_dis'] = np.where(case_eval_ds2['tag_esc']==1,0,1)\n  92 |     case_eval_ds2['prob_dis'] = 1-case_eval_ds2['prob_esc']\n  93 |     case_eval_ds_agg = case_eval_ds2.groupby(['tid','discipline_id','new_logic_label_v2','tag_esc','tag_rfi','tag_em','tag_dis']).agg({'prob_dis':'max','prob_esc':'max','prob_rfi':'max','prob_em':'max'}).reset_index()\n  94 |     case_eval_ds_agg['prob_dis2'] = 1-case_eval_ds_agg['prob_esc'] \n  95 |     case_eval_ds_agg['tag_dis2'] = case_eval_ds_agg['tag_dis']\n  96 |     #case_eval_ds_agg = case_eval_ds_agg.loc[~case_eval_ds_agg['prob_dis'].isna()]\n  97 |     def slice_by_cut(df, prob, tag, acc_need, n_tid):\n  98 |         _df = df[[prob,tag]].sort_values(by=prob,ascending=False)\n  99 |         _n_total_pos = _df[tag].sum()\n 100 |         _df['seq']=1\n 101 |         _df['sum_pos'] = _df[tag].cumsum()\n 102 |         _df['sum_cnt'] = _df['seq'].cumsum()\n 103 |         _df['acc_acc'] = _df['sum_pos']/_df['sum_cnt']\n 104 |         _score_cutoff = _df.loc[_df['acc_acc']>=acc_need,prob].min()\n 105 |         try:\n 106 |             _score_cutoff_recall = _df.loc[_df[prob]==_score_cutoff,'sum_pos']/_n_total_pos\n 107 |             _score_cutoff_automate = _df.loc[_df[prob]==_score_cutoff,'sum_cnt']/n_tid\n 108 |         except:\n 109 |         if _score_cutoff_recall.empty:\n 110 |             _score_cutoff_recall=0\n 111 |         else:\n 112 |             _score_cutoff_recall = _score_cutoff_recall.values[0]\n 113 |         if _score_cutoff_automate.empty:\n 114 |             _score_cutoff_automate=0\n 115 |         else:\n 116 |             _score_cutoff_automate = _score_cutoff_automate.values[0]\n 117 |         #return _score_cutoff_recall\n 118 |               .format(acc_need*100, _score_cutoff, _score_cutoff_recall*100,_score_cutoff_automate*100 ))\n 119 |         return _df\n 120 |     #return case_eval_ds_agg\n 121 |     if 1001 in case_eval_ds_agg['discipline_id'].unique():\n 122 |         case_eval_ds_agg['discipline_id'] = np.where(case_eval_ds_agg['discipline_id']==1001,0,1)\n 123 |     for disp,pep_ps in [['PS',0],['PEP',1]]:\n 124 |         for key in ['dis','dis2','esc','rfi','em']:\n 125 |             y_true = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pep_ps, 'tag_'+key]\n 126 |             y_prob = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pep_ps, 'prob_'+key]\n 127 |             y_pred = np.where(y_prob>0.5,1,0)\n 128 |             fpr,tpr,threhold=roc_curve(y_true,y_prob)\n 129 |             roc_auc=auc(fpr,tpr)\n 130 |             target_names = ['no_'+key,'is_'+key]\n 131 |             tmp_slice = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pep_ps]\n 132 |             n_tid = tmp_slice.shape[0]\n 133 |             if disp=='PS':\n 134 |                 acc_req = 0.85\n 135 |             elif disp=='PEP':\n 136 |                 acc_req = 0.85\n 137 |             _df = slice_by_cut(tmp_slice, 'prob_'+key, 'tag_'+key, acc_req, n_tid)\n 138 |     # get the OP for certain accuracy\n 139 |     return dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg\n 140 | def eval_oot_lgbm(_model_input_dict):\n 141 |     cat_col, num_col = _model_input_dict['features']\n 142 |     model = _model_input_dict['model']\n 143 |     dataset = _model_input_dict['oot_ds']\n 144 |     _tag = _model_input_dict['tag']\n 145 |     # Prediction\n 146 |     y_pred_list = {'true'+_tag:[]}\n 147 |     y_prob_list = {'prob'+_tag:[]}\n 148 |     labels_ls =  {_tag:[]}\n 149 |     with torch.no_grad():\n 150 |         model.eval()\n 151 |         for dat in oot_loader:\n 152 |             catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n 153 |             #return catdata,numdata\n 154 |             oot_outs = model(catdata.to(device), numdata.to(device))\n 155 |             #return oot_outs\n 156 |             for key in ['esc','rfi','em']:\n 157 |                 prob_class=model.predict(dataset[model.feature_name()])\n 158 |                 y_prob_list['prob_'+key].extend(prob_class)\n 159 |                 pred_class = torch.max(oot_outs[key],dim=1).indices\n 160 |                 y_pred_list['pred_'+key].extend(pred_class.cpu().numpy())\n 161 |                 labels_ls[key].extend(labels['label_'+key]) \n 162 |         #return y_pred_list\n 163 |     pred_prob_ls = []\n 164 |     confusion_dict = {}\n 165 |     for tag in ['esc','rfi','em']:\n 166 |         confusion_matrix_df = pd.DataFrame(confusion_matrix(y_pred_list['pred_'+tag], labels_ls[tag]))\n 167 |         confusion_dict[tag] = confusion_matrix_df\n 168 |         #sns.heatmap(confusion_matrix_df, annot=True)\n 169 |     case_eval_ds = dataset[['tid','alert_cust_id','entity_id','entity_reference_id', 'discipline_id', 'new_logic_label',_tag]]\n 170 |     case_eval_ds=case_eval_ds.reset_index(drop='True')\n 171 |     case_eval_ds2 = pd.concat([case_eval_ds, pd.DataFrame(y_prob_list)], axis=1)\n 172 |     case_eval_ds2['tag_dis'] = np.where(case_eval_ds2['tag_esc']==1,0,1)\n 173 |     case_eval_ds2['prob_dis'] = 1-case_eval_ds2['prob_esc']\n 174 |     case_eval_ds_agg = case_eval_ds2.groupby(['tid','discipline_id','new_logic_label','tag_esc','tag_rfi','tag_em','tag_dis']).agg({'prob_dis':'max','prob_esc':'max','prob_rfi':'max','prob_em':'max'}).reset_index()\n 175 |     case_eval_ds_agg['prob_dis2'] = 1-case_eval_ds_agg['prob_esc'] \n 176 |     case_eval_ds_agg['tag_dis2'] = case_eval_ds_agg['tag_dis']\n 177 |     #case_eval_ds_agg = case_eval_ds_agg.loc[~case_eval_ds_agg['prob_dis'].isna()]\n 178 |     def slice_by_cut(df, prob, tag, acc_need, n_tid):\n 179 |         _df = df[[prob,tag]].sort_values(by=prob,ascending=False)\n 180 |         _n_total_pos = _df[tag].sum()\n 181 |         _df['seq']=1\n 182 |         _df['sum_pos'] = _df[tag].cumsum()\n 183 |         _df['sum_cnt'] = _df['seq'].cumsum()\n 184 |         _df['acc_acc'] = _df['sum_pos']/_df['sum_cnt']\n 185 |         _score_cutoff = _df.loc[_df['acc_acc']>=acc_need,prob].min()\n 186 |         try:\n 187 |             _score_cutoff_recall = _df.loc[_df[prob]==_score_cutoff,'sum_pos']/_n_total_pos\n 188 |             _score_cutoff_automate = _df.loc[_df[prob]==_score_cutoff,'sum_cnt']/n_tid\n 189 |         except:\n 190 |         if _score_cutoff_recall.empty:\n 191 |             _score_cutoff_recall=0\n 192 |         else:\n 193 |             _score_cutoff_recall = _score_cutoff_recall.values[0]\n 194 |         if _score_cutoff_automate.empty:\n 195 |             _score_cutoff_automate=0\n 196 |         else:\n 197 |             _score_cutoff_automate = _score_cutoff_automate.values[0]\n 198 |         #return _score_cutoff_recall\n 199 |               .format(acc_need*100, _score_cutoff, _score_cutoff_recall*100,_score_cutoff_automate*100 ))\n 200 |         return _df\n 201 |     #return case_eval_ds_agg\n 202 |     if 1001 in case_eval_ds_agg['discipline_id'].unique():\n 203 |         case_eval_ds_agg['discipline_id'] = np.where(case_eval_ds_agg['discipline_id']==1001,0,1)\n 204 |     for disp,pep_ps in [['PS',0],['PEP',1]]:\n 205 |         for key in ['dis','dis2','esc','rfi','em']:\n 206 |             y_true = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pep_ps, 'tag_'+key]\n 207 |             y_prob = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pep_ps, 'prob_'+key]\n 208 |             y_pred = np.where(y_prob>0.5,1,0)\n 209 |             fpr,tpr,threhold=roc_curve(y_true,y_prob)\n 210 |             roc_auc=auc(fpr,tpr)\n 211 |             target_names = ['no_'+key,'is_'+key]\n 212 |             tmp_slice = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pep_ps]\n 213 |             n_tid = tmp_slice.shape[0]\n 214 |             if disp=='PS':\n 215 |                 acc_req = 0.85\n 216 |             elif disp=='PEP':\n 217 |                 acc_req = 0.85\n 218 |             _df = slice_by_cut(tmp_slice, 'prob_'+key, 'tag_'+key, acc_req, n_tid)\n 219 |     # get the OP for certain accuracy\n 220 |     return dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg\n 221 | def eval_ds_auc(_model_input_dict):\n 222 |     cat_col, num_col = _model_input_dict['features']\n 223 |     enc_dic = _model_input_dict['cat_encoding']\n 224 |     dev_mean, dev_std = _model_input_dict['num_norm']\n 225 |     categorical_embedding_sizes = _model_input_dict['categorical_embedding_sizes']\n 226 |     path = _model_input_dict['model_path']\n 227 |     nu = _model_input_dict['nu']\n 228 |     dataset = _model_input_dict['oot_ds']\n 229 |     model = MultiLabelModel(np.array(categorical_embedding_sizes), len(num_col), 2,2,2, [nu,nu//2], p=0.2)\n 230 |     model.load_state_dict(torch.load(path))\n 231 |     model.eval()\n 232 |     def process_categories(dataset):\n 233 |         datset = dataset.copy()\n 234 |         categorical_embedding_sizes = []\n 235 |         for category in tqdm(cat_col):\n 236 |             _tmp = np.where(datset[category].isin(enc_dic[category].classes_),datset[category],'UNSEEN')\n 237 |             datset[category] = enc_dic[category].transform(_tmp)\n 238 |             col_size = len(enc_dic[category].classes_)\n 239 |             categorical_embedding_sizes.append((col_size, min(100, (col_size+1)//2)))\n 240 |         return categorical_embedding_sizes, datset\n 241 |     dataset[cat_col] = dataset[cat_col].fillna('unknown')\n 242 |     dataset[num_col] = dataset[num_col].fillna(-999)\n 243 |     _, dataset_processed = process_categories(dataset)\n 244 |     dataset_processed[num_col] = (dataset_processed[num_col] - dev_mean)/dev_std\n 245 |     tag_mt = ['tag_esc', 'tag_rfi', 'tag_em']\n 246 |     dataset_buddle = MultiLabelDs(dataset_processed, cat_col, num_col, tag_mt)\n 247 |     oot_loader = torch.utils.data.DataLoader(dataset_buddle,\n 248 |                                          batch_size=500,\n 249 |                                          num_workers = 1,\n 250 |                                          shuffle=False)\n 251 |     # Prediction\n 252 |     y_pred_list = {'pred_esc':[], 'pred_rfi':[], 'pred_em':[]}\n 253 |     y_prob_list = {'prob_esc':[], 'prob_rfi':[], 'prob_em':[]}\n 254 |     labels_ls =  {'esc':[], 'rfi':[], 'em':[]}\n 255 |     #print('b')\n 256 |     device = 'cuda'\n 257 |     #print('a')\n 258 |     model = model.to(device)\n 259 |     with torch.no_grad():\n 260 |         model.eval()\n 261 |         for dat in oot_loader:\n 262 |             catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n 263 |             #return catdata,numdata\n 264 |             oot_outs = model(catdata.to(device), numdata.to(device))\n 265 |             #return oot_outs\n 266 |             for key in ['esc','rfi','em']:\n 267 |                 prob_class=torch.softmax(oot_outs[key],dim=1)[:,1]\n 268 |                 y_prob_list['prob_'+key].extend(prob_class.cpu().numpy())\n 269 |                 pred_class = torch.max(oot_outs[key],dim=1).indices\n 270 |                 y_pred_list['pred_'+key].extend(pred_class.cpu().numpy())\n 271 |                 labels_ls[key].extend(labels['label_'+key]) \n 272 |         #return y_pred_list\n 273 |     pred_prob_ls = []\n 274 |     case_eval_ds = dataset_processed[['tid','alert_cust_id','entity_id','entity_reference_id', 'discipline_id', 'new_logic_label']+tag_mt]\n 275 |     case_eval_ds=case_eval_ds.reset_index(drop='True')\n 276 |     case_eval_ds2 = pd.concat([case_eval_ds, pd.DataFrame(y_pred_list), pd.DataFrame(y_prob_list)], axis=1)\n 277 |     case_eval_ds2['tag_dis'] = np.where(case_eval_ds2['tag_esc']==1,0,1)\n 278 |     case_eval_ds2['prob_dis'] = 1-case_eval_ds2['prob_esc']\n 279 |     case_eval_ds_agg = case_eval_ds2.groupby(['tid','discipline_id','new_logic_label','tag_esc','tag_rfi','tag_em','tag_dis']).agg({'prob_dis':'max','prob_esc':'max','prob_rfi':'max','prob_em':'max'}).reset_index()\n 280 |     case_eval_ds_agg['prob_dis2'] = 1-case_eval_ds_agg['prob_esc'] \n 281 |     case_eval_ds_agg['tag_dis2'] = case_eval_ds_agg['tag_dis']\n 282 |     #case_eval_ds_agg = case_eval_ds_agg.loc[~case_eval_ds_agg['prob_dis'].isna()]\n 283 |     def slice_by_cut(df, prob, tag, acc_need, n_tid):\n 284 |         _df = df[[prob,tag]].sort_values(by=prob,ascending=False)\n 285 |         _n_total_pos = _df[tag].sum()\n 286 |         _df['seq']=1\n 287 |         _df['sum_pos'] = _df[tag].cumsum()\n 288 |         _df['sum_cnt'] = _df['seq'].cumsum()\n 289 |         _df['acc_acc'] = _df['sum_pos']/_df['sum_cnt']\n 290 |         _score_cutoff = _df.loc[_df['acc_acc']>=acc_need,prob].min()\n 291 |         try:\n 292 |             _score_cutoff_recall = _df.loc[_df[prob]==_score_cutoff,'sum_pos']/_n_total_pos\n 293 |             _score_cutoff_automate = _df.loc[_df[prob]==_score_cutoff,'sum_cnt']/n_tid\n 294 |         except:\n 295 |         if _score_cutoff_recall.empty:\n 296 |             _score_cutoff_recall=0\n 297 |         else:\n 298 |             _score_cutoff_recall = _score_cutoff_recall.values[0]\n 299 |         if _score_cutoff_automate.empty:\n 300 |             _score_cutoff_automate=0\n 301 |         else:\n 302 |             _score_cutoff_automate = _score_cutoff_automate.values[0]\n 303 |         #return _score_cutoff_recall\n 304 |               .format(acc_need*100, _score_cutoff, _score_cutoff_recall*100,_score_cutoff_automate*100 ))\n 305 |         return _df\n 306 |     #return case_eval_ds_agg\n 307 |     res_auc = []\n 308 |     for key in ['dis','dis2','esc','rfi','em']:\n 309 |         y_true = case_eval_ds_agg.loc[:, 'tag_'+key]\n 310 |         y_prob = case_eval_ds_agg.loc[:, 'prob_'+key]\n 311 |         y_pred = np.where(y_prob>0.5,1,0)\n 312 |         fpr,tpr,threhold=roc_curve(y_true,y_prob)\n 313 |         roc_auc=auc(fpr,tpr)\n 314 |         target_names = ['no_'+key,'is_'+key]\n 315 |         res_auc.append(roc_auc)\n 316 |         #tmp_slice = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pep_ps]\n 317 |         #n_tid = tmp_slice.shape[0]\n 318 |         #if disp=='PS':\n 319 |         #    acc_req = 0.9\n 320 |         #elif disp=='PEP':\n 321 |         #    acc_req = 0.9\n 322 |         #_df = slice_by_cut(tmp_slice, 'prob_'+key, 'tag_'+key, acc_req, n_tid)\n 323 |         #print(classification_report(y_true, y_pred, target_names=target_names))\n 324 |     # get the OP for certain accuracy\n 325 |     return res_auc\n 326 | def slice_by_cut(df, prob, tag, acc_need, n_tid):\n 327 |     _df = df[[prob,tag]].sort_values(by=prob,ascending=False)\n 328 |     _n_total_pos = _df[tag].sum()\n 329 |     _df['seq']=1\n 330 |     _df['sum_pos'] = _df[tag].cumsum()\n 331 |     _df['sum_cnt'] = _df['seq'].cumsum()\n 332 |     _df['acc_acc'] = _df['sum_pos']/_df['sum_cnt']\n 333 |     _score_cutoff = _df.loc[_df['acc_acc']>=acc_need,prob].min()\n 334 |     try:\n 335 |         _score_cutoff_recall = _df.loc[_df[prob]==_score_cutoff,'sum_pos']/_n_total_pos\n 336 |         _score_cutoff_automate = _df.loc[_df[prob]==_score_cutoff,'sum_cnt']/n_tid\n 337 |     except:\n 338 |     if _score_cutoff_recall.empty:\n 339 |         _score_cutoff_recall=0\n 340 |     else:\n 341 |         _score_cutoff_recall = _score_cutoff_recall.values[0]\n 342 |     if _score_cutoff_automate.empty:\n 343 |         _score_cutoff_automate=0\n 344 |     else:\n 345 |         _score_cutoff_automate = _score_cutoff_automate.values[0]\n 346 |     #return _score_cutoff_recall\n 347 |           .format(acc_need*100, _score_cutoff, _score_cutoff_recall*100,_score_cutoff_automate*100 ))\n 348 |     return _df,_score_cutoff\n 349 | def eval_train_val_oot(_model_input_dict):\n 350 |     cat_col, num_col = _model_input_dict['features']\n 351 |     enc_dic = _model_input_dict['cat_encoding']\n 352 |     dev_mean, dev_std = _model_input_dict['num_norm']\n 353 |     categorical_embedding_sizes = _model_input_dict['categorical_embedding_sizes']\n 354 |     path = _model_input_dict['model_path']\n 355 |     nu = _model_input_dict['nu']\n 356 |     dataset = _model_input_dict['oot_ds']\n 357 |     trainds = _model_input_dict['train_ds']\n 358 |     valds = _model_input_dict['val_ds']\n 359 |     n_layer = _model_input_dict['n_layer']\n 360 |     _layer=[nu]\n 361 |     last_out = nu//2\n 362 |     for i in range(n_layer-1):\n 363 |         _layer.append(last_out)\n 364 |         last_out//=2\n 365 |     model = MultiLabelModel(np.array(categorical_embedding_sizes), len(num_col), 2,2,2, _layer, p=0.2)\n 366 |     model.load_state_dict(torch.load(path))\n 367 |     model.eval()\n 368 |     device = 'cuda'\n 369 |     model = model.to(device)\n 370 |     def process_categories(dataset):\n 371 |         datset = dataset.copy()\n 372 |         categorical_embedding_sizes = []\n 373 |         for category in tqdm(cat_col):\n 374 |             _tmp = np.where(datset[category].isin(enc_dic[category].classes_),datset[category],'UNSEEN')\n 375 |             datset[category] = enc_dic[category].transform(_tmp)\n 376 |             col_size = len(enc_dic[category].classes_)\n 377 |             categorical_embedding_sizes.append((col_size, min(100, (col_size+1)//2)))\n 378 |         return categorical_embedding_sizes, datset\n 379 |     return_dic={'dataset_type':[],'run_date':[],'discipline':[],'tag':[],'num_cases':[],'AUC':[]}\n 380 |     for _type,_data in [['train',trainds],['val',valds],['oot',dataset]]:\n 381 |         _data[cat_col] = _data[cat_col].fillna('unknown')\n 382 |         _data[num_col] = _data[num_col].fillna(-999)\n 383 |         _, dataset_processed = process_categories(_data)\n 384 |         dataset_processed[num_col] = (dataset_processed[num_col] - dev_mean)/dev_std\n 385 |         tag_mt = ['tag_esc', 'tag_rfi', 'tag_em']\n 386 |         dataset_buddle = MultiLabelDs(dataset_processed, cat_col, num_col, tag_mt)\n 387 |         dt_loader = torch.utils.data.DataLoader(dataset_buddle,\n 388 |                                              batch_size=500,\n 389 |                                              num_workers = 1,\n 390 |                                              shuffle=False)\n 391 |         # Prediction\n 392 |         y_pred_list = {'pred_esc':[], 'pred_rfi':[], 'pred_em':[]}\n 393 |         y_prob_list = {'prob_esc':[], 'prob_rfi':[], 'prob_em':[]}\n 394 |         labels_ls =  {'esc':[], 'rfi':[], 'em':[]}\n 395 |         with torch.no_grad():\n 396 |             model.eval()\n 397 |             for dat in dt_loader:\n 398 |                 catdata, numdata, labels, weights = dat[0],dat[1],dat[2],dat[3]\n 399 |                 #return catdata,numdata\n 400 |                 prob_outs = model(catdata.to(device), numdata.to(device))\n 401 |                 #return oot_outs\n 402 |                 for key in ['esc','rfi','em']:\n 403 |                     prob_class=torch.softmax(prob_outs[key],dim=1)[:,1]\n 404 |                     y_prob_list['prob_'+key].extend(prob_class.cpu().numpy())\n 405 |                     pred_class = torch.max(prob_outs[key],dim=1).indices\n 406 |                     y_pred_list['pred_'+key].extend(pred_class.cpu().numpy())\n 407 |                     labels_ls[key].extend(labels['label_'+key]) \n 408 |         pred_prob_ls = []\n 409 |         case_eval_ds = dataset_processed[['tid','alert_cust_id','entity_id','entity_reference_id', 'discipline_id', 'new_logic_label','time_created']+tag_mt]\n 410 |         case_eval_ds=case_eval_ds.reset_index(drop='True')\n 411 |         case_eval_ds['run_date'] = case_eval_ds['time_created'].str[:7]\n 412 |         case_eval_ds2 = pd.concat([case_eval_ds, pd.DataFrame(y_pred_list), pd.DataFrame(y_prob_list)], axis=1)\n 413 |         case_eval_ds2['tag_dis'] = np.where(case_eval_ds2['tag_esc']==1,0,1)\n 414 |         case_eval_ds2['prob_dis'] = 1-case_eval_ds2['prob_esc']\n 415 |         case_eval_ds_agg = case_eval_ds2.groupby(['tid','discipline_id','new_logic_label','run_date','tag_esc','tag_rfi','tag_em','tag_dis']).agg({'prob_dis':'max','prob_esc':'max','prob_rfi':'max','prob_em':'max'}).reset_index()\n 416 |         case_eval_ds_agg['prob_dis2'] = 1-case_eval_ds_agg['prob_esc'] \n 417 |         case_eval_ds_agg['tag_dis2'] = case_eval_ds_agg['tag_dis']\n 418 |         if any([1001 in case_eval_ds_agg['discipline_id'].unique(),1002 in case_eval_ds_agg['discipline_id'].unique()]):\n 419 |             case_eval_ds_agg['discipline_id'] = np.where(case_eval_ds_agg['discipline_id']==1001,0,1)\n 420 |         for _date in case_eval_ds_agg['run_date'].unique():\n 421 |                 for disp,pep_ps in [['PS',0],['PEP',1]]:\n 422 |                     for key in ['dis','dis2','esc','rfi','em']:\n 423 |                         _tmp_data = case_eval_ds_agg.loc[(case_eval_ds_agg['run_date']==_date)&(case_eval_ds_agg['discipline_id']==pep_ps)]\n 424 |                         true_y = _tmp_data['tag_'+key]\n 425 |                         prob_y = _tmp_data['prob_'+key]\n 426 |                         if prob_y.shape[0]!=0:\n 427 |                             fpr,tpr,threhold=roc_curve(true_y,prob_y)\n 428 |                             roc_auc=auc(fpr,tpr)\n 429 |                         else:\n 430 |                             roc_auc=0\n 431 |                         _vol = _tmp_data.shape[0]\n 432 |                         return_dic['dataset_type'].append(_type)\n 433 |                         return_dic['run_date'].append(_date)\n 434 |                         return_dic['discipline'].append(disp)\n 435 |                         return_dic['tag'].append(key)\n 436 |                         return_dic['num_cases'].append(_vol)\n 437 |                         return_dic['AUC'].append(roc_auc)\n 438 |                 #return return_dic\n 439 |     return return_dic\n 440 | def tvo_plot(perf_dic):\n 441 |     for disp in ['PS','PEP']:\n 442 |         for tag in ['dis2','esc','rfi','em']:\n 443 |             a=pd.DataFrame(perf_dic)\n 444 |             b=a.loc[(a['tag']==tag) & (a['discipline']==disp)]\n 445 |             fig=plt.figure(figsize=(7,3))\n 446 |             plt.xticks(rotation=45)\n 447 |             ax1 = fig.add_subplot(111)\n 448 |             ax2 = ax1.twinx()\n 449 |             ax=sns.barplot(x='run_date',y='num_cases',data=b,color='blue',ax=ax1, hue='dataset_type')\n 450 |             sns.move_legend(ax, \"lower left\")\n 451 |             # only change this line\n 452 |             ax1=sns.lineplot(x='run_date', y='AUC',data=b,marker='s',color='orange',ax=ax2,hue='dataset_type')\n 453 |             ax1.set_yticks([0.5,0.6,0.7,.75,0.8,.85,0.9,.95,1.0])\n 454 |             sns.move_legend(ax1, \"lower right\")\n 455 |             plt.xticks(rotation=60)\n 456 |             plt.title('Train-Val-OOT AUC\\n{} - {}'.format(disp,tag))\n 457 |             plt.show()\n 458 |     return\n 459 | def gainChart(pred,score_norm='prediction',cust_id='cust_id',label='target'):\n 460 |     bins=[0]\n 461 |     bins+=[float(\"{0:.2f}\".format(x*0.05)) for x in range(1,20)]\n 462 |     bins+=[1]\n 463 |     pred['pred_bins']=pd.qcut(pred[score_norm].rank(method='first'),bins,labels=['bin'+str(x+1) for x in range(len(bins)-1)])\n 464 |     #df.rank(method='first')\n 465 |     aggregations = {\n 466 |         cust_id:'count',\n 467 |         label:'sum',\n 468 |         score_norm: ['min','max']\n 469 |     }\n 470 |     adf = pred.groupby('pred_bins').agg(aggregations)\n 471 |     bdf = adf.iloc[::-1].reset_index()\n 472 |     bdf['score_band_l']=bdf[score_norm]['min']*1000\n 473 |     bdf['score_band_h']=bdf[score_norm]['max']*1000\n 474 |     bdf['num_cum']=bdf[cust_id]['count'].cumsum()\n 475 |     bdf['num']=bdf[cust_id]['count']\n 476 |     bdf['resp_num']=bdf[label]['sum']\n 477 |     bdf['resp_cum']=bdf['resp_num'].cumsum()\n 478 |     bdf['perc']=1.0*bdf['num']/sum(bdf['num'])\n 479 |     bdf['resp_rate']=1.0*bdf['resp_num']/bdf['num']\n 480 |     bdf['cap_rate']=1.0*bdf['resp_num']/sum(bdf['resp_num'])\n 481 |     bdf['perc_cum']=bdf['perc'].cumsum()\n 482 |     bdf['resp_rate_cum']=bdf['resp_cum']/bdf['num_cum']\n 483 |     bdf['cap_rate_cum']=bdf['resp_cum']/sum(bdf['resp_num'])\n 484 |     return bdf[['score_band_l','score_band_h','num','resp_num','resp_cum','perc','perc_cum','resp_rate','resp_rate_cum','cap_rate','cap_rate_cum']]\n 485 | def eval_model(pred, act):\n 486 |     df_eval = pd.DataFrame({'pred':pred,'actual':act})\n 487 |     df_eval.sort_values('pred',ascending=False, inplace=True)\n 488 |     n_true_pos = df_eval.actual.sum()\n 489 |     df_eval['_seq']=1\n 490 |     df_eval['cum_cnt_t_pos'] = df_eval['actual'].cumsum()\n 491 |     df_eval['cum_cnt_all'] = df_eval['_seq'].cumsum()\n 492 |     df_eval['cum_precision'] = df_eval['cum_cnt_t_pos']*100/df_eval['cum_cnt_all']\n 493 |     df_eval['cum_recall'] = df_eval['cum_cnt_t_pos']*100/n_true_pos\n 494 |     df_eval['pct_volume']=df_eval['cum_cnt_all']*100/n_total\n 495 |     df_eval_ideal = pd.DataFrame({'actual':act})\n 496 |     df_eval_ideal.sort_values('actual',ascending=False, inplace=True)\n 497 |     n_true_pos = df_eval_ideal.actual.sum()\n 498 |     df_eval_ideal['_seq']=1\n 499 |     df_eval_ideal['cum_cnt_t_pos'] = df_eval_ideal['actual'].cumsum()\n 500 |     df_eval_ideal['cum_cnt_all'] = df_eval_ideal['_seq'].cumsum()\n 501 |     df_eval_ideal['cum_precision'] = df_eval_ideal['cum_cnt_t_pos']*100/df_eval_ideal['cum_cnt_all']\n 502 |     df_eval_ideal['cum_recall'] = df_eval_ideal['cum_cnt_t_pos']*100/n_true_pos\n 503 |     df_eval_ideal['pct_volume']=df_eval_ideal['cum_cnt_all']*100/n_total\n 504 |     return df_eval, df_eval_ideal\n 505 | def pt_roc_auc(true_y,prob_y):\n 506 |     from sklearn.metrics import roc_curve\n 507 |     from sklearn.metrics import auc\n 508 |     fpr,tpr,threhold=roc_curve(true_y,prob_y)\n 509 |     roc_auc=auc(fpr,tpr)\n 510 |     plt.title('ROC')\n 511 |     plt.plot(fpr,tpr,'b',label='AUC=%0.2f'%roc_auc)\n 512 |     plt.legend(loc='lower right')\n 513 |     plt.plot([0,1],[0,1],'r--')\n 514 |     plt.xlim([0,1])\n 515 |     plt.ylim([0,1])\n 516 |     plt.ylabel('True Positive Rate')\n 517 |     plt.xlabel('False Positive Rate')\n 518 |     plt.show()\n 519 |     return\n 520 | def pr_line(df_eval, df_ideal):\n 521 |     target_pr = df_eval.loc[df_eval['pct_volume']==df_eval.loc[df_eval['pct_volume']<=25,['pct_volume']].max().values[0],['cum_precision','cum_recall']].values\n 522 |     #print('At OP 25, Precision: {}, Recall: {}'.format(target_pr[0][0],target_pr[0][1]))\n 523 |     target_op = df_eval.loc[df_eval['cum_precision']>=95,'pct_volume'].max()\n 524 |     target_recall = df_eval.loc[df_eval['pct_volume']==target_op,'cum_recall']\n 525 |     # Evaluate by OP\n 526 |     ax = plt.gca()\n 527 |     df_eval.plot(x='pct_volume',y='cum_precision',kind='line',xticks=[0,*range(4,100,5)],sort_columns='pred'\n 528 |            ,title='Precision / Recall by OP',legend=True,label='Precision', grid=True\n 529 |            ,figsize=(10,4), color='b', ax=ax)\n 530 |     df_ideal.plot(x='pct_volume',y='cum_precision',kind='line',xticks=[0,*range(4,100,5)],sort_columns='actual'\n 531 |            ,title='Precision / Recall by OP',legend=True,label='Precision-ideal', grid=True\n 532 |            ,figsize=(10,4), color='b', style='--', ax=ax)\n 533 |     df_eval.plot(x='pct_volume',y='cum_recall',kind='line',xticks=[0,*range(4,100,5)],sort_columns='pred'\n 534 |            ,title='Precision / Recall by OP',legend=True,label='Recall', grid=True\n 535 |            ,figsize=(10,4), color='orange', ax=ax)\n 536 |     df_ideal.plot(x='pct_volume',y='cum_recall',kind='line',xticks=[0,*range(4,100,5)],sort_columns='actual'\n 537 |            ,title='Precision / Recall by OP',legend=True,label='Recall-ideal', grid=True\n 538 |            ,figsize=(10,4), color='orange', style='--', ax=ax)\n 539 |     ax.set_xlabel('Operation Point')\n 540 |     ax.set_ylabel('% - Precision / Recall')\n 541 |     ax.set_xticks(range(0,101,5))\n 542 |     ax.set_yticks([*range(0,101,5)])\n 543 |     #plt.axvline(x=25,color='red')\n 544 |     #ax.set_yticklabels(range(0,101,20))\n 545 |     plt.legend(loc=\"lower right\",fontsize=10)\n 546 |     plt.show()\n 547 |     # Evaluate by score\n 548 |     ax = plt.gca()\n 549 |     df_eval.plot(x='pred',y='cum_precision',kind='line',xticks=[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1],sort_columns='pred'\n 550 |            ,title='Precision / Recall by score',legend=True,label='Precision', grid=True\n 551 |            ,figsize=(10,4), ax=ax)\n 552 |     df_eval.plot(x='pred',y='cum_recall',kind='line',xticks=[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1],sort_columns='pred'\n 553 |            ,title='Precision / Recall by score',legend=True,label='Recall', grid=True\n 554 |            ,figsize=(10,4), ax=ax)\n 555 |     ax.set_xlabel('Model Score')\n 556 |     ax.set_ylabel('% - Precision / Recall')\n 557 |     ax.set_xticks([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1])\n 558 |     ax.set_yticks([0,15,35,55,75,95])\n 559 |     #ax.set_yticklabels(range(0,101,20))\n 560 |     plt.legend(loc=\"lower right\",fontsize=10)\n 561 |     plt.show()\n 562 | def eval_comb(df, key):\n 563 |     df_eval, df_eval_ideal = eval_model(df['prob_'+key], df['tag_'+key])\n 564 |     pt_roc_auc(df['tag_'+key],df['prob_'+key])\n 565 |     pr_line(df_eval, df_eval_ideal)\n 566 |     return gainChart(df,score_norm='prob_'+key,cust_id='tid',label='tag_'+key)\n 567 | # ## PEP v23.1 Single - no dob, more numericals, no rfi-dismissal\n 568 | folder_v = 'w23'\n 569 | tag_v='23.1_pep'\n 570 | model_input_dict={}\n 571 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 572 |     cat_col, num_col = pickle.load(f)\n 573 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v9.1.pk')\n 574 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2021-07-31 23:59:59']\n 575 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n 576 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n 577 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n 578 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n 579 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n 580 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n 581 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n 582 | tag = 'new_logic_label'\n 583 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 584 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n 585 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 586 | for cat in cat_col:\n 587 |     all_dataset[cat] = all_dataset[cat].astype('string')\n 588 |     all_dataset[cat] = all_dataset[cat].astype('O')\n 589 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n 590 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-04-31 23:59:59']\n 591 | dev_ds.set_index('tid',inplace=True)\n 592 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n 593 | train_ds = dev_ds.loc[train_idx].reset_index()\n 594 | test_ds = dev_ds.loc[test_idx].reset_index()\n 595 | #train_ds = dev_ds.loc[train_caseid].reset_index()\n 596 | #test_ds = dev_ds.loc[test_caseid].reset_index()\n 597 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-05-01 00:00:00']\n 598 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n 599 |     enc_dic = pickle.load(f)\n 600 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 601 |     dev_mean, dev_std = pickle.load(f)\n 602 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 603 |     categorical_embedding_sizes = pickle.load(f)\n 604 | model_input_dict['features'] = [cat_col, num_col]\n 605 | model_input_dict['cat_encoding'] = enc_dic\n 606 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n 607 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n 608 | model_input_dict['model_path'] = './PEP_PS/model_{}/best_after_tuning/{}_20220811_13_40.bin'.format(folder_v,tag_v)\n 609 | model_input_dict['nu'] = 50\n 610 | model_input_dict['train_ds'] = train_ds\n 611 | model_input_dict['val_ds'] = test_ds\n 612 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n 613 | model_input_dict['oot_ds'] = oot_ds\n 614 | perf_dic = eval_train_val_oot(model_input_dict)\n 615 | tvo_plot(perf_dic)\n 616 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n 617 | dis_cutoff=0.78\n 618 | rfi_cutoff=0.7\n 619 | n_total = np.sum(case_eval_ds_agg['discipline_id']==1)\n 620 | a_pos=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 621 |                          (case_eval_ds_agg['prob_dis2']>=dis_cutoff),\n 622 |                          ['new_logic_label']].value_counts()\n 623 | a_neg=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 624 |                          (case_eval_ds_agg['prob_dis2']<dis_cutoff),\n 625 |                          ['new_logic_label']].value_counts()\n 626 | a_merge = pd.merge(pd.DataFrame(a_pos),pd.DataFrame(a_neg),how='left',left_index=True,right_index=True)\n 627 | a_merge.columns = ['pos','neg']\n 628 | a_merge['ratio'] = a_merge['pos']/(a_merge['pos']+a_merge['neg'])\n 629 | a_merge_t = a_merge.T\n 630 | n_model_dis = a_merge_t.loc['pos',:].sum()\n 631 | a_merge_t['accuracy'] = a_merge_t[(      'Man-Dis',)]/(a_merge_t.sum(axis=1))\n 632 | a_merge_t\n 633 | #n_model_dis = a_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()\n 634 | b_pos=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 635 |                                (case_eval_ds_agg['prob_dis2']<dis_cutoff)&\n 636 |                          (case_eval_ds_agg['prob_rfi']>=rfi_cutoff),\n 637 |                          ['new_logic_label']].value_counts()\n 638 | b_neg=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 639 |                                (case_eval_ds_agg['prob_dis2']<dis_cutoff)&\n 640 |                          (case_eval_ds_agg['prob_rfi']<rfi_cutoff),\n 641 |                          ['new_logic_label']].value_counts()\n 642 | b_merge = pd.merge(pd.DataFrame(b_pos),pd.DataFrame(b_neg),how='left',left_index=True,right_index=True)\n 643 | b_merge.columns = ['pos','neg']\n 644 | b_merge['ratio'] = b_merge['pos']/(b_merge['pos']+b_merge['neg'])\n 645 | b_merge_t = b_merge.T\n 646 | n_model_rfi = b_merge_t.loc['pos',:].sum()\n 647 | b_merge_t['accuracy']  = b_merge_t[(      'RFI',)]/(b_merge_t.sum(axis=1))\n 648 | b_merge_t\n 649 | #n_model_rfi = b_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()\n 650 | for disp,pepps in [['PEP',1]]:\n 651 |     for key in ['dis2','esc','rfi','em']:\n 652 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n 653 |         #117689504158012865\n 654 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n 655 |         eval_comb(_slice_eva_ds, key)\n 656 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_PEP_23.1.csv',sep='\\x07',index=False)\n 657 | # ## PS v24.1 Single - no dob vars. trained without auto-rfi, more numericals\n 658 | case_auto_rfi = pd.read_pickle('/home/chaoychen/shared_data/data/keyuchen/pep_ps_scm_hits_driver_v2.pkl')\n 659 | case_auto_rfi = case_auto_rfi.loc[:,['TID','TIME_CREATED','new_logic_label_v2']].drop_duplicates()\n 660 | case_auto_rfi.columns = case_auto_rfi.columns.str.lower()\n 661 | folder_v = 'w24'\n 662 | tag_v='24.1_ps'\n 663 | model_input_dict={}\n 664 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 665 |     cat_col, num_col = pickle.load(f)\n 666 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v9.1.pk')\n 667 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n 668 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2021-07-31 23:59:59']\n 669 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n 670 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n 671 | tag = 'new_logic_label'\n 672 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 673 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n 674 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 675 | for cat in cat_col:\n 676 |     all_dataset[cat] = all_dataset[cat].astype('string')\n 677 |     all_dataset[cat] = all_dataset[cat].astype('O')\n 678 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n 679 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-03-31 23:59:59']\n 680 | dev_ds.set_index('tid',inplace=True)\n 681 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n 682 | #train_ds = dev_ds.loc[train_idx].reset_index()\n 683 | #test_ds = dev_ds.loc[test_idx].reset_index()\n 684 | train_ds = dev_ds.loc[train_caseid].reset_index()\n 685 | test_ds = dev_ds.loc[test_caseid].reset_index()\n 686 | # Change OOT evaluation to not including auto-rfi, it will be evaluated separately\n 687 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00'),:]\n 688 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n 689 |     enc_dic = pickle.load(f)\n 690 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 691 |     dev_mean, dev_std = pickle.load(f)\n 692 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 693 |     categorical_embedding_sizes = pickle.load(f)\n 694 | model_input_dict['features'] = [cat_col, num_col]\n 695 | model_input_dict['cat_encoding'] = enc_dic\n 696 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n 697 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n 698 | model_input_dict['model_path'] = './PEP_PS/model_{}/best_after_tuning/{}_20220811_13_06.bin'.format(folder_v,tag_v)\n 699 | model_input_dict['nu'] = 120\n 700 | model_input_dict['train_ds'] = train_ds\n 701 | model_input_dict['val_ds'] = test_ds\n 702 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n 703 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00') & (all_dataset['tid'].isin(case_auto_rfi.loc[case_auto_rfi['new_logic_label_v2']!='Auto-RFI','tid']))]\n 704 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n 705 | perf_dic = eval_train_val_oot(model_input_dict)\n 706 | tvo_plot(perf_dic)\n 707 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n 708 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00') ,:]\n 709 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n 710 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n 711 | case_eval_ds_agg_ext = pd.merge(case_eval_ds_agg,case_auto_rfi[['tid','time_created','new_logic_label_v2']],how='left',on='tid')\n 712 | case_eval_ds_agg_ext.to_csv('./PEP_PS/Evaluation/eva_PS_24.1.csv',sep='\\x07',index=False)\n 713 | case_eval_ds_agg_ext = pd.read_csv('./PEP_PS/Evaluation/eva_PS_24.1.csv',sep='\\x07')\n 714 | case_eval_ds_agg_ext.new_logic_label_v2.value_counts()\n 715 | dis_cutoff=0.611\n 716 | rfi_cutoff=0.93\n 717 | n_total = np.sum(case_eval_ds_agg_ext['discipline_id']==0)\n 718 | a_pos=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 719 |                          (case_eval_ds_agg_ext['prob_dis2']>=dis_cutoff),\n 720 |                          ['new_logic_label_v2']].value_counts()\n 721 | a_neg=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 722 |                          (case_eval_ds_agg_ext['prob_dis2']<dis_cutoff),\n 723 |                          ['new_logic_label_v2']].value_counts()\n 724 | a_merge = pd.merge(pd.DataFrame(a_pos),pd.DataFrame(a_neg),how='left',left_index=True,right_index=True)\n 725 | a_merge.columns = ['pos','neg']\n 726 | a_merge['ratio'] = a_merge['pos']/(a_merge['pos']+a_merge['neg'])\n 727 | a_merge_t = a_merge.T\n 728 | n_model_dis = a_merge_t.loc['pos',:].sum()\n 729 | a_merge_t['accuracy'] = a_merge_t[(      'Man-Dis',)]/(a_merge_t.sum(axis=1)-a_merge_t[(    'Auto-RFI',)])\n 730 | a_merge_t\n 731 | #n_model_dis = a_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()\n 732 | b_pos=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 733 |                                (case_eval_ds_agg_ext['prob_dis2']<dis_cutoff)&\n 734 |                          (case_eval_ds_agg_ext['prob_rfi']>=rfi_cutoff),\n 735 |                          ['new_logic_label_v2']].value_counts()\n 736 | b_neg=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 737 |                                (case_eval_ds_agg_ext['prob_dis2']<dis_cutoff)&\n 738 |                          (case_eval_ds_agg_ext['prob_rfi']<rfi_cutoff),\n 739 |                          ['new_logic_label_v2']].value_counts()\n 740 | b_merge = pd.merge(pd.DataFrame(b_pos),pd.DataFrame(b_neg),how='left',left_index=True,right_index=True)\n 741 | b_merge.columns = ['pos','neg']\n 742 | b_merge['ratio'] = b_merge['pos']/(b_merge['pos']+b_merge['neg'])\n 743 | b_merge_t = b_merge.T\n 744 | n_model_rfi = b_merge_t.loc['pos',:].sum()\n 745 | b_merge_t['accuracy']  = b_merge_t[(      'RFI',)]/(b_merge_t.sum(axis=1)-b_merge_t[(    'Auto-RFI',)])\n 746 | b_merge_t\n 747 | #n_model_rfi = b_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()\n 748 | b_pos=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 749 |                                (case_eval_ds_agg_ext['prob_dis2']<dis_cutoff)&\n 750 |                          (case_eval_ds_agg_ext['prob_rfi']>=rfi_cutoff),\n 751 |                          ['new_logic_label_v2']].value_counts()\n 752 | b_neg=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 753 |                                (case_eval_ds_agg_ext['prob_dis2']<dis_cutoff)&\n 754 |                          (case_eval_ds_agg_ext['prob_rfi']<rfi_cutoff),\n 755 |                          ['new_logic_label_v2']].value_counts()\n 756 | b_merge = pd.merge(pd.DataFrame(b_pos),pd.DataFrame(b_neg),how='left',left_index=True,right_index=True)\n 757 | b_merge.columns = ['pos','neg']\n 758 | b_merge['ratio'] = b_merge['pos']/(b_merge['pos']+b_merge['neg'])\n 759 | b_merge_t = b_merge.T\n 760 | n_model_rfi = b_merge_t.loc['pos',:].sum()\n 761 | b_merge_t['accuracy']  = b_merge_t[(      'RFI',)]/(b_merge_t.sum(axis=1)-b_merge_t[(    'Auto-RFI',)])\n 762 | b_merge_t\n 763 | b_merge_t.sum(axis=1)\n 764 | a_merge_t[(    'Auto-RFI',)]\n 765 | all_dataset.loc[:,['dob_available','customer_dob_available']].fillna(-999).value_counts()\n 766 | rfi_cutoff=0.858\n 767 | dis_cutoff=1\n 768 | a_pos=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 769 |                                (case_eval_ds_agg_ext['prob_dis2']<dis_cutoff)&\n 770 |                          (case_eval_ds_agg_ext['prob_rfi']>=rfi_cutoff),\n 771 |                          ['new_logic_label_v2']].value_counts()\n 772 | a_neg=case_eval_ds_agg_ext.loc[(case_eval_ds_agg_ext['discipline_id']==0) & \n 773 |                                (case_eval_ds_agg_ext['prob_dis2']<dis_cutoff)&\n 774 |                          (case_eval_ds_agg_ext['prob_rfi']<rfi_cutoff),\n 775 |                          ['new_logic_label_v2']].value_counts()\n 776 | a_merge = pd.merge(pd.DataFrame(a_pos),pd.DataFrame(a_neg),how='left',left_index=True,right_index=True)\n 777 | a_merge.columns = ['pos','neg']\n 778 | a_merge['ratio'] = a_merge['pos']/(a_merge['pos']+a_merge['neg'])\n 779 | a_merge_t = a_merge.T\n 780 | a_merge_t['accuracy']  = a_merge_t[(      'RFI',)]/(a_merge_t.sum(axis=1)-a_merge_t[(    'Auto-RFI',)])\n 781 | a_merge_t\n 782 | # ## PEP v23.2 Single - no dob, more numericals, no rfi-dismissal, hyper tune\n 783 | folder_v = 'w23'\n 784 | tag_v='23.2_pep'\n 785 | model_v='23.2_pepht'\n 786 | model_input_dict={}\n 787 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 788 |     cat_col, num_col = pickle.load(f)\n 789 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v9.1.pk')\n 790 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2021-07-31 23:59:59']\n 791 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n 792 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n 793 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n 794 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n 795 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n 796 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n 797 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n 798 | tag = 'new_logic_label'\n 799 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 800 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n 801 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 802 | for cat in cat_col:\n 803 |     all_dataset[cat] = all_dataset[cat].astype('string')\n 804 |     all_dataset[cat] = all_dataset[cat].astype('O')\n 805 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n 806 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-04-31 23:59:59']\n 807 | dev_ds.set_index('tid',inplace=True)\n 808 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n 809 | train_ds = dev_ds.loc[train_idx].reset_index()\n 810 | test_ds = dev_ds.loc[test_idx].reset_index()\n 811 | #train_ds = dev_ds.loc[train_caseid].reset_index()\n 812 | #test_ds = dev_ds.loc[test_caseid].reset_index()\n 813 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-05-01 00:00:00']\n 814 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n 815 |     enc_dic = pickle.load(f)\n 816 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 817 |     dev_mean, dev_std = pickle.load(f)\n 818 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 819 |     categorical_embedding_sizes = pickle.load(f)\n 820 | model_input_dict['features'] = [cat_col, num_col]\n 821 | model_input_dict['cat_encoding'] = enc_dic\n 822 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n 823 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n 824 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220811_23_11.bin'.format(folder_v,model_v)\n 825 | model_input_dict['nu'] = 101\n 826 | model_input_dict['n_layer'] = 1\n 827 | model_input_dict['train_ds'] = train_ds\n 828 | model_input_dict['val_ds'] = test_ds\n 829 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n 830 | model_input_dict['oot_ds'] = oot_ds\n 831 | perf_dic = eval_train_val_oot(model_input_dict)\n 832 | tvo_plot(perf_dic)\n 833 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n 834 | dis_cutoff=0.78\n 835 | rfi_cutoff=0.7\n 836 | n_total = np.sum(case_eval_ds_agg['discipline_id']==1)\n 837 | a_pos=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 838 |                          (case_eval_ds_agg['prob_dis2']>=dis_cutoff),\n 839 |                          ['new_logic_label']].value_counts()\n 840 | a_neg=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 841 |                          (case_eval_ds_agg['prob_dis2']<dis_cutoff),\n 842 |                          ['new_logic_label']].value_counts()\n 843 | a_merge = pd.merge(pd.DataFrame(a_pos),pd.DataFrame(a_neg),how='left',left_index=True,right_index=True)\n 844 | a_merge.columns = ['pos','neg']\n 845 | a_merge['ratio'] = a_merge['pos']/(a_merge['pos']+a_merge['neg'])\n 846 | a_merge_t = a_merge.T\n 847 | n_model_dis = a_merge_t.loc['pos',:].sum()\n 848 | a_merge_t['accuracy'] = a_merge_t[(      'Man-Dis',)]/(a_merge_t.sum(axis=1))\n 849 | a_merge_t\n 850 | #n_model_dis = a_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()\n 851 | b_pos=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 852 |                                (case_eval_ds_agg['prob_dis2']<dis_cutoff)&\n 853 |                          (case_eval_ds_agg['prob_rfi']>=rfi_cutoff),\n 854 |                          ['new_logic_label']].value_counts()\n 855 | b_neg=case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==1) & \n 856 |                                (case_eval_ds_agg['prob_dis2']<dis_cutoff)&\n 857 |                          (case_eval_ds_agg['prob_rfi']<rfi_cutoff),\n 858 |                          ['new_logic_label']].value_counts()\n 859 | b_merge = pd.merge(pd.DataFrame(b_pos),pd.DataFrame(b_neg),how='left',left_index=True,right_index=True)\n 860 | b_merge.columns = ['pos','neg']\n 861 | b_merge['ratio'] = b_merge['pos']/(b_merge['pos']+b_merge['neg'])\n 862 | b_merge_t = b_merge.T\n 863 | n_model_rfi = b_merge_t.loc['pos',:].sum()\n 864 | b_merge_t['accuracy']  = b_merge_t[(      'RFI',)]/(b_merge_t.sum(axis=1))\n 865 | b_merge_t\n 866 | #n_model_rfi = b_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()\n 867 | for disp,pepps in [['PEP',1]]:\n 868 |     for key in ['dis2','esc','rfi','em']:\n 869 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n 870 |         #117689504158012865\n 871 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n 872 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n 873 |         eval_comb(_slice_eva_ds, key)\n 874 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_PEP_23.2_ht_1layer.csv',sep='\\x07',index=False)\n 875 | # ## PEP v23.2 Single - no dob, more numericals, no rfi-dismissal, hyper tune\n 876 | folder_v = 'w23'\n 877 | tag_v='23.2_pep'\n 878 | model_v='23.2_pepht'\n 879 | model_input_dict={}\n 880 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 881 |     cat_col, num_col = pickle.load(f)\n 882 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v9.1.pk')\n 883 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2021-07-31 23:59:59']\n 884 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n 885 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n 886 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n 887 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n 888 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n 889 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n 890 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n 891 | tag = 'new_logic_label'\n 892 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 893 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n 894 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 895 | for cat in cat_col:\n 896 |     all_dataset[cat] = all_dataset[cat].astype('string')\n 897 |     all_dataset[cat] = all_dataset[cat].astype('O')\n 898 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n 899 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n 900 | dev_ds.set_index('tid',inplace=True)\n 901 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n 902 | train_ds = dev_ds.loc[train_idx].reset_index()\n 903 | test_ds = dev_ds.loc[test_idx].reset_index()\n 904 | #train_ds = dev_ds.loc[train_caseid].reset_index()\n 905 | #test_ds = dev_ds.loc[test_caseid].reset_index()\n 906 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n 907 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n 908 |     enc_dic = pickle.load(f)\n 909 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 910 |     dev_mean, dev_std = pickle.load(f)\n 911 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 912 |     categorical_embedding_sizes = pickle.load(f)\n 913 | model_input_dict['features'] = [cat_col, num_col]\n 914 | model_input_dict['cat_encoding'] = enc_dic\n 915 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n 916 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n 917 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220811_19_56.bin'.format(folder_v,model_v)\n 918 | model_input_dict['nu'] = 84\n 919 | model_input_dict['n_layer'] = 3\n 920 | model_input_dict['train_ds'] = train_ds\n 921 | model_input_dict['val_ds'] = test_ds\n 922 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n 923 | model_input_dict['oot_ds'] = oot_ds\n 924 | perf_dic = eval_train_val_oot(model_input_dict)\n 925 | tvo_plot(perf_dic)\n 926 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n 927 | for disp,pepps in [['PEP',1]]:\n 928 |     for key in ['dis2','rfi']:\n 929 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n 930 |         #117689504158012865\n 931 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n 932 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n 933 |         eval_comb(_slice_eva_ds, key)\n 934 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_PEP_23.2_ht_3layer.csv',sep='\\x07',index=False)\n 935 | # ## PEP v23.3 Single - no dob, more numericals, no rfi-dismissal, hyper tune\n 936 | folder_v = 'w23'\n 937 | tag_v='23.3_pep'\n 938 | model_v='23.3_pepht'\n 939 | model_input_dict={}\n 940 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 941 |     cat_col, num_col = pickle.load(f)\n 942 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v9.1.pk')\n 943 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-01-31 23:59:59']\n 944 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n 945 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n 946 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n 947 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n 948 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n 949 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n 950 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n 951 | tag = 'new_logic_label'\n 952 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n 953 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n 954 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n 955 | for cat in cat_col:\n 956 |     all_dataset[cat] = all_dataset[cat].astype('string')\n 957 |     all_dataset[cat] = all_dataset[cat].astype('O')\n 958 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n 959 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n 960 | dev_ds.set_index('tid',inplace=True)\n 961 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n 962 | #train_ds = dev_ds.loc[train_idx].reset_index()\n 963 | #test_ds = dev_ds.loc[test_idx].reset_index()\n 964 | train_ds = dev_ds.loc[train_caseid].reset_index()\n 965 | test_ds = dev_ds.loc[test_caseid].reset_index()\n 966 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n 967 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n 968 |     enc_dic = pickle.load(f)\n 969 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 970 |     dev_mean, dev_std = pickle.load(f)\n 971 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n 972 |     categorical_embedding_sizes = pickle.load(f)\n 973 | model_input_dict['features'] = [cat_col, num_col]\n 974 | model_input_dict['cat_encoding'] = enc_dic\n 975 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n 976 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n 977 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220812_14_28.bin'.format(folder_v,model_v)\n 978 | model_input_dict['nu'] = 107\n 979 | model_input_dict['n_layer'] = 4\n 980 | model_input_dict['train_ds'] = train_ds\n 981 | model_input_dict['val_ds'] = test_ds\n 982 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n 983 | model_input_dict['oot_ds'] = oot_ds\n 984 | perf_dic = eval_train_val_oot(model_input_dict)\n 985 | tvo_plot(perf_dic)\n 986 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n 987 | for disp,pepps in [['PEP',1]]:\n 988 |     for key in ['dis2','rfi']:\n 989 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n 990 |         #117689504158012865\n 991 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n 992 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n 993 |         eval_comb(_slice_eva_ds, key)\n 994 | # !pip3 install xlrd -i https://dtr-vip.ccg13.slc.paypalinc.com/artifactory/api/pypi/python/simple\n 995 | # !pip3 install openpyxl -i https://dtr-vip.ccg13.slc.paypalinc.com/artifactory/api/pypi/python/simple\n 996 | all_brd = pd.read_excel('/home/chaoychen/PEP_PS/dataset/VariablesFromBRD.xlsx',engine='openpyxl',sheet_name=None,usecols=[0,1,2,3,4])\n 997 | all_mapping = all_brd['Sheet1']\n 998 | var_mapping = all_brd['Sheet2']\n 999 | [i for i in cat_col if not i in var_mapping['model original variables'].tolist()]\n1000 | [i for i in num_col if not i in var_mapping['model original variables'].tolist()]\n1001 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_PEP_23.3_ht_4layer.csv',sep='\\x07',index=False)\n1002 | # ## PEP v23.4 LGBM - no dob, more numericals, no rfi-dismissal\n1003 | folder_v = 'w23'\n1004 | tag_v='23.3_pep'\n1005 | model_input_dict={}\n1006 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1007 |     cat_col, num_col = pickle.load(f)\n1008 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v9.1.pk')\n1009 | all_dataset=all_dataset.loc[(all_dataset['discipline_id']==1002) & (all_dataset['time_created']>'2022-02-15 23:59:59'),:]\n1010 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1011 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1012 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1013 | tag = 'new_logic_label'\n1014 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1015 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1016 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1017 | for cat in cat_col:\n1018 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1019 |     all_dataset[cat] = all_dataset[cat].astype('category')\n1020 | #train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1021 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n1022 | dev_ds.set_index('tid',inplace=True)\n1023 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1024 | train_ds = dev_ds.loc[train_idx].reset_index()\n1025 | test_ds = dev_ds.loc[test_idx].reset_index()\n1026 | #train_ds = dev_ds.loc[train_caseid].reset_index()\n1027 | #test_ds = dev_ds.loc[test_caseid].reset_index()\n1028 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n1029 | with open('/home/chaoychen/PEP_PS/model_w23/lgbm_1002_tag_esc.pk','rb') as f:\n1030 |     lgbm_esc = pickle.load(f)\n1031 | with open('/home/chaoychen/PEP_PS/model_w23/lgbm_1002_tag_rfi.pk','rb') as f:\n1032 |     lgbm_rfi = pickle.load(f)\n1033 | pred_score = lgbm_esc.predict(oot_ds[lgbm_esc.feature_name()])\n1034 | score_hit = oot_ds[['tid','alert_cust_id','entity_id','tag_esc','tag_rfi','tag_em']]\n1035 | score_hit['pred_esc'] = pred_score\n1036 | score_case = score_hit.groupby(['tid','tag_esc','tag_rfi','tag_em']).agg({'pred_esc':'max'})\n1037 | score_case=score_case.reset_index()\n1038 | true_y = score_case['tag_esc']\n1039 | prob_y = score_case['pred_esc']\n1040 | pt_roc_auc(true_y,prob_y)\n1041 | pred_score = lgbm_rfi.predict(oot_ds[lgbm_rfi.feature_name()])\n1042 | score_hit = oot_ds[['tid','alert_cust_id','entity_id','tag_esc','tag_rfi','tag_em']]\n1043 | score_hit['prob_rfi'] = pred_score\n1044 | score_case = score_hit.groupby(['tid','tag_esc','tag_rfi','tag_em']).agg({'prob_rfi':'max'})\n1045 | score_case=score_case.reset_index()\n1046 | true_y = score_case['tag_rfi']\n1047 | prob_y = score_case['prob_rfi']\n1048 | pt_roc_auc(true_y,prob_y)\n1049 | score_case['prob_dis'] = 1-score_case['pred_esc']\n1050 | score_case['tag_dis'] = np.where(score_case['tag_esc']==1,0,1)\n1051 | eval_comb(score_case,'dis')\n1052 | eval_comb(score_case,'rfi')\n1053 | # ## PEP v25.1 Single - has dob, best 4 layer\n1054 | folder_v = 'w25'\n1055 | tag_v='25.1_pep'\n1056 | model_v='25.1_pepht'\n1057 | model_input_dict={}\n1058 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1059 |     cat_col, num_col = pickle.load(f)\n1060 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.pk')\n1061 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-01-31 23:59:59']\n1062 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1063 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n1064 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n1065 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n1066 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n1067 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1068 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1069 | tag = 'new_logic_label'\n1070 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1071 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1072 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1073 | for cat in cat_col:\n1074 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1075 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1076 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1077 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n1078 | dev_ds.set_index('tid',inplace=True)\n1079 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1080 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1081 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1082 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1083 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1084 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n1085 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1086 |     enc_dic = pickle.load(f)\n1087 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1088 |     dev_mean, dev_std = pickle.load(f)\n1089 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1090 |     categorical_embedding_sizes = pickle.load(f)\n1091 | model_input_dict['features'] = [cat_col, num_col]\n1092 | model_input_dict['cat_encoding'] = enc_dic\n1093 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1094 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1095 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220818_15_05.bin'.format(folder_v,model_v)\n1096 | model_input_dict['nu'] = 107\n1097 | model_input_dict['n_layer'] = 4\n1098 | model_input_dict['train_ds'] = train_ds\n1099 | model_input_dict['val_ds'] = test_ds\n1100 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1101 | model_input_dict['oot_ds'] = oot_ds\n1102 | perf_dic = eval_train_val_oot(model_input_dict)\n1103 | tvo_plot(perf_dic)\n1104 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1105 | for disp,pepps in [['PEP',1]]:\n1106 |     for key in ['dis2','rfi']:\n1107 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n1108 |         #117689504158012865\n1109 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n1110 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1111 |         eval_comb(_slice_eva_ds, key)\n1112 | # ## PEP v25.1 Single - has dob, best 2 layer\n1113 | folder_v = 'w25'\n1114 | tag_v='25.1_pep'\n1115 | model_v='25.1_pepht'\n1116 | model_input_dict={}\n1117 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1118 |     cat_col, num_col = pickle.load(f)\n1119 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.pk')\n1120 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-01-31 23:59:59']\n1121 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1122 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n1123 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n1124 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n1125 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n1126 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1127 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1128 | tag = 'new_logic_label'\n1129 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1130 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1131 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1132 | for cat in cat_col:\n1133 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1134 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1135 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1136 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n1137 | dev_ds.set_index('tid',inplace=True)\n1138 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1139 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1140 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1141 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1142 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1143 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n1144 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1145 |     enc_dic = pickle.load(f)\n1146 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1147 |     dev_mean, dev_std = pickle.load(f)\n1148 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1149 |     categorical_embedding_sizes = pickle.load(f)\n1150 | model_input_dict['features'] = [cat_col, num_col]\n1151 | model_input_dict['cat_encoding'] = enc_dic\n1152 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1153 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1154 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220818_14_11.bin'.format(folder_v,model_v)\n1155 | model_input_dict['nu'] = 59\n1156 | model_input_dict['n_layer'] = 2\n1157 | model_input_dict['train_ds'] = train_ds\n1158 | model_input_dict['val_ds'] = test_ds\n1159 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1160 | model_input_dict['oot_ds'] = oot_ds\n1161 | perf_dic = eval_train_val_oot(model_input_dict)\n1162 | tvo_plot(perf_dic)\n1163 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1164 | for disp,pepps in [['PEP',1]]:\n1165 |     for key in ['dis2','rfi']:\n1166 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n1167 |         #117689504158012865\n1168 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n1169 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1170 |         eval_comb(_slice_eva_ds, key)\n1171 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_PEP_25.1_ht_2layer.csv',sep='\\x07',index=False)\n1172 | # ## PS v26.1 Single - dob vars. trained without auto-rfi, more numericals\n1173 | case_auto_rfi = pd.read_pickle('/home/chaoychen/shared_data/data/keyuchen/pep_ps_scm_hits_driver_v2.pkl')\n1174 | case_auto_rfi = case_auto_rfi.loc[:,['TID','TIME_CREATED','new_logic_label_v2']].drop_duplicates()\n1175 | case_auto_rfi.columns = case_auto_rfi.columns.str.lower()\n1176 | folder_v = 'w26'\n1177 | tag_v='26.1_ps'\n1178 | model_input_dict={}\n1179 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1180 |     cat_col, num_col = pickle.load(f)\n1181 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.pk')\n1182 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1183 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2021-07-31 23:59:59']\n1184 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1185 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1186 | tag = 'new_logic_label'\n1187 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1188 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1189 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1190 | for cat in cat_col:\n1191 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1192 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1193 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1194 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-03-31 23:59:59']\n1195 | dev_ds.set_index('tid',inplace=True)\n1196 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1197 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1198 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1199 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1200 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1201 | # Change OOT evaluation to not including auto-rfi, it will be evaluated separately\n1202 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00'),:]\n1203 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1204 |     enc_dic = pickle.load(f)\n1205 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1206 |     dev_mean, dev_std = pickle.load(f)\n1207 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1208 |     categorical_embedding_sizes = pickle.load(f)\n1209 | model_input_dict['features'] = [cat_col, num_col]\n1210 | model_input_dict['cat_encoding'] = enc_dic\n1211 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1212 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1213 | model_input_dict['model_path'] = './PEP_PS/model_{}/best_after_tuning/{}_20220818_14_18.bin'.format(folder_v,tag_v)\n1214 | model_input_dict['nu'] = 120\n1215 | model_input_dict['n_layer'] = 2\n1216 | model_input_dict['train_ds'] = train_ds\n1217 | model_input_dict['val_ds'] = test_ds\n1218 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1219 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00') & (all_dataset['tid'].isin(case_auto_rfi.loc[case_auto_rfi['new_logic_label_v2']!='Auto-RFI','tid']))]\n1220 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1221 | perf_dic = eval_train_val_oot(model_input_dict)\n1222 | tvo_plot(perf_dic)\n1223 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1224 | for disp,pepps in [['PS',0]]:\n1225 |     for key in ['dis2','rfi']:\n1226 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1227 |         eval_comb(_slice_eva_ds, key)\n1228 | # ## PS v26.2 Single - no dob vars. trained without auto-rfi, more numericals\n1229 | case_auto_rfi = pd.read_pickle('/home/chaoychen/shared_data/data/keyuchen/pep_ps_scm_hits_driver_v2.pkl')\n1230 | case_auto_rfi = case_auto_rfi.loc[:,['TID','TIME_CREATED','new_logic_label_v2']].drop_duplicates()\n1231 | case_auto_rfi.columns = case_auto_rfi.columns.str.lower()\n1232 | folder_v = 'w26'\n1233 | tag_v='26.2_ps'\n1234 | model_input_dict={}\n1235 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1236 |     cat_col, num_col = pickle.load(f)\n1237 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.pk')\n1238 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1239 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2021-07-31 23:59:59']\n1240 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1241 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1242 | tag = 'new_logic_label'\n1243 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1244 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1245 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1246 | for cat in cat_col:\n1247 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1248 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1249 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1250 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-03-31 23:59:59']\n1251 | dev_ds.set_index('tid',inplace=True)\n1252 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1253 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1254 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1255 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1256 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1257 | # Change OOT evaluation to not including auto-rfi, it will be evaluated separately\n1258 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00'),:]\n1259 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1260 |     enc_dic = pickle.load(f)\n1261 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1262 |     dev_mean, dev_std = pickle.load(f)\n1263 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1264 |     categorical_embedding_sizes = pickle.load(f)\n1265 | model_input_dict['features'] = [cat_col, num_col]\n1266 | model_input_dict['cat_encoding'] = enc_dic\n1267 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1268 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1269 | model_input_dict['model_path'] = './PEP_PS/model_{}/best_after_tuning/{}_20220819_14_52.bin'.format(folder_v,tag_v)\n1270 | model_input_dict['nu'] = 120\n1271 | model_input_dict['n_layer'] = 2\n1272 | model_input_dict['train_ds'] = train_ds\n1273 | model_input_dict['val_ds'] = test_ds\n1274 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1275 | all_dataset[['new_logic_label','new_logic_label_v2']].value_counts()\n1276 | #oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00') & (all_dataset['tid'].isin(case_auto_rfi.loc[case_auto_rfi['new_logic_label_v2']!='Auto-RFI','tid']))]\n1277 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00')]\n1278 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1279 | perf_dic = eval_train_val_oot(model_input_dict)\n1280 | tvo_plot(perf_dic)\n1281 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1282 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_{}_ht_2layer_nodob.csv'.format(tag_v),sep='\\x07',index=False)\n1283 | ## Adhoc, get the result with auto-rfi\n1284 | oot_ds = all_dataset.loc[(all_dataset['time_created']>='2022-04-01 00:00:00')]\n1285 | model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1286 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1287 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_{}_ht_2layer_nodob.csv'.format(tag_v),sep='\\x07',index=False)\n1288 | for disp,pepps in [['PS',0]]:\n1289 |     for key in ['dis2','rfi']:\n1290 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n1291 |         #117689504158012865\n1292 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n1293 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1294 |         eval_comb(_slice_eva_ds, key)\n1295 | # ## PEP v25.3 no dob, best 4 layer\n1296 | folder_v = 'w25'\n1297 | tag_v='25.3_pep'\n1298 | model_v='25.3_pepht'\n1299 | model_input_dict={}\n1300 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1301 |     cat_col, num_col = pickle.load(f)\n1302 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.1.pk')\n1303 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-01-31 23:59:59']\n1304 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1305 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n1306 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n1307 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n1308 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n1309 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1310 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1311 | tag = 'new_logic_label'\n1312 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1313 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1314 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1315 | for cat in cat_col:\n1316 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1317 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1318 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1319 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n1320 | dev_ds.set_index('tid',inplace=True)\n1321 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1322 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1323 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1324 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1325 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1326 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n1327 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1328 |     enc_dic = pickle.load(f)\n1329 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1330 |     dev_mean, dev_std = pickle.load(f)\n1331 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1332 |     categorical_embedding_sizes = pickle.load(f)\n1333 | model_input_dict['features'] = [cat_col, num_col]\n1334 | model_input_dict['cat_encoding'] = enc_dic\n1335 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1336 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1337 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220822_09_16.bin'.format(folder_v,model_v)\n1338 | model_input_dict['nu'] = 107\n1339 | model_input_dict['n_layer'] = 4\n1340 | model_input_dict['train_ds'] = train_ds\n1341 | model_input_dict['val_ds'] = test_ds\n1342 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1343 | model_input_dict['oot_ds'] = oot_ds\n1344 | perf_dic = eval_train_val_oot(model_input_dict)\n1345 | tvo_plot(perf_dic)\n1346 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1347 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_{}_ht_4layer.csv'.format(model_v),sep='\\x07',index=False)\n1348 | for disp,pepps in [['PEP',1]]:\n1349 |     for key in ['dis2','rfi']:\n1350 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n1351 |         #117689504158012865\n1352 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n1353 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1354 |         eval_comb(_slice_eva_ds, key)\n1355 | # ## PEP v25.5 has dob, best 2 layer\n1356 | folder_v = 'w25'\n1357 | tag_v='25.5_pep'\n1358 | model_v='25.5_pepht'\n1359 | model_input_dict={}\n1360 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1361 |     cat_col, num_col = pickle.load(f)\n1362 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.1.pk')\n1363 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-01-31 23:59:59']\n1364 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1365 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n1366 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n1367 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n1368 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n1369 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1370 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1371 | tag = 'new_logic_label'\n1372 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1373 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1374 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1375 | for cat in cat_col:\n1376 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1377 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1378 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1379 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n1380 | dev_ds.set_index('tid',inplace=True)\n1381 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1382 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1383 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1384 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1385 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1386 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n1387 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1388 |     enc_dic = pickle.load(f)\n1389 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1390 |     dev_mean, dev_std = pickle.load(f)\n1391 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1392 |     categorical_embedding_sizes = pickle.load(f)\n1393 | model_input_dict['features'] = [cat_col, num_col]\n1394 | model_input_dict['cat_encoding'] = enc_dic\n1395 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1396 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1397 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220822_11_04.bin'.format(folder_v,model_v)\n1398 | model_input_dict['nu'] = 71\n1399 | model_input_dict['n_layer'] = 2\n1400 | model_input_dict['train_ds'] = train_ds\n1401 | model_input_dict['val_ds'] = test_ds\n1402 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1403 | model_input_dict['oot_ds'] = oot_ds\n1404 | perf_dic = eval_train_val_oot(model_input_dict)\n1405 | tvo_plot(perf_dic)\n1406 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1407 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_{}_ht_2layer.csv'.format(model_v),sep='\\x07',index=False)\n1408 | for disp,pepps in [['PEP',1]]:\n1409 |     for key in ['dis2','rfi']:\n1410 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n1411 |         #117689504158012865\n1412 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n1413 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1414 |         eval_comb(_slice_eva_ds, key)\n1415 | # ## PEP v25.6 no dob, best 2 layer\n1416 | folder_v = 'w25'\n1417 | tag_v='25.6_pep'\n1418 | model_v='25.6_pepht'\n1419 | model_input_dict={}\n1420 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1421 |     cat_col, num_col = pickle.load(f)\n1422 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.1.pk')\n1423 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-01-31 23:59:59']\n1424 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1425 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n1426 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n1427 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n1428 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n1429 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1430 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1431 | tag = 'new_logic_label'\n1432 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1433 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1434 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1435 | for cat in cat_col:\n1436 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1437 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1438 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1439 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n1440 | dev_ds.set_index('tid',inplace=True)\n1441 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1442 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1443 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1444 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1445 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1446 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n1447 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1448 |     enc_dic = pickle.load(f)\n1449 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1450 |     dev_mean, dev_std = pickle.load(f)\n1451 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1452 |     categorical_embedding_sizes = pickle.load(f)\n1453 | model_input_dict['features'] = [cat_col, num_col]\n1454 | model_input_dict['cat_encoding'] = enc_dic\n1455 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1456 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1457 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}_20220824_11_53.bin'.format(folder_v,model_v)\n1458 | model_input_dict['nu'] = 71\n1459 | model_input_dict['n_layer'] = 2\n1460 | model_input_dict['train_ds'] = train_ds\n1461 | model_input_dict['val_ds'] = test_ds\n1462 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1463 | model_input_dict['oot_ds'] = oot_ds\n1464 | perf_dic = eval_train_val_oot(model_input_dict)\n1465 | tvo_plot(perf_dic)\n1466 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1467 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_{}_ht_2layer.csv'.format(model_v),sep='\\x07',index=False)\n1468 | for disp,pepps in [['PEP',1]]:\n1469 |     for key in ['dis2','rfi']:\n1470 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n1471 |         #117689504158012865\n1472 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n1473 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1474 |         eval_comb(_slice_eva_ds, key)\n1475 | # ## PEP v25.6 dob, best 2 layer, with new dob (change numerical difference, such as 19900101 to 1990, 1, 1 and get difference\n1476 | folder_v = 'w25'\n1477 | tag_v='25.6_pep_newdob'\n1478 | model_v='25.6_pep_newdob'\n1479 | model_input_dict={}\n1480 | with open(\"./PEP_PS/model_{}/col_names_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1481 |     cat_col, num_col = pickle.load(f)\n1482 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.1.pk')\n1483 | all_dataset = all_dataset.loc[all_dataset['time_created']>'2022-01-31 23:59:59']\n1484 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n1485 | #all_dataset.drop(columns=['entity_type_x'],inplace=True)\n1486 | #all_dataset.drop(columns=['entity_type_y'],inplace=True)\n1487 | #all_dataset.drop(columns=['entity_type_name_x'],inplace=True)\n1488 | #all_dataset.rename(columns={'entity_type_name_y':'entity_type_name'},inplace=True)\n1489 | col_2_num = all_dataset.loc[:3,num_col].select_dtypes('object').columns.tolist()\n1490 | all_dataset[col_2_num] = all_dataset[col_2_num].astype('float64')\n1491 | tag = 'new_logic_label'\n1492 | all_dataset['tag_esc'] = np.where(all_dataset[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n1493 | all_dataset['tag_rfi'] = np.where(all_dataset[tag].isin(['RFI']),1,0)\n1494 | all_dataset['tag_em'] = np.where(all_dataset[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n1495 | for cat in cat_col:\n1496 |     all_dataset[cat] = all_dataset[cat].astype('string')\n1497 |     all_dataset[cat] = all_dataset[cat].astype('O')\n1498 | train_caseid, test_caseid = pd.read_pickle('./PEP_PS/model_{}/dev_splitcase_{}.pk'.format(folder_v,tag_v))\n1499 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n1500 | dev_ds.set_index('tid',inplace=True)\n1501 | train_idx, test_idx = train_test_split(dev_ds.index.unique(), test_size=0.2, random_state=42)\n1502 | #train_ds = dev_ds.loc[train_idx].reset_index()\n1503 | #test_ds = dev_ds.loc[test_idx].reset_index()\n1504 | train_ds = dev_ds.loc[train_caseid].reset_index()\n1505 | test_ds = dev_ds.loc[test_caseid].reset_index()\n1506 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n1507 | with open('./PEP_PS/model_{}/enc_dic_splitcase_{}.pk'.format(folder_v,tag_v),'rb') as f:\n1508 |     enc_dic = pickle.load(f)\n1509 | with open(\"./PEP_PS/model_{}/num_mean_std_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1510 |     dev_mean, dev_std = pickle.load(f)\n1511 | with open(\"./PEP_PS/model_{}/categorical_embedding_sizes_splitcase_{}.pk\".format(folder_v,tag_v), \"rb\") as f:\n1512 |     categorical_embedding_sizes = pickle.load(f)\n1513 | model_input_dict['features'] = [cat_col, num_col]\n1514 | model_input_dict['cat_encoding'] = enc_dic\n1515 | model_input_dict['num_norm'] = [dev_mean, dev_std]\n1516 | model_input_dict['categorical_embedding_sizes'] = categorical_embedding_sizes\n1517 | model_input_dict['model_path'] = './PEP_PS/model_{}/hptuning/{}ht_20220906_10_18.bin'.format(folder_v,model_v)\n1518 | model_input_dict['nu'] = 71\n1519 | model_input_dict['n_layer'] = 2\n1520 | model_input_dict['train_ds'] = train_ds\n1521 | model_input_dict['val_ds'] = test_ds\n1522 | #model_input_dict['oot_ds'] = oot_ds.loc[oot_ds['time_created'].str[:10]!='2022-06-15',:]\n1523 | model_input_dict['oot_ds'] = oot_ds\n1524 | perf_dic = eval_train_val_oot(model_input_dict)\n1525 | tvo_plot(perf_dic)\n1526 | dataset_processed,confusion_dict,case_eval_ds2, case_eval_ds_agg = eval_oot(model_input_dict)\n1527 | case_eval_ds_agg.to_csv('./PEP_PS/Evaluation/eva_{}_ht_2layer.csv'.format(model_v),sep='\\x07',index=False)\n1528 | for disp,pepps in [['PEP',1]]:\n1529 |     for key in ['dis2','rfi']:\n1530 |         #_slice_eva_ds = case_eval_ds_agg.loc[case_eval_ds_agg['discipline_id']==pepps]\n1531 |         #117689504158012865\n1532 |         #_slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['tid']!=117689504158012865)&(case_eval_ds_agg['discipline_id']==pepps)]\n1533 |         _slice_eva_ds = case_eval_ds_agg.loc[(case_eval_ds_agg['discipline_id']==pepps)]\n1534 |         eval_comb(_slice_eva_ds, key)\n1535 | dis_cutoff=0.739\n1536 | rfi_cutoff=0.805\n1537 | em_cutoff=0.99999\n1538 | eva_col = 'new_logic_label_v2'\n1539 | case_eval_ds_agg_with_final=case_eval_ds_agg\n1540 | #eva_col = 'final_step_label'\n1541 | n_total = np.sum(case_eval_ds_agg_with_final['discipline_id']==1)\n1542 | a_pos=case_eval_ds_agg_with_final.loc[(case_eval_ds_agg_with_final['discipline_id']==1) & \n1543 |                          (case_eval_ds_agg_with_final['prob_dis2']>=dis_cutoff)\n1544 |                                       ,\n1545 |                          [eva_col]].value_counts()\n1546 | a_neg=case_eval_ds_agg_with_final.loc[(case_eval_ds_agg_with_final['discipline_id']==1) & \n1547 |                          (case_eval_ds_agg_with_final['prob_dis2']<dis_cutoff),\n1548 |                          [eva_col]].value_counts()\n1549 | a_merge = pd.merge(pd.DataFrame(a_pos),pd.DataFrame(a_neg),how='left',left_index=True,right_index=True)\n1550 | a_merge.columns = ['pos','neg']\n1551 | a_merge['ratio'] = a_merge['pos']/(a_merge['pos']+a_merge['neg'])\n1552 | a_merge_t = a_merge.T\n1553 | n_model_dis = a_merge_t.loc['pos',:].sum()\n1554 | a_merge_t['accuracy'] = a_merge_t[(      'Man-Dis',)]/(a_merge_t.sum(axis=1))\n1555 | a_merge_t\n1556 | #n_model_dis = a_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()\n1557 | b_pos=case_eval_ds_agg_with_final.loc[(case_eval_ds_agg_with_final['discipline_id']==1) & \n1558 |                                (case_eval_ds_agg_with_final['prob_dis2']<dis_cutoff)&\n1559 |                          (case_eval_ds_agg_with_final['prob_rfi']>=rfi_cutoff),\n1560 |                          [eva_col]].value_counts()\n1561 | b_neg=case_eval_ds_agg_with_final.loc[(case_eval_ds_agg_with_final['discipline_id']==1) & \n1562 |                                (case_eval_ds_agg_with_final['prob_dis2']<dis_cutoff)&\n1563 |                          (case_eval_ds_agg_with_final['prob_rfi']<rfi_cutoff),\n1564 |                          [eva_col]].value_counts()\n1565 | b_merge = pd.merge(pd.DataFrame(b_pos),pd.DataFrame(b_neg),how='left',left_index=True,right_index=True)\n1566 | b_merge.columns = ['pos','neg']\n1567 | b_merge['ratio'] = b_merge['pos']/(b_merge['pos']+b_merge['neg'])\n1568 | b_merge_t = b_merge.T\n1569 | n_model_rfi = b_merge_t.loc['pos',:].sum()\n1570 | b_merge_t['accuracy']  = b_merge_t[(      'RFI',)]/(b_merge_t.sum(axis=1))\n1571 | b_merge_t\n1572 | #n_model_rfi = b_merge_t.loc['pos',['Man-Dis','RFI','Man-Esca','Confirmed PEP']].sum()",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/05-lgbm_feature_importance_PEP.py": "   1 | # ## This version is lgbm, aiming on check feature importance, prevent data leakage\n   2 | import lightgbm as lgbm\n   3 | import pandas as pd\n   4 | from IPython.core.interactiveshell import InteractiveShell\n   5 | InteractiveShell.ast_node_interactivity = \"all\"\n   6 | from sklearn.model_selection import train_test_split\n   7 | pd.set_option('display.max_columns', 500)\n   8 | pd.set_option('display.max_rows', 500)\n   9 | import numpy as np\n  10 | import pickle\n  11 | import warnings \n  12 | warnings.filterwarnings('ignore')\n  13 | # ## Read dataset from hdfs\n  14 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.1.pk')\n  15 | all_dataset=all_dataset.loc[(all_dataset['discipline_id']==1002) & (all_dataset['time_created']>'2022-02-15 23:59:59'),:]\n  16 | # ## Define dataset\n  17 | with open(\"./PEP_PS/model_w25/col_names_25.5_pep.pk\", \"rb\") as f:\n  18 |     cat_col, num_col = pickle.load(f)\n  19 | len(cat_col)\n  20 | len(num_col)\n  21 | meta_col = ['tid','discipline_id','entity_reference_id','time_created','new_logic_label','customer_id','alert_cust_id','ps_decision','ps_decision_reason','tag','entity_id','entity_type','entity_uid','pit_context']\n  22 | tag = 'new_logic_label'\n  23 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n  24 | for cat in cat_col:\n  25 |     all_dataset[cat] = all_dataset[cat].astype('O')\n  26 | for num in num_col:\n  27 |     if all_dataset[num].dtype.kind=='O':\n  28 |         all_dataset[num] = all_dataset[num].astype('float64')\n  29 | all_dataset['discipline_id'] = all_dataset['discipline_id'].astype('string')\n  30 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-05-31 23:59:59']\n  31 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-06-01 00:00:00']\n  32 | dev_ds['tag_esc'] = np.where(dev_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n  33 | dev_ds['tag_rfi'] = np.where(dev_ds[tag].isin(['RFI']),1,0)\n  34 | dev_ds['tag_em'] = np.where(dev_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n  35 | oot_ds['tag_esc'] = np.where(oot_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n  36 | oot_ds['tag_rfi'] = np.where(oot_ds[tag].isin(['RFI']),1,0)\n  37 | oot_ds['tag_em'] = np.where(oot_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n  38 | # ## Convert categorical\n  39 | dev_ds[cat_col] = dev_ds[cat_col].astype('category')\n  40 | oot_ds[cat_col] = oot_ds[cat_col].astype('category')\n  41 | with open('./PEP_PS/model_w27/dev_ds_lgbm.pk','wb') as f:\n  42 |     pickle.dump(dev_ds,f,protocol=4)\n  43 | with open('./PEP_PS/model_w27/oot_ds_lgbm.pk','wb') as f:\n  44 |     pickle.dump(oot_ds,f,protocol=4)\n  45 | # ## split dataset\n  46 | dev_ds.shape\n  47 | oot_ds.shape\n  48 | dev_ds[tag_mt].mean()\n  49 | oot_ds[tag_mt].mean()\n  50 | case_auto_rfi = pd.read_pickle('/home/chaoychen/shared_data/data/keyuchen/pep_ps_scm_hits_driver_v2.pkl')\n  51 | case_auto_rfi = case_auto_rfi.loc[:,['TID','TIME_CREATED','new_logic_label_v2']].drop_duplicates()\n  52 | case_auto_rfi.columns = case_auto_rfi.columns.str.lower()\n  53 | dev_ds2 = dev_ds.loc[dev_ds['tid'].isin(case_auto_rfi.loc[case_auto_rfi['new_logic_label_v2']!='Auto-RFI','tid'])]\n  54 | dev_ds.shape\n  55 | dev_ds2.shape\n  56 | raw_train, raw_test = train_test_split(dev_ds2, test_size=0.2, random_state=42)\n  57 | raw_train[tag_mt].mean()\n  58 | raw_test[tag_mt].mean()\n  59 | # ## Modeling\n  60 | params1 = {'task': 'train'\n  61 |            , 'boosting_type': 'gbdt'\n  62 |            , 'objective': 'binary'\n  63 |            , 'metric': 'auc'\n  64 |            , 'is_unbalance': True\n  65 |            , 'learning_rate': 0.005\n  66 |            , 'feature_fraction': 0.8\n  67 |            , 'bagging_fraction': 0.8\n  68 |            , 'bagging_freq': -1\n  69 |            , 'verbose': 50\n  70 |            , 'max_depth': 6\n  71 |            , 'num_leaves': 22\n  72 |            , 'max_bin': 18\n  73 |            , 'min_sum_hessian_in_leaf': 240.89066194627077\n  74 |            , 'num_threads': 10\n  75 |           , 'n_estimators': 400\n  76 |           }\n  77 | tag_mt\n  78 | #with open('/home/chaoychen/PEP_PS/model_w13/num_col.pk','wb') as f:\n  79 | #    pickle.dump(num_col,f)\n  80 | #with open('/home/chaoychen/PEP_PS/model_w13/cat_col.pk','wb') as f:\n  81 | #    pickle.dump(cat_col,f)\n  82 | for disp in ['1002']:\n  83 |     sample_raw_train = raw_train.loc[raw_train['discipline_id']==disp,:]\n  84 |     sample_raw_test = raw_test.loc[raw_test['discipline_id']==disp,:]\n  85 |     for _tag in tag_mt:\n  86 |         dtrain = lgbm.Dataset(data=sample_raw_train[num_col+cat_col]\n  87 |                               ,label=sample_raw_train[_tag]\n  88 |                               ,free_raw_data=False\n  89 |                               ,categorical_feature=cat_col)\n  90 |         dtest = lgbm.Dataset(data=sample_raw_test[num_col+cat_col]\n  91 |                              ,label=sample_raw_test[_tag]\n  92 |                              ,free_raw_data=False\n  93 |                              ,categorical_feature=cat_col)\n  94 |         gbm_init=lgbm.train(params1, train_set=dtrain, valid_sets=[dtest],valid_names=['test'], verbose_eval=50)\n  95 |         with open('/home/chaoychen/PEP_PS/model_w27_lgbm/lgbm_'+disp+'_'+_tag+'.pk','wb') as f:\n  96 |             pickle.dump(gbm_init,f)\n  97 | # ## Feature importance\n  98 | # !pip3 install openpyxl -i https://dtr-vip.ccg13.slc.paypalinc.com/artifactory/api/pypi/python/simple\n  99 | ## all features and save\n 100 | tag = 'new_logic_label'\n 101 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n 102 | model_ls = {}\n 103 | fea_imp_ls = {}\n 104 | for disp in ['1001','1002']:\n 105 |     if disp=='1001':\n 106 |         disp_name = 'PS'\n 107 |     elif disp=='1002':\n 108 |         disp_name = 'PEP'\n 109 |     for _tag in tag_mt:\n 110 |         model_name = disp_name+'_'+_tag\n 111 |         with open('/home/chaoychen/PEP_PS/model_w20/lgbm_'+disp+'_'+_tag+'.pk','rb') as f:\n 112 |             model_ls[model_name] = pickle.load(f)\n 113 |         fea_imp=[*zip(model_ls[model_name].feature_name(),model_ls[model_name].feature_importance('gain'))]\n 114 |         _sum_imp = sum([j for i,j in fea_imp])\n 115 |         fea_imp_df = pd.DataFrame(sorted(fea_imp,key=lambda x:x[1],reverse=True)).rename(columns={0:'variable',1:'importance'})\n 116 |         fea_imp_df['scaled_importance'] = fea_imp_df['importance']/_sum_imp\n 117 |         fea_imp_ls[model_name]= fea_imp_df[['variable','scaled_importance']]\n 118 | with pd.ExcelWriter('./PEP_PS/Feature_imp/pepps_model_imp_v9.1.xlsx') as writer:  \n 119 |     for i in fea_imp_ls.keys():\n 120 |         fea_imp_ls[i].to_excel(writer, sheet_name=i)\n 121 | ## only top 10 features\n 122 | tag = 'new_logic_label'\n 123 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n 124 | model_ls = {}\n 125 | fea_imp_ls = {}\n 126 | for disp in ['1001','1002']:\n 127 |     for _tag in tag_mt:\n 128 |         model_name = disp+'_'+_tag\n 129 |         with open('/home/chaoychen/PEP_PS/model_w20/lgbm_'+disp+'_'+_tag+'.pk','rb') as f:\n 130 |             model_ls[model_name] = pickle.load(f)\n 131 |         fea_imp=[*zip(model_ls[model_name].feature_name(),model_ls[model_name].feature_importance('gain'))]\n 132 |         _sum_imp = sum([j for i,j in fea_imp])\n 133 |         fea_imp_df = pd.DataFrame(sorted(fea_imp,key=lambda x:x[1],reverse=True)[0:]).rename(columns={0:'variable',1:'importance'})\n 134 |         fea_imp_df['scaled_importance'] = fea_imp_df['importance']/_sum_imp\n 135 |         fea_imp_ls[model_name]= fea_imp_df[['variable','scaled_importance']]\n 136 | fea_imp_ls['1001_tag_rfi']",
    "rmr_agent/repos/PEP_PS-Model/modeling_script/06-lgbm_feature_importance_PS.py": "   1 | # ## This version is lgbm, aiming on check feature importance, prevent data leakage\n   2 | import lightgbm as lgbm\n   3 | import pandas as pd\n   4 | from IPython.core.interactiveshell import InteractiveShell\n   5 | InteractiveShell.ast_node_interactivity = \"all\"\n   6 | from sklearn.model_selection import train_test_split\n   7 | pd.set_option('display.max_columns', 500)\n   8 | pd.set_option('display.max_rows', 500)\n   9 | import numpy as np\n  10 | import pickle\n  11 | import warnings \n  12 | warnings.filterwarnings('ignore')\n  13 | # ## Read dataset from hdfs\n  14 | all_dataset = pd.read_pickle('./PEP_PS/dataset/clean_all_var_v10.1.pk')\n  15 | all_dataset=all_dataset.loc[(all_dataset['discipline_id']==1001) & (all_dataset['time_created']>'2021-08-01 00:00:00'),:]\n  16 | # ## Define dataset\n  17 | with open(\"./PEP_PS/model_w26/col_names_26.2_ps.pk\", \"rb\") as f:\n  18 |     cat_col, num_col = pickle.load(f)\n  19 | len(cat_col)\n  20 | len(num_col)\n  21 | meta_col = ['tid','discipline_id','entity_reference_id','time_created','new_logic_label','customer_id','alert_cust_id','ps_decision','ps_decision_reason','tag','entity_id','entity_type','entity_uid','pit_context']\n  22 | tag = 'new_logic_label'\n  23 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n  24 | all_dataset = all_dataset.loc[all_dataset['s_trade_name_profanity']!='NON_GIB',:]\n  25 | for cat in cat_col:\n  26 |     all_dataset[cat] = all_dataset[cat].astype('O')\n  27 | for num in num_col:\n  28 |     if all_dataset[num].dtype.kind=='O':\n  29 |         all_dataset[num] = all_dataset[num].astype('float64')\n  30 | all_dataset['discipline_id'] = all_dataset['discipline_id'].astype('string')\n  31 | dev_ds = all_dataset.loc[all_dataset['time_created']<='2022-03-31 23:59:59']\n  32 | oot_ds = all_dataset.loc[all_dataset['time_created']>='2022-04-01 00:00:00']\n  33 | dev_ds['tag_esc'] = np.where(dev_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n  34 | dev_ds['tag_rfi'] = np.where(dev_ds[tag].isin(['RFI']),1,0)\n  35 | dev_ds['tag_em'] = np.where(dev_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n  36 | oot_ds['tag_esc'] = np.where(oot_ds[tag].isin(['Man-Dis','Auto-Dis']),0,1)\n  37 | oot_ds['tag_rfi'] = np.where(oot_ds[tag].isin(['RFI']),1,0)\n  38 | oot_ds['tag_em'] = np.where(oot_ds[tag].isin(['Confirmed PS','Confirmed PEP']),1,0)\n  39 | # ## Convert categorical\n  40 | dev_ds[cat_col] = dev_ds[cat_col].astype('category')\n  41 | oot_ds[cat_col] = oot_ds[cat_col].astype('category')\n  42 | # ## split dataset\n  43 | dev_ds.shape\n  44 | oot_ds.shape\n  45 | dev_ds[tag_mt].mean()\n  46 | oot_ds[tag_mt].mean()\n  47 | case_auto_rfi = pd.read_pickle('/home/chaoychen/shared_data/data/keyuchen/pep_ps_scm_hits_driver_v2.pkl')\n  48 | case_auto_rfi = case_auto_rfi.loc[:,['TID','TIME_CREATED','new_logic_label_v2']].drop_duplicates()\n  49 | case_auto_rfi.columns = case_auto_rfi.columns.str.lower()\n  50 | dev_ds2 = dev_ds.loc[dev_ds['tid'].isin(case_auto_rfi.loc[case_auto_rfi['new_logic_label_v2']!='Auto-RFI','tid'])]\n  51 | dev_ds.shape\n  52 | dev_ds2.shape\n  53 | raw_train, raw_test = train_test_split(dev_ds2, test_size=0.2, random_state=42)\n  54 | raw_train[tag_mt].mean()\n  55 | raw_test[tag_mt].mean()\n  56 | # ## Modeling\n  57 | params1 = {'task': 'train'\n  58 |            , 'boosting_type': 'gbdt'\n  59 |            , 'objective': 'binary'\n  60 |            , 'metric': 'auc'\n  61 |            , 'is_unbalance': True\n  62 |            , 'learning_rate': 0.005\n  63 |            , 'feature_fraction': 0.8\n  64 |            , 'bagging_fraction': 0.8\n  65 |            , 'bagging_freq': -1\n  66 |            , 'verbose': 50\n  67 |            , 'max_depth': 6\n  68 |            , 'num_leaves': 22\n  69 |            , 'max_bin': 18\n  70 |            , 'min_sum_hessian_in_leaf': 240.89066194627077\n  71 |            , 'num_threads': 10\n  72 |           , 'n_estimators': 400\n  73 |           }\n  74 | tag_mt\n  75 | #with open('/home/chaoychen/PEP_PS/model_w13/num_col.pk','wb') as f:\n  76 | #    pickle.dump(num_col,f)\n  77 | #with open('/home/chaoychen/PEP_PS/model_w13/cat_col.pk','wb') as f:\n  78 | #    pickle.dump(cat_col,f)\n  79 | for disp in ['1001']:\n  80 |     sample_raw_train = raw_train.loc[raw_train['discipline_id']==disp,:]\n  81 |     sample_raw_test = raw_test.loc[raw_test['discipline_id']==disp,:]\n  82 |     for _tag in tag_mt:\n  83 |         dtrain = lgbm.Dataset(data=sample_raw_train[num_col+cat_col]\n  84 |                               ,label=sample_raw_train[_tag]\n  85 |                               ,free_raw_data=False\n  86 |                               ,categorical_feature=cat_col)\n  87 |         dtest = lgbm.Dataset(data=sample_raw_test[num_col+cat_col]\n  88 |                              ,label=sample_raw_test[_tag]\n  89 |                              ,free_raw_data=False\n  90 |                              ,categorical_feature=cat_col)\n  91 |         gbm_init=lgbm.train(params1, train_set=dtrain, valid_sets=[dtest],valid_names=['test'], verbose_eval=50)\n  92 |         with open('/home/chaoychen/PEP_PS/model_w27_lgbm/lgbm_'+disp+'_'+_tag+'.pk','wb') as f:\n  93 |             pickle.dump(gbm_init,f)\n  94 | # ## Feature importance\n  95 | # !pip3 install openpyxl -i https://dtr-vip.ccg13.slc.paypalinc.com/artifactory/api/pypi/python/simple\n  96 | ## all features and save\n  97 | tag = 'new_logic_label'\n  98 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n  99 | model_ls = {}\n 100 | fea_imp_ls = {}\n 101 | for disp in ['1001','1002']:\n 102 |     if disp=='1001':\n 103 |         disp_name = 'PS'\n 104 |     elif disp=='1002':\n 105 |         disp_name = 'PEP'\n 106 |     for _tag in tag_mt:\n 107 |         model_name = disp_name+'_'+_tag\n 108 |         with open('/home/chaoychen/PEP_PS/model_w27_lgbm/lgbm_'+disp+'_'+_tag+'.pk','rb') as f:\n 109 |             model_ls[model_name] = pickle.load(f)\n 110 |         fea_imp=[*zip(model_ls[model_name].feature_name(),model_ls[model_name].feature_importance('gain'))]\n 111 |         _sum_imp = sum([j for i,j in fea_imp])\n 112 |         fea_imp_df = pd.DataFrame(sorted(fea_imp,key=lambda x:x[1],reverse=True)).rename(columns={0:'variable',1:'importance'})\n 113 |         fea_imp_df['scaled_importance'] = fea_imp_df['importance']/_sum_imp\n 114 |         fea_imp_ls[model_name]= fea_imp_df[['variable','scaled_importance']]\n 115 | with pd.ExcelWriter('./PEP_PS/Feature_imp/pepps_model_imp_v10.1.xlsx') as writer:  \n 116 |     for i in fea_imp_ls.keys():\n 117 |         fea_imp_ls[i].to_excel(writer, sheet_name=i)\n 118 | ## only top 10 features\n 119 | tag = 'new_logic_label'\n 120 | tag_mt = ['tag_esc','tag_rfi','tag_em']\n 121 | model_ls = {}\n 122 | fea_imp_ls = {}\n 123 | for disp in ['1001','1002']:\n 124 |     for _tag in tag_mt:\n 125 |         model_name = disp+'_'+_tag\n 126 |         with open('/home/chaoychen/PEP_PS/model_w27_lgbm/lgbm_'+disp+'_'+_tag+'.pk','rb') as f:\n 127 |             model_ls[model_name] = pickle.load(f)\n 128 |         fea_imp=[*zip(model_ls[model_name].feature_name(),model_ls[model_name].feature_importance('gain'))]\n 129 |         _sum_imp = sum([j for i,j in fea_imp])\n 130 |         fea_imp_df = pd.DataFrame(sorted(fea_imp,key=lambda x:x[1],reverse=True)[0:]).rename(columns={0:'variable',1:'importance'})\n 131 |         fea_imp_df['scaled_importance'] = fea_imp_df['importance']/_sum_imp\n 132 |         fea_imp_ls[model_name]= fea_imp_df[['variable','scaled_importance']]\n 133 | fea_imp_ls['1002_tag_rfi']"
  }
}